<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<meta name="theme-color" content="#222">
<script>
    (function(){
        if('mahuateng'){
            if (prompt('请输入文章密码') !== 'mahuateng'){
                alert('密码错误！请问博主爸爸');
                history.back();
            }
        }
    })();
</script>


  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "258f1ebb"
    });
  daovoice('update');
  </script>









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="算法竞赛,日志,">










<meta name="description" content="4月18日比赛第一天,刚拿到数据,简单粗略的看了一遍数据,已将uer,ad_operation,ad_feature三个文件的里的杂乱数据转换成csv下的数据. 发现的一些问题: User文件 这里user_id 其实是乱排的,所以它不是连续的整型数据.所以如果用字符串处理它也是可以的,只要之后用sklean再重新编码就行了  性别里是由1,2,3的数值来表示,也就是说存在不确定性别这一说  这里">
<meta name="keywords" content="算法竞赛,日志">
<meta property="og:type" content="article">
<meta property="og:title" content="腾讯广告算法大赛日志">
<meta property="og:url" content="http://yifdu.github.io/2019/04/18/腾讯广告算法大赛日志/index.html">
<meta property="og:site_name" content="深度菜鸟">
<meta property="og:description" content="4月18日比赛第一天,刚拿到数据,简单粗略的看了一遍数据,已将uer,ad_operation,ad_feature三个文件的里的杂乱数据转换成csv下的数据. 发现的一些问题: User文件 这里user_id 其实是乱排的,所以它不是连续的整型数据.所以如果用字符串处理它也是可以的,只要之后用sklean再重新编码就行了  性别里是由1,2,3的数值来表示,也就是说存在不确定性别这一说  这里">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-05-02T17:08:16.373Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="腾讯广告算法大赛日志">
<meta name="twitter:description" content="4月18日比赛第一天,刚拿到数据,简单粗略的看了一遍数据,已将uer,ad_operation,ad_feature三个文件的里的杂乱数据转换成csv下的数据. 发现的一些问题: User文件 这里user_id 其实是乱排的,所以它不是连续的整型数据.所以如果用字符串处理它也是可以的,只要之后用sklean再重新编码就行了  性别里是由1,2,3的数值来表示,也就是说存在不确定性别这一说  这里">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yifdu.github.io/2019/04/18/腾讯广告算法大赛日志/">





  <title>腾讯广告算法大赛日志 | 深度菜鸟</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">深度菜鸟</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-resume">
          <a href="/resume/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            简历
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yifdu.github.io/2019/04/18/腾讯广告算法大赛日志/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yif Du">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/xuanyi.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="深度菜鸟">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">腾讯广告算法大赛日志</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-18T23:19:52+08:00">
                2019-04-18
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/算法竞赛/" itemprop="url" rel="index">
                    <span itemprop="name">算法竞赛</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读数
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  9.9k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  42 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="4月18日"><a href="#4月18日" class="headerlink" title="4月18日"></a>4月18日</h1><p>比赛第一天,刚拿到数据,简单粗略的看了一遍数据,已将uer,ad_operation,ad_feature三个文件的里的杂乱数据转换成csv下的数据.</p>
<p>发现的一些问题:</p>
<h2 id="User文件"><a href="#User文件" class="headerlink" title="User文件"></a>User文件</h2><ol>
<li><p>这里user_id 其实是乱排的,所以它不是连续的整型数据.所以如果用字符串处理它也是可以的,只要之后用sklean再重新编码就行了</p>
</li>
<li><p>性别里是由1,2,3的数值来表示,也就是说存在不确定性别这一说</p>
</li>
<li><p>这里婚恋状况(Status)是取多值的,暂时将其保存成了字符串的形式. 常见的数值是0-18,不知道为什么会有那么多状态.</p>
</li>
<li><p>Education很规矩,1-8取其中的任意一个值.消费能力(Consuption)也很规矩,1-3取其中的任意一个值</p>
</li>
<li><p>device:这个特征很调皮,取了0,2,3,4,所以之后也要用sklearn重新编码一下</p>
</li>
<li><p>work:是可以取多值的,0-6的取值互相组合,统计下来有以下几种组合:<br>[0]、[1]、[2]、[2,1]、[2,4]、[2,5]、[2,6]、[2,6,1]、[2,6,4]、[2,6,5]、[3]、[3,2]、[3,2,6]、[3,6]、[4]、[5]、[6]、[6,1]、[6,4]、[6,5]<br>之后也可以用sklearn重新编码一下</p>
</li>
<li><p>连接类型:很规矩，1-5,都是单值</p>
</li>
<li><p>behavior:暂时存成了字符串形式,暂时没有想法</p>
</li>
</ol>
<h2 id="ad-feature"><a href="#ad-feature" class="headerlink" title="ad_feature"></a>ad_feature</h2><ol>
<li><p>ad_id都是唯一的,但发现日志里的广告数少于这里的广告数,说明有一些广告是没有在日志里曝光过的,并且说明书里也有提及测试数据里会有新的广告,这时我想到的是推荐系统里的协同过滤,细节还没有想清楚</p>
</li>
<li><p>create_time:是创造的时间,以时间戳的形式存储,后续应该怎么处理,可以参考一下以前比赛的处理方式</p>
</li>
<li><p>account_id: 从1开始一直到29737,只取单值.看到有不同广告同一个account_id,很有可能是一家公司,或是什么的.这个到时候可以进行补全缺失值用。还有就是暂时没弄懂账户结构分为4级的意思.</p>
</li>
<li><p>merch_id:这个说明书上写的是唯一标识,但却找到了不唯一的ad,并且里面的格式貌似也是不统一的,要到时候修正一下(重点处理该特征)</p>
</li>
<li><p>merch_type:很干净,1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18(注意少了9,糟老头坏的很)。</p>
</li>
<li><p>ad_industry:可以取多值,暂时保存成了字符串形式.</p>
</li>
<li><p>ad_size:存在缺省值:说是可以取多值,但是暂时没看到多个值,还要再观察观察.</p>
</li>
</ol>
<h2 id="ad-operation"><a href="#ad-operation" class="headerlink" title="ad_operation"></a>ad_operation</h2><ol>
<li>ad_id:会出现多次</li>
<li>time:这个时间是创建时间或者是修改时间,当数值为0表示创建时间,你可以在上面的ad_feature里找到具体的创建时间,非零的情况是修改时间,这个时间并不是时间戳的形式,而是20170217000000这样的形式(个人觉得没什么用)</li>
<li>op_type:操作的类型,创建是2,修改是1,创建时time就为0</li>
<li>modify:修改字段，只出现1，2，3，4,指明要修改的特征</li>
<li>change_value:是改后的值,现在保存成了字符串的形式,之后可以考虑多弄几列分别表示更改广告状态,出价,人群定向和广告时段设置.注意广告人群定向里有all.</li>
</ol>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>看了第一天的日志(2.16),</p>
<ol>
<li>统计了一下ad_position_id,有些位置的曝光次数特别的多.可以认为是常用广告位.</li>
<li>同一时间的请求,同一个广告位上可能存在多个广告.</li>
<li>之前说过要改user_id,注意一定要与日志里的同时改.</li>
<li>同一天里同一个广告,很有可能专门出现在一个位置,大小也倾向相同,当然这也不绝对,还是到时候要画图一下看看</li>
<li>另外,同一天的同一个曝光广告的bid可能是不同,个人认为不会是因为广告频繁被修改价格,而是因为GSP竞价机制,最终赢的广告的价格是由第二名决定的.我看GSP的概念的时候,认为这时与时间强相关的一种竞价方式,不知道这里会不会用到时间序列.</li>
<li>有些广告曝光次数很多,有些很少,应该也是符合长尾分布.具体还要画图才能知道.</li>
</ol>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol>
<li>把user,ad_feature,ad_op里的独立的特征都进行编码,所谓独立的特征就是与其他表不相关的特征</li>
<li>对ad_operation里的change_value处理.ad_operation里的time改成时间戳的形式</li>
<li>考虑一些需要显示的图:<br>a. 日志里31天每天的请求次数(不重复)可以绘制成图,可以反映,这些用户的用手机的习惯<br>b. 看个别几条广告31天的曝光次数变化,参照着它的操作.<br>c. 也需要考虑用户这31天的请求次数(不重复)的图,可以反映个人习惯.<br>d. 考虑单天里位置,尺寸的影响.<br>….待补充….<br>一些计算广告专业数值与曝光的关系需要好好研究研究.<h1 id="4月19日"><a href="#4月19日" class="headerlink" title="4月19日"></a>4月19日</h1>发现ad_op中其实创建修改一般都是同时进行的.<br>绝大部分创建时就修改了属性<br>有1522个数据是创建时就设置了失活.<br>有231493次操作要设置为正常.<br>有269309次操作要设置为失活.<br>而暂时未知,创建了广告之后状态是算失活还是正常.<br>（个人倾向于一创建就算正常,否则创建设置失活这一操作就毫无意义.但不确定需要与log中进行比较查看才能确定.）</li>
</ol>
<h2 id="Done"><a href="#Done" class="headerlink" title="Done"></a>Done</h2><h3 id="user"><a href="#user" class="headerlink" title="user"></a>user</h3><p>device：从[0,2,3,4]映射到了[0,1,2,3]<br>work:[‘0’,’1’,’2’,’2,1’,’2,4’,’2,5’,’2,6’,’2,6,1’,’2,6,4’,’2,6,5’,’3’,’3,2’,’3,2,6’,’3,6’,’4’,’5’,’6’,’6,1’,’6,4’,’6,5’]映射到[0,…19]</p>
<h3 id="ad-feature-1"><a href="#ad-feature-1" class="headerlink" title="ad_feature"></a>ad_feature</h3><p>将merch_type与test里的merch_type统一<br>[1,2,3,4,5,6,7,8,10,11,12,13,14,15,16,17,18]映射到[0,….,16]</p>
<p>ad_id为388994,219111,56723的广告,商品id不唯一<br>388994:(6199,28123)<br>219111:(6199,28123)<br>56723:(19196,26277)</p>
<p>暂且只有一个广告的size是两个值的.</p>
<h3 id="ad-op"><a href="#ad-op" class="headerlink" title="ad_op"></a>ad_op</h3><p>在将time转化成时间戳的过程中发现了一些无效的时间,比如,20190230,这个日期会存在我准备将其保存成-1(大概有1292个)<br>将chang_value那一列扩展成了4列,每列分别对应于修改字段修改的值.因为每行每列都要用数字填充,所以用-1填充.</p>
<h2 id="TODO-1"><a href="#TODO-1" class="headerlink" title="TODO"></a>TODO</h2><p>要给日志里的时间找到对应的周几.<br>以及对ad_op文件里的投放时间段进行处理,以便以后方便找到投放时间.</p>
<h1 id="4月20日"><a href="#4月20日" class="headerlink" title="4月20日"></a>4月20日</h1><h2 id="ad-op-1"><a href="#ad-op-1" class="headerlink" title="ad_op"></a>ad_op</h2><p>已经确定ad_op的数据里time=0且op_type=1的数据为脏数据。这些数据没有后续操作了<br>测试数据有20000条。<br>不知道人群定向以外的人会收到该广告的曝光么?<br>广告之间是会相互影响的,不能一条一条的输入.<br>（广告竞争！！）</p>
<p>现已将ad_op里的time=0且op_type=2的数据的time=0改成其创造时间,有些操作的广告没有静态数据,则已经被用0来填充了.time里的-1表示时间戳有问题.</p>
<p>ad_op里进行过操作的不同广告数为37000多(已经剃除了脏数据)</p>
<h2 id="ad-feature-2"><a href="#ad-feature-2" class="headerlink" title="ad_feature"></a>ad_feature</h2><p>静态数据里创建时间存在0,缺省值（9290个）<br>account_id不存在缺省值<br>merch_id存在落地页,也许不算缺省值<br>ad_industry不存在缺省值<br>ad_size有缺失</p>
<h2 id="用户画像的方法"><a href="#用户画像的方法" class="headerlink" title="用户画像的方法"></a>用户画像的方法</h2><p>用户画像构建方法分成三类:</p>
<ol>
<li><p>第一类就是查户口。直接使用原始数据作为用户画像的内容，如注册资料等人口统计学信息，或者购买历史，阅读历史等，除了数据清洗等工作，数据本身并没有做任何抽象和归纳。这就跟查户口一样，没什么技术含量，但通常对于用户冷启动等场景非常有用。</p>
</li>
<li><p>第二类就是堆数据。方法就是堆积历史数据，做统计工作，这是最常见的用户画像数据，常见的兴趣标签，就是这一类，就是从历史行为数据中去挖掘出标签，然后在标签维度上做数据统计，用统计结果作为量化结果。这一类数据贡献了常见的酷炫用户画像</p>
</li>
<li>第三类就是黑盒子。就是用机器学习方法，学习出人类无法直观理解的稠密向量，也最不被非技术人员重视，但实际上在推荐系统中承担的作用非常大。比如使用潜语义模型构建用户阅读兴趣，或者使用矩阵分解得到的隐因子，或者使用深度学习模型学习用户的 Embedding 向量。这一类用户画像数据因为通常是不可解释，不能直接被人看懂。<h2 id="TODO-2"><a href="#TODO-2" class="headerlink" title="TODO"></a>TODO</h2></li>
<li>得到User的候选广告</li>
</ol>
<h1 id="4-25"><a href="#4-25" class="headerlink" title="4.25"></a>4.25</h1><h2 id="每天的数据已经得到"><a href="#每天的数据已经得到" class="headerlink" title="每天的数据已经得到"></a>每天的数据已经得到</h2><p>目前已经得到多个统计数据<br>暂时的发现,日志里的曝光广告的ad_size都不为-1,且曝光广告位的大小与广告大小严格一致<br>且统计了每天的各个大小的曝光广告位的个数,应该是一致的分布<br>找到各个广告位的id所匹配的广告位大小</p>
<h2 id="TODO-3"><a href="#TODO-3" class="headerlink" title="TODO"></a>TODO</h2><p>pctr与广告位有关</p>
<p>各个广告位的个数在每天是差不多的,也就是说可以的到预测一天广告位的个数</p>
<p>广告位与广告尺寸的大小关系是固定的,广告位只与特定的几个广告尺寸相关</p>
<h1 id="4-27"><a href="#4-27" class="headerlink" title="4.27"></a>4.27</h1><h2 id="log"><a href="#log" class="headerlink" title="log"></a>log</h2><p>quality_ecpm为0的个数,在一天中各个时段有周期性变化,到午后达到峰值,再到9点多达到另一个峰值</p>
<h1 id="5月1日"><a href="#5月1日" class="headerlink" title="5月1日"></a>5月1日</h1><h2 id="比赛模型一般框架"><a href="#比赛模型一般框架" class="headerlink" title="比赛模型一般框架"></a>比赛模型一般框架</h2><h3 id="Preprocess"><a href="#Preprocess" class="headerlink" title="Preprocess"></a>Preprocess</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通用的预处理框架</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy <span class="keyword">as</span> sp</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件读取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_csv_file</span><span class="params">(f, logging=False)</span>:</span></span><br><span class="line">    print(<span class="string">"==========读取数据========="</span>)</span><br><span class="line">    data =  pd.read_csv(f)</span><br><span class="line">    <span class="keyword">if</span> logging:</span><br><span class="line">        print(data.head(<span class="number">5</span>))</span><br><span class="line">        print(f, <span class="string">"包含以下列"</span>)</span><br><span class="line">        print(data.columns.values)</span><br><span class="line">        print(data.describe())</span><br><span class="line">        print(data.info())</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<h3 id="LogisticRegression"><a href="#LogisticRegression" class="headerlink" title="LogisticRegression"></a>LogisticRegression</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通用的LogisticRegression框架</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. load data</span></span><br><span class="line">df_train = pd.DataFrame()</span><br><span class="line">df_test  = pd.DataFrame()</span><br><span class="line">y_train = df_train[<span class="string">'label'</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. process data</span></span><br><span class="line">ss = StandardScaler()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. feature engineering/encoding</span></span><br><span class="line"><span class="comment"># 3.1 For Labeled Feature</span></span><br><span class="line">enc = OneHotEncoder()</span><br><span class="line">feats = [<span class="string">"creativeID"</span>, <span class="string">"adID"</span>, <span class="string">"campaignID"</span>]</span><br><span class="line"><span class="keyword">for</span> i, feat <span class="keyword">in</span> enumerate(feats):</span><br><span class="line">    x_train = enc.fit_transform(df_train[feat].values.reshape(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">    x_test = enc.fit_transform(df_test[feat].values.reshape(<span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        X_train, X_test = x_train, x_test</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        X_train, X_test = sparse.hstack((X_train, x_train)), sparse.hstack((X_test, x_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.2 For Numerical Feature</span></span><br><span class="line"><span class="comment"># It must be a 2-D Data for StandardScalar, otherwise reshape(-1, len(feats)) is required</span></span><br><span class="line">feats = [<span class="string">"price"</span>, <span class="string">"age"</span>]</span><br><span class="line">x_train = ss.fit_transform(df_train[feats].values)</span><br><span class="line">x_test  = ss.fit_transform(df_test[feats].values)</span><br><span class="line">X_train, X_test = sparse.hstack((X_train, x_train)), sparse.hstack((X_test, x_test))</span><br><span class="line"></span><br><span class="line"><span class="comment"># model training</span></span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(X_train, y_train)</span><br><span class="line">proba_test = lr.predict_proba(X_test)[:, <span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h3 id="LightGBM"><a href="#LightGBM" class="headerlink" title="LightGBM"></a>LightGBM</h3><ol>
<li><p>二分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Loading Data ... "</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">train_x, train_y, test_x = load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用sklearn.cross_validation进行训练数据集划分，这里训练集和交叉验证集比例为7：3，可以自己根据需要设置</span></span><br><span class="line">X, val_X, y, val_y = train_test_split(</span><br><span class="line">    train_x,</span><br><span class="line">    train_y,</span><br><span class="line">    test_size=<span class="number">0.05</span>,</span><br><span class="line">    random_state=<span class="number">1</span>,</span><br><span class="line">    stratify=train_y <span class="comment">## 这里保证分割后y的比例分布与原数据一致</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X_train = X</span><br><span class="line">y_train = y</span><br><span class="line">X_test = val_X</span><br><span class="line">y_test = val_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># create dataset for lightgbm</span></span><br><span class="line">lgb_train = lgb.Dataset(X_train, y_train)</span><br><span class="line">lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)</span><br><span class="line"><span class="comment"># specify your configurations as a dict</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>,</span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'binary'</span>,</span><br><span class="line">    <span class="string">'metric'</span>: &#123;<span class="string">'binary_logloss'</span>, <span class="string">'auc'</span>&#125;,</span><br><span class="line">    <span class="string">'num_leaves'</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">'max_depth'</span>: <span class="number">6</span>,</span><br><span class="line">    <span class="string">'min_data_in_leaf'</span>: <span class="number">450</span>,</span><br><span class="line">    <span class="string">'learning_rate'</span>: <span class="number">0.1</span>,</span><br><span class="line">    <span class="string">'feature_fraction'</span>: <span class="number">0.9</span>,</span><br><span class="line">    <span class="string">'bagging_fraction'</span>: <span class="number">0.95</span>,</span><br><span class="line">    <span class="string">'bagging_freq'</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">'lambda_l1'</span>: <span class="number">1</span>,  </span><br><span class="line">    <span class="string">'lambda_l2'</span>: <span class="number">0.001</span>,  <span class="comment"># 越小l2正则程度越高</span></span><br><span class="line">    <span class="string">'min_gain_to_split'</span>: <span class="number">0.2</span>,</span><br><span class="line">    <span class="string">'verbose'</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">'is_unbalance'</span>: <span class="keyword">True</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">print(<span class="string">'Start training...'</span>)</span><br><span class="line">gbm = lgb.train(params,</span><br><span class="line">                lgb_train,</span><br><span class="line">                num_boost_round=<span class="number">10000</span>,</span><br><span class="line">                valid_sets=lgb_eval,</span><br><span class="line">                early_stopping_rounds=<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Start predicting...'</span>)</span><br><span class="line"></span><br><span class="line">preds = gbm.predict(test_x, num_iteration=gbm.best_iteration)  <span class="comment"># 输出的是概率结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出结果</span></span><br><span class="line">threshold = <span class="number">0.5</span></span><br><span class="line"><span class="keyword">for</span> pred <span class="keyword">in</span> preds:</span><br><span class="line">    result = <span class="number">1</span> <span class="keyword">if</span> pred &gt; threshold <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出特征重要性</span></span><br><span class="line">importance = gbm.feature_importance()</span><br><span class="line">names = gbm.feature_name()</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./feature_importance.txt'</span>, <span class="string">'w+'</span>) <span class="keyword">as</span> file:</span><br><span class="line">    <span class="keyword">for</span> index, im <span class="keyword">in</span> enumerate(importance):</span><br><span class="line">        string = names[index] + <span class="string">', '</span> + str(im) + <span class="string">'\n'</span></span><br><span class="line">        file.write(string)</span><br></pre></td></tr></table></figure>
</li>
<li><p>多分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Loading Data ... "</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">train_x, train_y, test_x = load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用sklearn.cross_validation进行训练数据集划分，这里训练集和交叉验证集比例为7：3，可以自己根据需要设置</span></span><br><span class="line">X, val_X, y, val_y = train_test_split(</span><br><span class="line">    train_x,</span><br><span class="line">    train_y,</span><br><span class="line">    test_size=<span class="number">0.05</span>,</span><br><span class="line">    random_state=<span class="number">1</span>,</span><br><span class="line">    stratify=train_y <span class="comment">## 这里保证分割后y的比例分布与原数据一致</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X_train = X</span><br><span class="line">y_train = y</span><br><span class="line">X_test = val_X</span><br><span class="line">y_test = val_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># create dataset for lightgbm</span></span><br><span class="line">lgb_train = lgb.Dataset(X_train, y_train)</span><br><span class="line">lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)</span><br><span class="line"><span class="comment"># specify your configurations as a dict</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'boosting_type'</span>: <span class="string">'gbdt'</span>,</span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'multiclass'</span>,</span><br><span class="line">    <span class="string">'num_class'</span>: <span class="number">9</span>,</span><br><span class="line">    <span class="string">'metric'</span>: <span class="string">'multi_error'</span>,</span><br><span class="line">    <span class="string">'num_leaves'</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="string">'min_data_in_leaf'</span>: <span class="number">100</span>,</span><br><span class="line">    <span class="string">'learning_rate'</span>: <span class="number">0.01</span>,</span><br><span class="line">    <span class="string">'feature_fraction'</span>: <span class="number">0.8</span>,</span><br><span class="line">    <span class="string">'bagging_fraction'</span>: <span class="number">0.8</span>,</span><br><span class="line">    <span class="string">'bagging_freq'</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">'lambda_l1'</span>: <span class="number">0.4</span>,</span><br><span class="line">    <span class="string">'lambda_l2'</span>: <span class="number">0.5</span>,</span><br><span class="line">    <span class="string">'min_gain_to_split'</span>: <span class="number">0.2</span>,</span><br><span class="line">    <span class="string">'verbose'</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">'is_unbalance'</span>: <span class="keyword">True</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">print(<span class="string">'Start training...'</span>)</span><br><span class="line">gbm = lgb.train(params,</span><br><span class="line">                lgb_train,</span><br><span class="line">                num_boost_round=<span class="number">10000</span>,</span><br><span class="line">                valid_sets=lgb_eval,</span><br><span class="line">                early_stopping_rounds=<span class="number">500</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Start predicting...'</span>)</span><br><span class="line"></span><br><span class="line">preds = gbm.predict(test_x, num_iteration=gbm.best_iteration)  <span class="comment"># 输出的是概率结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出结果</span></span><br><span class="line"><span class="keyword">for</span> pred <span class="keyword">in</span> preds:</span><br><span class="line">    result = prediction = int(np.argmax(pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出特征重要性</span></span><br><span class="line">importance = gbm.feature_importance()</span><br><span class="line">names = gbm.feature_name()</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'./feature_importance.txt'</span>, <span class="string">'w+'</span>) <span class="keyword">as</span> file:</span><br><span class="line">    <span class="keyword">for</span> index, im <span class="keyword">in</span> enumerate(importance):</span><br><span class="line">        string = names[index] + <span class="string">', '</span> + str(im) + <span class="string">'\n'</span></span><br><span class="line">        file.write(string)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><ol>
<li>二分类<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_x, train_y, test_x = load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建特征</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用sklearn.cross_validation进行训练数据集划分，这里训练集和交叉验证集比例为7：3，可以自己根据需要设置</span></span><br><span class="line">X, val_X, y, val_y = train_test_split(</span><br><span class="line">    train_x,</span><br><span class="line">    train_y,</span><br><span class="line">    test_size=<span class="number">0.01</span>,</span><br><span class="line">    random_state=<span class="number">1</span>,</span><br><span class="line">    stratify=train_y</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xgb矩阵赋值</span></span><br><span class="line">xgb_val = xgb.DMatrix(val_X, label=val_y)</span><br><span class="line">xgb_train = xgb.DMatrix(X, label=y)</span><br><span class="line">xgb_test = xgb.DMatrix(test_x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># xgboost模型 #####################</span></span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'booster'</span>: <span class="string">'gbtree'</span>,</span><br><span class="line">    <span class="comment"># 'objective': 'multi:softmax',  # 多分类的问题、</span></span><br><span class="line">    <span class="comment"># 'objective': 'multi:softprob',   # 多分类概率</span></span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'binary:logistic'</span>,</span><br><span class="line">    <span class="string">'eval_metric'</span>: <span class="string">'logloss'</span>,</span><br><span class="line">    <span class="comment"># 'num_class': 9,  # 类别数，与 multisoftmax 并用</span></span><br><span class="line">    <span class="string">'gamma'</span>: <span class="number">0.1</span>,  <span class="comment"># 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。</span></span><br><span class="line">    <span class="string">'max_depth'</span>: <span class="number">8</span>,  <span class="comment"># 构建树的深度，越大越容易过拟合</span></span><br><span class="line">    <span class="string">'alpha'</span>: <span class="number">0</span>,   <span class="comment"># L1正则化系数</span></span><br><span class="line">    <span class="string">'lambda'</span>: <span class="number">10</span>,  <span class="comment"># 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。</span></span><br><span class="line">    <span class="string">'subsample'</span>: <span class="number">0.7</span>,  <span class="comment"># 随机采样训练样本</span></span><br><span class="line">    <span class="string">'colsample_bytree'</span>: <span class="number">0.5</span>,  <span class="comment"># 生成树时进行的列采样</span></span><br><span class="line">    <span class="string">'min_child_weight'</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="comment"># 这个参数默认是 1，是每个叶子里面 h 的和至少是多少，对正负样本不均衡时的 0-1 分类而言</span></span><br><span class="line">    <span class="comment"># ，假设 h 在 0.01 附近，min_child_weight 为 1 意味着叶子节点中最少需要包含 100 个样本。</span></span><br><span class="line">    <span class="comment"># 这个参数非常影响结果，控制叶子节点中二阶导的和的最小值，该参数值越小，越容易 overfitting。</span></span><br><span class="line">    <span class="string">'silent'</span>: <span class="number">0</span>,  <span class="comment"># 设置成1则没有运行信息输出，最好是设置为0.</span></span><br><span class="line">    <span class="string">'eta'</span>: <span class="number">0.03</span>,  <span class="comment"># 如同学习率</span></span><br><span class="line">    <span class="string">'seed'</span>: <span class="number">1000</span>,</span><br><span class="line">    <span class="string">'nthread'</span>: <span class="number">-1</span>,  <span class="comment"># cpu 线程数</span></span><br><span class="line">    <span class="string">'missing'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">'scale_pos_weight'</span>: (np.sum(y==<span class="number">0</span>)/np.sum(y==<span class="number">1</span>))  <span class="comment"># 用来处理正负样本不均衡的问题,通常取：sum(negative cases) / sum(positive cases)</span></span><br><span class="line">    <span class="comment"># 'eval_metric': 'auc'</span></span><br><span class="line">&#125;</span><br><span class="line">plst = list(params.items())</span><br><span class="line">num_rounds = <span class="number">2000</span>  <span class="comment"># 迭代次数</span></span><br><span class="line">watchlist = [(xgb_train, <span class="string">'train'</span>), (xgb_val, <span class="string">'val'</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉验证</span></span><br><span class="line">result = xgb.cv(plst, xgb_train, num_boost_round=<span class="number">200</span>, nfold=<span class="number">4</span>, early_stopping_rounds=<span class="number">200</span>, verbose_eval=<span class="keyword">True</span>, folds=StratifiedKFold(n_splits=<span class="number">4</span>).split(X, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型并保存</span></span><br><span class="line"><span class="comment"># early_stopping_rounds 当设置的迭代次数较大时，early_stopping_rounds 可在一定的迭代次数内准确率没有提升就停止训练</span></span><br><span class="line">model = xgb.train(plst, xgb_train, num_rounds, watchlist, early_stopping_rounds=<span class="number">200</span>)</span><br><span class="line">model.save_model(<span class="string">'../data/model/xgb.model'</span>)  <span class="comment"># 用于存储训练出的模型</span></span><br><span class="line"></span><br><span class="line">preds = model.predict(xgb_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导出结果</span></span><br><span class="line">threshold = <span class="number">0.5</span></span><br><span class="line"><span class="keyword">for</span> pred <span class="keyword">in</span> preds:</span><br><span class="line">    result = <span class="number">1</span> <span class="keyword">if</span> pred &gt; threshold <span class="keyword">else</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="lightGBM"><a href="#lightGBM" class="headerlink" title="lightGBM"></a>lightGBM</h2><p>使用Dataset构建数据到lgb中<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练数据，500个样本，10个维度</span></span><br><span class="line">train_data = np.random.rand(<span class="number">500</span>, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 构建二分类数据</span></span><br><span class="line">label = np.random.randint(<span class="number">2</span>, size=<span class="number">500</span>)</span><br><span class="line"><span class="comment"># 放入到dataset中</span></span><br><span class="line">train = lgb.Dataset(train_data, label=label)</span><br><span class="line">print(train)</span><br></pre></td></tr></table></figure></p>
<p>还有下列清晰构建数据方式,指定 feature names（特征名称）和 categorical features（分类特征）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data = lgb.Dataset(data, label=label, feature_name=[<span class="string">'c1'</span>, <span class="string">'c2'</span>, <span class="string">'c3'</span>], categorical_feature=[<span class="string">'c3'</span>])</span><br></pre></td></tr></table></figure></p>
<p>分类特征可以人为制定，使用categorical_feature选取你制定的名称</p>
<h2 id="XGBoost-1"><a href="#XGBoost-1" class="headerlink" title="XGBoost"></a>XGBoost</h2><p>在用XGBoost模型进行预测之前先对XGBoost进行简单的介绍</p>
<p>XGBoost模型有两种使用方式，一种是原生版本，一种是实现了sklearn接口的版本。</p>
<h3 id="XGBoost的原生版本参数介绍"><a href="#XGBoost的原生版本参数介绍" class="headerlink" title="XGBoost的原生版本参数介绍"></a>XGBoost的原生版本参数介绍</h3><h4 id="General-Parameters"><a href="#General-Parameters" class="headerlink" title="General Parameters"></a>General Parameters</h4><ol>
<li>booster [default=gbtree]：可选项为gbtree，gblinear或dart；其中gbtree和dart是使用基于树模型的，而gblinear是使用基于线性模型的；</li>
<li>silent [default=0]：0表示输出运行信息，1表示不输出；</li>
<li>nthread [如果不进行设置，默认是最大线程数量]：表示XGBoost运行时的并行线程数量；</li>
<li>disable_default_eval_metric [default=0]：标记以禁用默认度量标准。设置 &gt;0 表示禁用；</li>
<li>num_pbuffer [通过XGBoost自动设置，不需要用户来设置]：预测缓冲区的大小，通常设置为训练实例的数量；</li>
<li>num_feature [通过XGBoost自动设置，不需要用户来设置]：被使用在boosting中的特征维度，设置为最大化的特征维度；</li>
</ol>
<h4 id="Parameters-for-Tree-Booster："><a href="#Parameters-for-Tree-Booster：" class="headerlink" title="Parameters for Tree Booster："></a>Parameters for Tree Booster：</h4><ol>
<li>eta (default=0.3, 别名: learning_rate) ：eta表示学习率：range：[0, 1] ，作用：防止过拟合；</li>
<li>gamma [default=0, 别名: min_split_loss]： 在树的叶节点上进一步分区所需的最小化损失减少，gamma越大算法越保守 range:[0, ∞]；</li>
<li>max_depth [default=6]：表示树的深度，值越大模型越复杂，越容易过拟合。0表示不限制；</li>
<li>min_child_weight [default=1]：子节点所需要的最小样本权重之和。如果一个叶子节点的样本权重和小于min_child_weight结束节点进一步的切分。在线性回归模型中，这个参数是指建立每个模型所需要的最小样本数。该值越大，算法越保守；</li>
<li>max_delta_step [default=0]：我们允许每个叶子输出的最大的delta step，该值为0，表示不限制。该值为正数，可以帮助使更新步骤更加保守。通常该参数不需要设置，但是在logistic回归中，分类类别极度不平衡的时候，将该值设置在1_10之间可以帮助控制更新步骤；</li>
<li>subsample [default=1]：训练数据的子样本，subsample=n，表示在训练数据中随机采样n%的样本，可以防止过拟合。 range：(0, 1] ；</li>
<li>lambda [default=1, 别名: reg_lambda]： L2正则化项系数；</li>
<li>alpha [default=0, 别名: reg_alpha]： L1正则化项系数；</li>
<li>tree_method string [default= auto]：在分布式和外存的版本中，仅支持 tree_method=approx；可选项为：auto, exact, approx, hist, gpu_exact, gpu_hist</li>
</ol>
<ul>
<li>auto：表示使用启发式的方法来选择使运行速度最快的算法，如下：<br>1.1 对于小到中等的数据集，Exact Greedy Algorithm将被使用；<br>1.2 对于大数据集，Approximate Algorithm将被使用；<br>1.3 因为以前的行为总是在单个机器中使用Exact Greedy Algorithm，所以当选择Approximate Algorithm来通知该选择时，用户将得到消息。</li>
<li>Exact Greedy Algorithm</li>
<li>approx：Approximate Algorithm</li>
<li>hist：快速直方图优化近似贪心算法。它使用了一些可以改善性能的方法，例如bins caching；</li>
<li>gpu_exact：在GPU上执行Exact Greedy Algorithm；</li>
<li>gpu_hist：在GPU上执行hist算法；</li>
</ul>
<ol>
<li>max_leaves​ [default=0]：设置叶节点的最大数量，仅仅和​​​​​​当row_policy=lossguide才需要被设置；</li>
<li>max_bin, [default=256]：仅仅tree_method=hist时，该方法需要去设置。bucket连续特征的最大离散bins数量；<h4 id="学习任务参数（Learning-Task-Parameters）"><a href="#学习任务参数（Learning-Task-Parameters）" class="headerlink" title="学习任务参数（Learning Task Parameters）"></a>学习任务参数（Learning Task Parameters）</h4></li>
<li>objective [default=reg:linear]</li>
</ol>
<ul>
<li>reg:linear：线性回归；</li>
<li>reg:logistic：逻辑回归；</li>
<li>binary:logistic： 二分类逻辑回归，输出概率；</li>
<li>binary:logitraw： 二分类逻辑回归，在logistic transformation之前输出score；</li>
<li>binary:hinge： 二分类的hinge损失，让预测为0或1，而不是概率；</li>
<li>multi:softmax：多分类的使用softmax目标函数，使用此含参数时需要指定多分类分为几类，设置num_class=n；</li>
<li>multi:softprob: 和softmax相同，但是输出的是每个样本点属于哪个类的预测概率值；</li>
<li>rank:pairwise：使用XGBoost做排序任务使用的。</li>
</ul>
<ol>
<li>base_score [default=0.5]：所有实例的初始预测分数，全局偏差。对于有足够的迭代数目，改变该值将不会太多的影响；</li>
<li>eval_metric [default according to objective] ：默认：根据objective参数(回归：rmse, 分类：error)。还有许多可以自己查官方API。<h3 id="使用XGBoost原生版本模型"><a href="#使用XGBoost原生版本模型" class="headerlink" title="使用XGBoost原生版本模型"></a>使用XGBoost原生版本模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">X_train,X_test,y_train,y_test = train_test_split(df_train,target,test_size = <span class="number">0.3</span>,random_state = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">data_train = xgb.DMatrix(X_train, y_train)  <span class="comment"># 使用XGBoost的原生版本需要对数据进行转化</span></span><br><span class="line">data_test = xgb.DMatrix(X_test, y_test)</span><br><span class="line"></span><br><span class="line">param = &#123;<span class="string">'max_depth'</span>: <span class="number">5</span>, <span class="string">'eta'</span>: <span class="number">1</span>, <span class="string">'objective'</span>: <span class="string">'binary:logistic'</span>&#125;</span><br><span class="line">watchlist = [(data_test, <span class="string">'test'</span>), (data_train, <span class="string">'train'</span>)]</span><br><span class="line">n_round = <span class="number">3</span></span><br><span class="line">booster = xgb.train(param, data_train, num_boost_round=n_round, evals=watchlist)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算错误率</span></span><br><span class="line">y_predicted = booster.predict(data_test)</span><br><span class="line">y = data_test.get_label()</span><br><span class="line"></span><br><span class="line">accuracy = sum(y == (y_predicted &gt; <span class="number">0.5</span>))</span><br><span class="line">accuracy_rate = float(accuracy) / len(y_predicted)</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'样本总数：&#123;0&#125;'</span>.format(len(y_predicted)))</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'正确数目：&#123;0&#125;'</span>.format(accuracy) )</span><br><span class="line"><span class="keyword">print</span> (<span class="string">'正确率：&#123;0:.3f&#125;'</span>.format((accuracy_rate)))</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="XGBoost的sklearn接口版本参数介绍"><a href="#XGBoost的sklearn接口版本参数介绍" class="headerlink" title="XGBoost的sklearn接口版本参数介绍"></a>XGBoost的sklearn接口版本参数介绍</h3><p>因为XGBoost是使用的是一堆CART树进行集成的，而CART(Classification And Regression Tree)树即可用作分类也可用作回归，这里仅仅介绍XGBoost的分类，回归问题类似，有需要请访问XGBoost API的官网进行查看。</p>
<p>class xgboost.XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective=’binary:logistic’, booster=’gbtree’, n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, ** kwargs)</p>
<ol>
<li>max_depth : int  表示基学习器的最大深度；</li>
<li>learning_rate : float  表示学习率，相当于原生版本的 “eta”;</li>
<li>n_estimators: int  表示去拟合的boosted  tree数量；</li>
<li>silent：boolean  表示是否在运行boosting期间打印信息；</li>
<li>objective：string or callable  指定学习任务和相应的学习目标或者一个自定义的函数被使用，具体看原生版本的objective；</li>
<li>booster：string  指定要使用的booster，可选项为：gbtree，gblinear 或 dart；</li>
<li>n_jobs：int  在运行XGBoost时并行的线程数量。</li>
<li>gamma：float  在树的叶节点上进行进一步分区所需的最小损失的减少值，即加入新节点进入的复杂度的代价；</li>
<li>min_child_weight ： int  在子节点中实例权重的最小的和；</li>
<li>max_delta_step ： int  我们允许的每棵树的权重估计最大的delta步骤；</li>
<li>subsample ：float  训练样本的子采样率；</li>
<li>colsample_bytree ：float  构造每个树时列的子采样率。</li>
<li>colsample_bylevel ：float  在每一层中的每次切分节点时的列采样率；</li>
<li>reg_alpha ：float  相当于原生版本的alpha，表示L1正则化项的权重系数；</li>
<li>reg_lambda： float  相当于原生版本的lambda，表示L2正则化项的权重系数；</li>
<li>scale_pos_weight：float  用来平衡正负权重；</li>
<li>base_score：  所有实例的初始预测分数，全局偏差；</li>
<li>random_state：int  随机种子；</li>
<li>missing：float，optional  需要作为缺失值存在的数据中的值。 如果为None，则默认为np.nan。</li>
</ol>
<p>XGBoost的sklearn的接口版本用法与sklearn中的模型的用法相同，这里简单的进行使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X_train,X_test,y_train,y_test = train_test_split(df_train,target,test_size = <span class="number">0.3</span>,random_state = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model = xgb.XGBClassifier(max_depth=<span class="number">3</span>, n_estimators=<span class="number">200</span>, learn_rate=<span class="number">0.01</span>)</span><br><span class="line">model.fit(X_train, y_train)  </span><br><span class="line">test_score = model.score(X_test, y_test)</span><br><span class="line">print(<span class="string">'test_score: &#123;0&#125;'</span>.format(test_score))</span><br></pre></td></tr></table></figure>
<h2 id="Randomforest"><a href="#Randomforest" class="headerlink" title="Randomforest"></a>Randomforest</h2><p>在scikit-learn中，RandomForest的分类类是RandomForestClassifier，回归类是RandomForestRegressor，需要调参的参数包括两部分，第一部分是Bagging框架的参数，第二部分是CART决策树的参数。</p>
<p>sklearn官网地址（RandomForestClassifier）：<a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">sklearn</span>.<span class="title">ensemble</span>.<span class="title">RandomForestClassifier</span><span class="params">(n_estimators=<span class="number">10</span>, criterion=<span class="string">'gini'</span>, max_depth=None,min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>,max_features=<span class="string">'auto'</span>, max_leaf_nodes=None, min_impurity_split=<span class="number">1e-07</span>,bootstrap=True, oob_score=False, n_jobs=<span class="number">1</span>, random_state=None, verbose=<span class="number">0</span>,warm_start=False, class_weight=None)</span></span></span><br></pre></td></tr></table></figure>
<ol>
<li>参数解读<br>1.1 Bagging框架的参数<br>和GBDT对比，GBDT的框架参数比较多，重要的有最大迭代器个数，步长和子采样比例，调参起来比较费力。但是RF则比较简单，这是因为bagging框架里的各个弱学习器之间是没有依赖关系的，这减小的调参的难度。换句话说，达到同样的调参效果，RF调参时间要比GBDT少一些。下面我来看看RF重要的Bagging框架的参数，由于RandomForestClassifier和RandomForestRegressor参数绝大部分相同，这里会将它们一起讲，不同点会指出。</li>
</ol>
<ul>
<li>n_estimators: 也就是弱学习器的最大迭代次数，或者说最大的弱学习器的个数，默认是10。一般来说n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合，一般选择一个适中的数值。对Random Forest来说，增加“子模型数”（n_estimators）可以明显降低整体模型的方差，且不会对子模型的偏差和方差有任何影响。模型的准确度会随着“子模型数”的增加而提高，由于减少的是整体模型方差公式的第二项，故准确度的提高有一个上限。在实际应用中，可以以10为单位，考察取值范围在1至201的调参情况。</li>
<li>bootstrap：默认True，是否有放回的采样。</li>
<li>oob_score ：默认识False，即是否采用袋外样本来评估模型的好坏。有放回采样中大约36.8%的没有被采样到的数据，我们常常称之为袋外数据(Out Of Bag, 简称OOB)，这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。个人推荐设置为True，因为袋外分数反应了一个模型拟合后的泛化能力。对单个模型的参数训练，我们知道可以用cross validation（cv）来进行，但是特别消耗时间，而且对于随机森林这种情况也没有大的必要，所以就用这个数据对决策树模型进行验证，算是一个简单的交叉验证，性能消耗小，但是效果不错。</li>
<li>criterion： 即CART树做划分时对特征的评价标准，分类模型和回归模型的损失函数是不一样的。分类RF对应的CART分类树默认是基尼系数gini,另一个可选择的标准是信息增益entropy，是用来选择节点的最优特征和切分点的两个准则。回归RF对应的CART回归树默认是均方差mse，另一个可以选择的标准是绝对值差mae。一般来说选择默认的标准就已经很好的。<br>从上面可以看出， RF重要的框架参数比较少，主要需要关注的是 n_estimators，即RF最大的决策树个数。<br>1.2 RF决策树的参数<br>RF的决策树参数，它要调参的参数基本和GBDT相同，如下:</li>
<li>max_features: RF划分时考虑的最大特征数。可以使用很多种类型的值，默认是”None”,意味着划分时考虑所有的特征数；如果是”log2”意味着划分时最多考虑log2N个特征；如果是”sqrt”或者”auto”意味着划分时最多考虑N−−√N个特征。如果是整数，代表考虑的特征绝对数。如果是浮点数，代表考虑特征百分比，即考虑（百分比xN）取整后的特征数，其中N为样本总特征数。一般来说，如果样本特征数不多，比如小于50，我们用默认的”None”就可以了，如果特征数非常多，我们可以灵活使用刚才描述的其他取值来控制划分时考虑的最大特征数，以控制决策树的生成时间。</li>
<li>max_depth: 决策树最大深度。默认为”None”，决策树在建立子树的时候不会限制子树的深度这样建树时，会使每一个叶节点只有一个类别，或是达到min_samples_split。一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。</li>
<li>min_samples_split: 内部节点再划分所需最小样本数，默认2。这个值限制了子树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分。 默认是2.如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。</li>
<li>min_samples_leaf:叶子节点最少样本数。 这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。 默认是1,可以输入最少的样本数的整数，或者最少样本数占样本总数的百分比。如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。</li>
<li>min_weight_fraction_leaf：叶子节点最小的样本权重和。这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝。 默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。</li>
<li>max_leaf_nodes: 最大叶子节点数。通过限制最大叶子节点数，可以防止过拟合，默认是”None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制，具体的值可以通过交叉验证得到。</li>
<li>min_impurity_split: 节点划分最小不纯度。这个值限制了决策树的增长，如果某节点的不纯度(基于基尼系数，均方差)小于这个阈值，则该节点不再生成子节点，即为叶子节点 。一般不推荐改动默认值1e-7。<br>上面决策树参数中最重要的包括最大特征数max_features， 最大深度max_depth， 内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf。</li>
<li>splitter: 随机选择属性”random”还是选择不纯度最大”best”的属性，建议用默认 best。</li>
<li>presort:是否对数据进行预分类，以加快拟合中最佳分裂点的发现。默认False，适用于大数据集。小数据集使用True,可以加快训练。是否预排序,预排序可以加速查找最佳分裂点，对于稀疏数据不管用，Bool，auto：非稀疏数据则预排序，若稀疏数据则不预排序<br>1.3 进行预测的几种常用方法</li>
<li>predict_proba(x)：给出带有概率值的结果。每个点在所有label（类别）的概率和为1.</li>
<li>predict(x)：直接给出预测结果。内部还是调用的predict_proba()，根据概率的结果看哪个类型的预测值最高就是哪个类型。</li>
<li>predict_log_proba(x)：和predict_proba基本上一样，只是把结果给做了log()处理。<br>1.4 RandomForest调参实例<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入需要的库</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> cross_validation, metrics</span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入数据，顺便看看数据的类别分布</span></span><br><span class="line">train= pd.read_csv(<span class="string">'C:\\Users\\86349\\Desktop\\train_modified\\train_modified.csv'</span>)</span><br><span class="line">target=<span class="string">'Disbursed'</span> <span class="comment"># Disbursed的值就是二元分类的输出</span></span><br><span class="line">IDcol= <span class="string">'ID'</span></span><br><span class="line">train[<span class="string">'Disbursed'</span>].value_counts()</span><br><span class="line"></span><br><span class="line"><span class="comment">#可以看到类别输出如下，也就是类别0的占大多数：</span></span><br><span class="line"><span class="number">0</span>    <span class="number">19680</span></span><br><span class="line"><span class="number">1</span>      <span class="number">320</span></span><br><span class="line">Name:Disbursed, dtype: int64</span><br><span class="line"></span><br><span class="line"><span class="comment">#接着选择好样本特征和类别输出，样本特征为除去ID和输出类别的列</span></span><br><span class="line">x_columns = [x <span class="keyword">for</span> x <span class="keyword">in</span> train.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [target,IDcol]]</span><br><span class="line">X = train[x_columns]</span><br><span class="line">y = train[<span class="string">'Disbursed'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#不管任何参数，都用默认的，拟合下数据看看</span></span><br><span class="line">rf0 = RandomForestClassifier(oob_score=<span class="keyword">True</span>, random_state=<span class="number">10</span>)</span><br><span class="line">rf0.fit(X,y)</span><br><span class="line"><span class="keyword">print</span> rf0.oob_score_</span><br><span class="line">y_predprob = rf0.predict_proba(X)[:,<span class="number">1</span>]</span><br><span class="line"><span class="keyword">print</span> <span class="string">"AUC Score (Train): %f"</span> % metrics.roc_auc_score(y,y_predprob)</span><br><span class="line"><span class="comment">#输出如下：0.98005  AUC Score (Train): 0.999833</span></span><br><span class="line"><span class="comment">#可见袋外分数已经很高（理解为袋外数据作为验证集时的准确率，也就是模型的泛化能力），而且AUC分数也很高（AUC是指从一堆样本中随机抽一个，抽到正样本的概率比抽到负样本的概率 大的可能性）。相对于GBDT的默认参数输出，RF的默认参数拟合效果对本例要好一些。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#首先对n_estimators进行网格搜索</span></span><br><span class="line">param_test1= &#123;<span class="string">'n_estimators'</span>:range(<span class="number">10</span>,<span class="number">71</span>,<span class="number">10</span>)&#125;</span><br><span class="line">gsearch1= GridSearchCV(estimator = RandomForestClassifier(min_samples_split=<span class="number">100</span>,</span><br><span class="line">                                 min_samples_leaf=<span class="number">20</span>,max_depth=<span class="number">8</span>,max_features=<span class="string">'sqrt'</span> ,random_state=<span class="number">10</span>),</span><br><span class="line">                       param_grid =param_test1, scoring=<span class="string">'roc_auc'</span>,cv=<span class="number">5</span>)</span><br><span class="line">gsearch1.fit(X,y)</span><br><span class="line">gsearch1.grid_scores_,gsearch1.best_params_, gsearch1.best_score_</span><br><span class="line"><span class="comment">#输出结果如下：</span></span><br><span class="line">([mean:<span class="number">0.80681</span>, std: <span class="number">0.02236</span>, params: &#123;<span class="string">'n_estimators'</span>: <span class="number">10</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81600</span>, std: <span class="number">0.03275</span>, params:&#123;<span class="string">'n_estimators'</span>: <span class="number">20</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81818</span>, std: <span class="number">0.03136</span>, params:&#123;<span class="string">'n_estimators'</span>: <span class="number">30</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81838</span>, std: <span class="number">0.03118</span>, params:&#123;<span class="string">'n_estimators'</span>: <span class="number">40</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82034</span>, std: <span class="number">0.03001</span>, params:&#123;<span class="string">'n_estimators'</span>: <span class="number">50</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82113</span>, std: <span class="number">0.02966</span>, params:&#123;<span class="string">'n_estimators'</span>: <span class="number">60</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81992</span>, std: <span class="number">0.02836</span>, params:&#123;<span class="string">'n_estimators'</span>: <span class="number">70</span>&#125;],</span><br><span class="line">&#123;<span class="string">'n_estimators'</span>:<span class="number">60</span>&#125;,</span><br><span class="line"><span class="number">0.8211334476626017</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#这样我们得到了最佳的弱学习器迭代次数，接着我们对决策树最大深度max_depth和内部节点再划分所需最小样本数min_samples_split进行网格搜索。</span></span><br><span class="line">param_test2= &#123;<span class="string">'max_depth'</span>:range(<span class="number">3</span>,<span class="number">14</span>,<span class="number">2</span>), <span class="string">'min_samples_split'</span>:range(<span class="number">50</span>,<span class="number">201</span>,<span class="number">20</span>)&#125;</span><br><span class="line">gsearch2= GridSearchCV(estimator = RandomForestClassifier(n_estimators= <span class="number">60</span>,</span><br><span class="line">                                 min_samples_leaf=<span class="number">20</span>,max_features=<span class="string">'sqrt'</span> ,oob_score=<span class="keyword">True</span>,random_state=<span class="number">10</span>),</span><br><span class="line">   param_grid = param_test2,scoring=<span class="string">'roc_auc'</span>,iid=<span class="keyword">False</span>, cv=<span class="number">5</span>)</span><br><span class="line">gsearch2.fit(X,y)</span><br><span class="line">gsearch2.grid_scores_,gsearch2.best_params_, gsearch2.best_score_</span><br><span class="line"><span class="comment">#输出如下：</span></span><br><span class="line">([mean:<span class="number">0.79379</span>, std: <span class="number">0.02347</span>, params: &#123;<span class="string">'min_samples_split'</span>: <span class="number">50</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.79339</span>, std: <span class="number">0.02410</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">70</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.79350</span>, std: <span class="number">0.02462</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">90</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.79367</span>, std: <span class="number">0.02493</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">110</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.79387</span>, std: <span class="number">0.02521</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">130</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.79373</span>, std: <span class="number">0.02524</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">150</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.79378</span>, std: <span class="number">0.02532</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">170</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.79349</span>, std: <span class="number">0.02542</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">190</span>, <span class="string">'max_depth'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.80960</span>, std: <span class="number">0.02602</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">50</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.80920</span>, std: <span class="number">0.02629</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">70</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.80888</span>, std: <span class="number">0.02522</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">90</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.80923</span>, std: <span class="number">0.02777</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">110</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.80823</span>, std: <span class="number">0.02634</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">130</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.80801</span>, std: <span class="number">0.02637</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">150</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.80792</span>, std: <span class="number">0.02685</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">170</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.80771</span>, std: <span class="number">0.02587</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">190</span>, <span class="string">'max_depth'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81688</span>, std: <span class="number">0.02996</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">50</span>, <span class="string">'max_depth'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81872</span>, std: <span class="number">0.02584</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">70</span>, <span class="string">'max_depth'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81501</span>, std: <span class="number">0.02857</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">90</span>, <span class="string">'max_depth'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81476</span>, std: <span class="number">0.02552</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">110</span>, <span class="string">'max_depth'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81557</span>, std: <span class="number">0.02791</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">130</span>, <span class="string">'max_depth'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81459</span>, std: <span class="number">0.02905</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">150</span>, <span class="string">'max_depth'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81601</span>, std: <span class="number">0.02808</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">170</span>, <span class="string">'max_depth'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81704</span>, std: <span class="number">0.02757</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">190</span>, <span class="string">'max_depth'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82090</span>, std: <span class="number">0.02665</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">50</span>, <span class="string">'max_depth'</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81908</span>, std: <span class="number">0.02527</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">70</span>, <span class="string">'max_depth'</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82036</span>, std: <span class="number">0.02422</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">90</span>, <span class="string">'max_depth'</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81889</span>, std: <span class="number">0.02927</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">110</span>, <span class="string">'max_depth'</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81991</span>, std: <span class="number">0.02868</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">130</span>, <span class="string">'max_depth'</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81788</span>, std: <span class="number">0.02436</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">150</span>, <span class="string">'max_depth'</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81898</span>, std: <span class="number">0.02588</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">170</span>, <span class="string">'max_depth'</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81746</span>, std: <span class="number">0.02716</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">190</span>, <span class="string">'max_depth'</span>: <span class="number">9</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82395</span>, std: <span class="number">0.02454</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">50</span>, <span class="string">'max_depth'</span>: <span class="number">11</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82380</span>, std: <span class="number">0.02258</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">70</span>, <span class="string">'max_depth'</span>: <span class="number">11</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81953</span>, std: <span class="number">0.02552</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">90</span>, <span class="string">'max_depth'</span>: <span class="number">11</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82254</span>, std: <span class="number">0.02366</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">110</span>, <span class="string">'max_depth'</span>: <span class="number">11</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81950</span>, std: <span class="number">0.02768</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">130</span>, <span class="string">'max_depth'</span>: <span class="number">11</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81887</span>, std: <span class="number">0.02636</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">150</span>, <span class="string">'max_depth'</span>: <span class="number">11</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81910</span>, std: <span class="number">0.02734</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">170</span>, <span class="string">'max_depth'</span>: <span class="number">11</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81564</span>, std: <span class="number">0.02622</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">190</span>, <span class="string">'max_depth'</span>: <span class="number">11</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82291</span>, std: <span class="number">0.02092</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">50</span>, <span class="string">'max_depth'</span>: <span class="number">13</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82177</span>, std: <span class="number">0.02513</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">70</span>, <span class="string">'max_depth'</span>: <span class="number">13</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82415</span>, std: <span class="number">0.02480</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">90</span>, <span class="string">'max_depth'</span>: <span class="number">13</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82420</span>, std: <span class="number">0.02417</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">110</span>, <span class="string">'max_depth'</span>: <span class="number">13</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82209</span>, std: <span class="number">0.02481</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">130</span>, <span class="string">'max_depth'</span>: <span class="number">13</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81852</span>, std: <span class="number">0.02227</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">150</span>, <span class="string">'max_depth'</span>: <span class="number">13</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81955</span>, std: <span class="number">0.02885</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">170</span>, <span class="string">'max_depth'</span>: <span class="number">13</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82092</span>, std: <span class="number">0.02600</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">190</span>, <span class="string">'max_depth'</span>: <span class="number">13</span>&#125;],</span><br><span class="line">&#123;<span class="string">'max_depth'</span>:<span class="number">13</span>, <span class="string">'min_samples_split'</span>: <span class="number">110</span>&#125;,</span><br><span class="line"><span class="number">0.8242016800050813</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#已经取了三个最优参数，看看现在模型的袋外分数：</span></span><br><span class="line">rf1= RandomForestClassifier(n_estimators= <span class="number">60</span>, max_depth=<span class="number">13</span>, min_samples_split=<span class="number">110</span>,</span><br><span class="line">                                 min_samples_leaf=<span class="number">20</span>,max_features=<span class="string">'sqrt'</span> ,oob_score=<span class="keyword">True</span>,random_state=<span class="number">10</span>)</span><br><span class="line">rf1.fit(X,y)</span><br><span class="line">printrf1.oob_score_</span><br><span class="line"><span class="comment">#输出结果为：0.984</span></span><br><span class="line"><span class="comment">#可见此时我们的袋外分数有一定的提高。也就是时候模型的泛化能力增强了。对于内部节点再划分所需最小样本数min_samples_split，我们暂时不能一起定下来，因为这个还和决策树其他的参数存在关联。下面我们再对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#再对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参</span></span><br><span class="line">param_test3= &#123;<span class="string">'min_samples_split'</span>:range(<span class="number">80</span>,<span class="number">150</span>,<span class="number">20</span>), <span class="string">'min_samples_leaf'</span>:range(<span class="number">10</span>,<span class="number">60</span>,<span class="number">10</span>)&#125;</span><br><span class="line">gsearch3= GridSearchCV(estimator = RandomForestClassifier(n_estimators= <span class="number">60</span>,max_depth=<span class="number">13</span>,</span><br><span class="line">                                 max_features=<span class="string">'sqrt'</span> ,oob_score=<span class="keyword">True</span>, random_state=<span class="number">10</span>),</span><br><span class="line">   param_grid = param_test3,scoring=<span class="string">'roc_auc'</span>,iid=<span class="keyword">False</span>, cv=<span class="number">5</span>)</span><br><span class="line">gsearch3.fit(X,y)</span><br><span class="line">gsearch3.grid_scores_,gsearch2.best_params_, gsearch2.best_score_</span><br><span class="line"><span class="comment">#输出如下：</span></span><br><span class="line">([mean:<span class="number">0.82093</span>, std: <span class="number">0.02287</span>, params: &#123;<span class="string">'min_samples_split'</span>: <span class="number">80</span>, <span class="string">'min_samples_leaf'</span>:<span class="number">10</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81913</span>, std: <span class="number">0.02141</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">100</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">10</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82048</span>, std: <span class="number">0.02328</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">120</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">10</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81798</span>, std: <span class="number">0.02099</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">140</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">10</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82094</span>, std: <span class="number">0.02535</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">80</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">20</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82097</span>, std: <span class="number">0.02327</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">100</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">20</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82487</span>, std: <span class="number">0.02110</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">120</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">20</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82169</span>, std: <span class="number">0.02406</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">140</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">20</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82352</span>, std: <span class="number">0.02271</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">80</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">30</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82164</span>, std: <span class="number">0.02381</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">100</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">30</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82070</span>, std: <span class="number">0.02528</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">120</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">30</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82141</span>, std: <span class="number">0.02508</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">140</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">30</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82278</span>, std: <span class="number">0.02294</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">80</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">40</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82141</span>, std: <span class="number">0.02547</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">100</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">40</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82043</span>, std: <span class="number">0.02724</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">120</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">40</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82162</span>, std: <span class="number">0.02348</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">140</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">40</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82225</span>, std: <span class="number">0.02431</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">80</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">50</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82225</span>, std: <span class="number">0.02431</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">100</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">50</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81890</span>, std: <span class="number">0.02458</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">120</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">50</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81917</span>, std: <span class="number">0.02528</span>, params:&#123;<span class="string">'min_samples_split'</span>: <span class="number">140</span>, <span class="string">'min_samples_leaf'</span>: <span class="number">50</span>&#125;],</span><br><span class="line">&#123;<span class="string">'min_samples_leaf'</span>:<span class="number">20</span>, <span class="string">'min_samples_split'</span>: <span class="number">120</span>&#125;,</span><br><span class="line"><span class="number">0.8248650279471544</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#最后我们再对最大特征数max_features做调参:</span></span><br><span class="line">param_test4= &#123;<span class="string">'max_features'</span>:range(<span class="number">3</span>,<span class="number">11</span>,<span class="number">2</span>)&#125;</span><br><span class="line">gsearch4= GridSearchCV(estimator = RandomForestClassifier(n_estimators= <span class="number">60</span>,max_depth=<span class="number">13</span>, min_samples_split=<span class="number">120</span>,</span><br><span class="line">                                 min_samples_leaf=<span class="number">20</span> ,oob_score=<span class="keyword">True</span>, random_state=<span class="number">10</span>),</span><br><span class="line">   param_grid = param_test4,scoring=<span class="string">'roc_auc'</span>,iid=<span class="keyword">False</span>, cv=<span class="number">5</span>)</span><br><span class="line">gsearch4.fit(X,y)</span><br><span class="line">gsearch4.grid_scores_,gsearch4.best_params_, gsearch4.best_score_</span><br><span class="line"><span class="comment">#输出如下：</span></span><br><span class="line">([mean:<span class="number">0.81981</span>, std: <span class="number">0.02586</span>, params: &#123;<span class="string">'max_features'</span>: <span class="number">3</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81639</span>, std: <span class="number">0.02533</span>, params:&#123;<span class="string">'max_features'</span>: <span class="number">5</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.82487</span>, std: <span class="number">0.02110</span>, params:&#123;<span class="string">'max_features'</span>: <span class="number">7</span>&#125;,</span><br><span class="line">  mean: <span class="number">0.81704</span>, std: <span class="number">0.02209</span>, params:&#123;<span class="string">'max_features'</span>: <span class="number">9</span>&#125;],</span><br><span class="line">&#123;<span class="string">'max_features'</span>:<span class="number">7</span>&#125;,</span><br><span class="line"><span class="number">0.8248650279471544</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#用我们搜索到的最佳参数，我们再看看最终的模型拟合：</span></span><br><span class="line">rf2= RandomForestClassifier(n_estimators= <span class="number">60</span>, max_depth=<span class="number">13</span>, min_samples_split=<span class="number">120</span>,</span><br><span class="line">                                 min_samples_leaf=<span class="number">20</span>,max_features=<span class="number">7</span> ,oob_score=<span class="keyword">True</span>, random_state=<span class="number">10</span>)</span><br><span class="line">rf2.fit(X,y)</span><br><span class="line">printrf2.oob_score_</span><br><span class="line"><span class="comment">#此时的输出为：0.984</span></span><br><span class="line"><span class="comment">#可见此时模型的袋外分数基本没有提高，主要原因是0.984已经是一个很高的袋外分数了，如果想进一步需要提高模型的泛化能力，我们需要更多的数据。</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol>
<li><a href="https://blog.csdn.net/qq_32805671/article/details/84147415" target="_blank" rel="noopener">https://blog.csdn.net/qq_32805671/article/details/84147415</a></li>
<li><a href="https://www.kesci.com/home/project/5ae969440739c42faa1eab95" target="_blank" rel="noopener">https://www.kesci.com/home/project/5ae969440739c42faa1eab95</a></li>
<li><a href="https://www.jianshu.com/p/204fc7bdd077(https://blog.csdn.net/ssswill/article/details/85235074" target="_blank" rel="noopener">https://www.jianshu.com/p/204fc7bdd077(https://blog.csdn.net/ssswill/article/details/85235074</a>)</li>
<li><a href="http://lightgbm.apachecn.org/#/(http://www.zeroyx.com/index.php?r=site/art&amp;id=17&amp;title_id=105" target="_blank" rel="noopener">http://lightgbm.apachecn.org/#/(http://www.zeroyx.com/index.php?r=site/art&amp;id=17&amp;title_id=105</a>)</li>
<li><a href="https://blog.csdn.net/sinat_35512245/article/details/79700029(XGboost数据比赛实战之调参篇(完整流程" target="_blank" rel="noopener">https://blog.csdn.net/sinat_35512245/article/details/79700029(XGboost数据比赛实战之调参篇(完整流程</a>))</li>
<li><a href="https://blog.csdn.net/m_buddy/article/details/79341058(XGBoost数据训练小例子" target="_blank" rel="noopener">https://blog.csdn.net/m_buddy/article/details/79341058(XGBoost数据训练小例子</a>)</li>
<li><a href="https://blog.csdn.net/Eddy_zheng/article/details/50496186(机器学习xgboost实战—手写数字识别" target="_blank" rel="noopener">https://blog.csdn.net/Eddy_zheng/article/details/50496186(机器学习xgboost实战—手写数字识别</a>)</li>
<li><a href="https://blog.csdn.net/qq_27469517/article/details/76570168(XGBoost" target="_blank" rel="noopener">https://blog.csdn.net/qq_27469517/article/details/76570168(XGBoost</a> 与 信用卡诈骗数据集 三)</li>
<li><a href="https://blog.csdn.net/sinat_35512245/article/details/79668363(Scikit中的特征选择，XGboost进行回归预测，模型优化的实战" target="_blank" rel="noopener">https://blog.csdn.net/sinat_35512245/article/details/79668363(Scikit中的特征选择，XGboost进行回归预测，模型优化的实战</a>)</li>
<li><a href="https://blog.csdn.net/ChenVast/article/details/82107490(【机器学习】一些常用的回归模型实战（9种回归模型）" target="_blank" rel="noopener">https://blog.csdn.net/ChenVast/article/details/82107490(【机器学习】一些常用的回归模型实战（9种回归模型）</a>)</li>
<li><a href="https://blog.csdn.net/u010462995/article/details/70312702(随机森林回归应用中遇到的问题" target="_blank" rel="noopener">https://blog.csdn.net/u010462995/article/details/70312702(随机森林回归应用中遇到的问题</a>)</li>
<li><a href="https://cloud.tencent.com/developer/news/319575(XGBoost＋LightGBM＋LSTM：一次机器学习比赛中的高分模型方案" target="_blank" rel="noopener">https://cloud.tencent.com/developer/news/319575(XGBoost＋LightGBM＋LSTM：一次机器学习比赛中的高分模型方案</a>)</li>
<li><a href="https://www.jianshu.com/p/49ab87122562(catboost" target="_blank" rel="noopener">https://www.jianshu.com/p/49ab87122562(catboost</a> 实战)</li>
<li><a href="https://www.cnblogs.com/webRobot/p/9249906.html(sklearn实战-乳腺癌细胞数据挖掘" target="_blank" rel="noopener">https://www.cnblogs.com/webRobot/p/9249906.html(sklearn实战-乳腺癌细胞数据挖掘</a>)</li>
<li><a href="https://redstonewill.com/1565/" target="_blank" rel="noopener">https://redstonewill.com/1565/</a></li>
<li><a href="https://blog.csdn.net/linxid/article/details/80723811" target="_blank" rel="noopener">https://blog.csdn.net/linxid/article/details/80723811</a></li>
</ol>

      
    </div>
    
    
    

	<div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

      
    </div>
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/算法竞赛/" rel="tag"># 算法竞赛</a>
          
            <a href="/tags/日志/" rel="tag"># 日志</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/18/时间序列相关算法与分析步骤/" rel="next" title="时间序列相关算法与分析步骤(转)">
                <i class="fa fa-chevron-left"></i> 时间序列相关算法与分析步骤(转)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/05/22/Hadoop（一）/" rel="prev" title="Hadoop（一）">
                Hadoop（一） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container"></div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/xuanyi.jpg" alt="Yif Du">
            
              <p class="site-author-name" itemprop="name">Yif Du</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">162</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">135</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yifdu" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="17210240004@fudan.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#4月18日"><span class="nav-number">1.</span> <span class="nav-text">4月18日</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#User文件"><span class="nav-number">1.1.</span> <span class="nav-text">User文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ad-feature"><span class="nav-number">1.2.</span> <span class="nav-text">ad_feature</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ad-operation"><span class="nav-number">1.3.</span> <span class="nav-text">ad_operation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他"><span class="nav-number">1.4.</span> <span class="nav-text">其他</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TODO"><span class="nav-number">1.5.</span> <span class="nav-text">TODO</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4月19日"><span class="nav-number">2.</span> <span class="nav-text">4月19日</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Done"><span class="nav-number">2.1.</span> <span class="nav-text">Done</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#user"><span class="nav-number">2.1.1.</span> <span class="nav-text">user</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ad-feature-1"><span class="nav-number">2.1.2.</span> <span class="nav-text">ad_feature</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ad-op"><span class="nav-number">2.1.3.</span> <span class="nav-text">ad_op</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TODO-1"><span class="nav-number">2.2.</span> <span class="nav-text">TODO</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4月20日"><span class="nav-number">3.</span> <span class="nav-text">4月20日</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ad-op-1"><span class="nav-number">3.1.</span> <span class="nav-text">ad_op</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ad-feature-2"><span class="nav-number">3.2.</span> <span class="nav-text">ad_feature</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#用户画像的方法"><span class="nav-number">3.3.</span> <span class="nav-text">用户画像的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TODO-2"><span class="nav-number">3.4.</span> <span class="nav-text">TODO</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-25"><span class="nav-number">4.</span> <span class="nav-text">4.25</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#每天的数据已经得到"><span class="nav-number">4.1.</span> <span class="nav-text">每天的数据已经得到</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TODO-3"><span class="nav-number">4.2.</span> <span class="nav-text">TODO</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-27"><span class="nav-number">5.</span> <span class="nav-text">4.27</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#log"><span class="nav-number">5.1.</span> <span class="nav-text">log</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5月1日"><span class="nav-number">6.</span> <span class="nav-text">5月1日</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#比赛模型一般框架"><span class="nav-number">6.1.</span> <span class="nav-text">比赛模型一般框架</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Preprocess"><span class="nav-number">6.1.1.</span> <span class="nav-text">Preprocess</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LogisticRegression"><span class="nav-number">6.1.2.</span> <span class="nav-text">LogisticRegression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LightGBM"><span class="nav-number">6.1.3.</span> <span class="nav-text">LightGBM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#XGBoost"><span class="nav-number">6.1.4.</span> <span class="nav-text">XGBoost</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lightGBM"><span class="nav-number">6.2.</span> <span class="nav-text">lightGBM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#XGBoost-1"><span class="nav-number">6.3.</span> <span class="nav-text">XGBoost</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#XGBoost的原生版本参数介绍"><span class="nav-number">6.3.1.</span> <span class="nav-text">XGBoost的原生版本参数介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#General-Parameters"><span class="nav-number">6.3.1.1.</span> <span class="nav-text">General Parameters</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Parameters-for-Tree-Booster："><span class="nav-number">6.3.1.2.</span> <span class="nav-text">Parameters for Tree Booster：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#学习任务参数（Learning-Task-Parameters）"><span class="nav-number">6.3.1.3.</span> <span class="nav-text">学习任务参数（Learning Task Parameters）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用XGBoost原生版本模型"><span class="nav-number">6.3.2.</span> <span class="nav-text">使用XGBoost原生版本模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#XGBoost的sklearn接口版本参数介绍"><span class="nav-number">6.3.3.</span> <span class="nav-text">XGBoost的sklearn接口版本参数介绍</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Randomforest"><span class="nav-number">6.4.</span> <span class="nav-text">Randomforest</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">6.5.</span> <span class="nav-text">参考文献</span></a></li></ol></li></ol></div>
            

			
          </div>
        </section>
      <!--/noindex-->
      

      
	 

    </div>
		  
	  
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="heart">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yif Du</span>

  
</div>





        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
  <script src="/js/src/md5.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '7428ad62daef314bef06',
          clientSecret: '93cd3f4cd41cfc00c4760f65f8d895a66088ea5a',
          repo: 'Comments',
          owner: 'yifdu',
          admin: ['yifdu'],
          id: md5(location.pathname),
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')           
       </script>


  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  <style>
#selectionCopyright {
    position: absolute;
    display: none;
    background: rgba(244,67,54,.7);
    color: #fff;
    border-radius: 6px;
    box-shadow: none;
    border: none;
    font-size: 14px;
}
#selectionCopyright a{
    color:#fff;
    border-color: #fff;
}
#selectionCopyright::before {
    content: "";
    width: 0;
    height: 0;
    border-style: solid;
    border-width: 6px 8px 6px 0;
    border-color: transparent rgba(244,67,54,.7) transparent transparent;
    position: absolute;
    left: -8px;
    top:50%;
    transform:translateY(-50%);
}
</style>

<button id="selectionCopyright" disabled="disabled">本文发表于[<a href="http://yifdu.github.io">yifdu.github.io</a>]分享请注明来源！</button>

<script>
window.onload = function() {
    function selectText() {
        if (document.selection) { //IE浏览器下
            return document.selection.createRange().text; //返回选中的文字
        } else { //非IE浏览器下
            return window.getSelection().toString(); //返回选中的文字
        }
    }
    var content = document.getElementsByTagName("body")[0];
    var scTip = document.getElementById('selectionCopyright');

    content.onmouseup = function(ev) { //设定一个onmouseup事件
        var ev = ev || window.event;
        var left = ev.clientX;//获取鼠标相对浏览器可视区域左上角水平距离距离
        var top = ev.clientY;//获取鼠标相对浏览器可视区域左上角垂直距离距离
        var xScroll = Math.max(document.body.scrollLeft, document.documentElement.scrollLeft);//获取文档水平滚动距离
        var yScroll = Math.max(document.body.scrollTop, document.documentElement.scrollTop);//获取文档垂直滚动距离
        if (selectText().length > 0) {
            setTimeout(function() { //设定一个定时器
                scTip.style.display = 'inline-block';
                scTip.style.left = left + xScroll + 15 + 'px';//鼠标当前x值
                scTip.style.top = top + yScroll - 15 + 'px';//鼠标当前y值
            }, 100);
        } else {
            scTip.style.display = 'none';
        }
    };

    content.onclick = function(ev) {
        var ev = ev || window.event;
        ev.cancelBubble = true;
    };
    document.onclick = function() {
        scTip.style.display = 'none';
    };
};
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-miku"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
