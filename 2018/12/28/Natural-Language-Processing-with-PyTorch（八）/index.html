<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<meta name="theme-color" content="#222">
<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！请问博主爸爸');
                history.back();
            }
        }
    })();
</script>


  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "258f1ebb"
    });
  daovoice('update');
  </script>









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="NLP,Pytorch,">










<meta name="description" content="由Yif翻译，仅供学习严禁任何商业用途 Chapter 8. Advanced Sequence Modeling for Natural Language Processing在本章中，我们以第六章和第七章讨论的序列建模概念为基础，将它们扩展到序列到序列建模的领域，其中模型以一个序列作为输入，并产生另一个可能不同长度的序列作为输出。序列对序列问题的例子随处可见。例如，给定一封电子邮件，我们可能希">
<meta name="keywords" content="NLP,Pytorch">
<meta property="og:type" content="article">
<meta property="og:title" content="Natural-Language-Processing-with-PyTorch（八）">
<meta property="og:url" content="http://yifdu.github.io/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/index.html">
<meta property="og:site_name" content="深度菜鸟">
<meta property="og:description" content="由Yif翻译，仅供学习严禁任何商业用途 Chapter 8. Advanced Sequence Modeling for Natural Language Processing在本章中，我们以第六章和第七章讨论的序列建模概念为基础，将它们扩展到序列到序列建模的领域，其中模型以一个序列作为输入，并产生另一个可能不同长度的序列作为输出。序列对序列问题的例子随处可见。例如，给定一封电子邮件，我们可能希">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545023935255&di=c2469985994fb00217b96200714f5f27&imgtype=0&src=http%3A%2F%2Fimage.tupian114.com%2F20120504%2F2012050420332255.jpg">
<meta property="og:updated_time" content="2018-12-28T03:47:48.912Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Natural-Language-Processing-with-PyTorch（八）">
<meta name="twitter:description" content="由Yif翻译，仅供学习严禁任何商业用途 Chapter 8. Advanced Sequence Modeling for Natural Language Processing在本章中，我们以第六章和第七章讨论的序列建模概念为基础，将它们扩展到序列到序列建模的领域，其中模型以一个序列作为输入，并产生另一个可能不同长度的序列作为输出。序列对序列问题的例子随处可见。例如，给定一封电子邮件，我们可能希">
<meta name="twitter:image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545023935255&di=c2469985994fb00217b96200714f5f27&imgtype=0&src=http%3A%2F%2Fimage.tupian114.com%2F20120504%2F2012050420332255.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yifdu.github.io/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/">





  <title>Natural-Language-Processing-with-PyTorch（八） | 深度菜鸟</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">深度菜鸟</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-resume">
          <a href="/resume/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            简历
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yifdu.github.io/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yif Du">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/xuanyi.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="深度菜鸟">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Natural-Language-Processing-with-PyTorch（八）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-28T09:37:03+08:00">
                2018-12-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Pytorch/" itemprop="url" rel="index">
                    <span itemprop="name">Pytorch</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Pytorch/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读数
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  12k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  49 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
        <div class="post-gallery" itemscope="" itemtype="http://schema.org/ImageGallery">
          
          
            <div class="post-gallery-row">
              <a class="post-gallery-img fancybox" href="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545023935255&di=c2469985994fb00217b96200714f5f27&imgtype=0&src=http%3A%2F%2Fimage.tupian114.com%2F20120504%2F2012050420332255.jpg" rel="gallery_cjw2e8j9100lbpgwah5mdt01e" itemscope="" itemtype="http://schema.org/ImageObject" itemprop="url">
                <img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545023935255&di=c2469985994fb00217b96200714f5f27&imgtype=0&src=http%3A%2F%2Fimage.tupian114.com%2F20120504%2F2012050420332255.jpg" itemprop="contentUrl">
              </a>
            
          

          
          </div>
        </div>
      

      
        <p><strong>由Yif翻译，仅供学习严禁任何商业用途</strong></p>
<h1 id="Chapter-8-Advanced-Sequence-Modeling-for-Natural-Language-Processing"><a href="#Chapter-8-Advanced-Sequence-Modeling-for-Natural-Language-Processing" class="headerlink" title="Chapter 8. Advanced Sequence Modeling for Natural Language Processing"></a>Chapter 8. Advanced Sequence Modeling for Natural Language Processing</h1><p>在本章中，我们以第六章和第七章讨论的序列建模概念为基础，将它们扩展到序列到序列建模的领域，其中模型以一个序列作为输入，并产生另一个可能不同长度的序列作为输出。序列对序列问题的例子随处可见。例如，给定一封电子邮件，我们可能希望预测响应。给出一个法语句子，预测它的英语翻译。或者，给定一篇文章，写一篇摘要。我们还讨论了序列模型的结构变体，特别是双向模型。为了最大限度地利用序列表示，我们介绍了注意机制并对其进行了深入讨论。最后，本章以实现本章描述的概念的神经机器翻译的详细演练结束。</p>
<h2 id="Sequence-to-Sequence-Models-Encoder–Decoder-Models-and-Conditioned-Generation"><a href="#Sequence-to-Sequence-Models-Encoder–Decoder-Models-and-Conditioned-Generation" class="headerlink" title="Sequence-to-Sequence Models, Encoder–Decoder Models, and Conditioned Generation"></a>Sequence-to-Sequence Models, Encoder–Decoder Models, and Conditioned Generation</h2><p>序列到序列(S2S)模型是一种称为编码器-解码器模型的一般模型家族的特殊情况。编码器-解码器模型是两个模型(图8-1)的组合，一个是“编码器”模型，另一个是“解码器”模型，这两个模型通常是联合训练的。编码器模型需要输入并产生一个编码或表示ϕ的输入,通常一个向量。编码器的目标是捕获与当前任务相关的输入的重要属性。解码器的目标是获取编码输入并产生所需的输出。通过对编码器和解码器的理解，我们将S2S模型定义为编码器-解码器模型，其中编码器和解码器是序列模型，输入和输出都是序列，可能长度不同。<br><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/S2S.png" alt="S2S" title="图8-1编码器-解码器模型是由两个联合训练的模型组成的。编码器产生一个代表或编码输入ϕ的解码器用来产生一个输出。"><br>一种查看编码器-解码器模型的方法是将其作为称为条件生成模型的模型的特殊情况。在conditioned-generation中,替代输入表示ϕ,一般条件上下文c影响译码器产生一个输出。当条件上下文c来自编码器模型时，条件生成与编码器-解码器模型相同。并非所有的条件生成模型都是编码器-解码器模型，因为条件上下文可能来自结构化源。以天气报告生成器为例。温度、湿度、风速和风向的值可以“调节”解码器，生成文本天气报告。在“模型2:条件性姓氏生成模型”中，我们看到了一个基于国籍条件性姓氏生成的例子。图8-2展示了一些条件生成模型的实际示例。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/example.png" alt="example" title="图8 - 2。用编码器-解码器模型解决的任务示例。（一）机器翻译:输入A为法语句，输出B为英语句。（二）邮件回复建议:输入A为邮件文本;输出B是许多可能的答复之一。在（III）中，给出了一个更复杂的例子。在这里，聊天机器人正在回答以a为标记的关于输入图像（a &#39;）的问题，它将响应B的生成条件设置为a和a的编码。所有这些任务也可以看作是条件生成任务。"></p>
<p>在这一章中，我们深入研究了S2S模型，并在机器翻译任务的背景下进行了说明。考虑一个“智能”的iOS/Android键盘，它可以在你打字时自动将文本转换成表情符号。如果你输入“omg!”房子着火了!，你希望键盘输出类似内联输出的内容。注意，输出的长度(4个令牌)与输入的长度(6个令牌)不同。输出和输入之间的映射称为对齐，如图8-3所示。<br><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/example2.png" alt="example2" title="图8 - 3。表情符号翻译是一个S2S预测问题:两个序列中符号之间的对齐表示翻译等值。"><br>同样，在本例中，输入中的单个令牌可以在输出中生成零个或多个令牌。传统上，许多解决S2S问题的方法都是尝试使用工程和启发式重统计方法。虽然回顾这些方法超出了本章和本书的范围，但是我们建议您阅读Koehn(2009)并参考statmt.org中的参考资料。</p>
<p>在第6章中，我们学习了序列模型如何将任意长度的序列编码成向量。在第7章中，我们看到单个向量如何使递归神经网络(RNN)有条件地产生不同的姓氏。S2S模型是这些概念的自然延伸。</p>
<p>图8 - 4显示了编码器整个输入一个表示“编码”,ϕ,条件解码器生成正确的输出。您可以使用任何RNN作为编码器，无论是Elman RNN, Long - term Memory (LSTM)，还是gate Unit (GRU)，。在接下来的两个部分中，我们将介绍现代S2S模型的两个重要组件。首先，我们引入了双向递归模型，该模型将向前和向后传递组合在一个序列上，以创建更丰富的表示。然后，在“从序列中获取更多信息:注意力”中，我们介绍并考察了注意力机制，它在关注与任务相关的输入的不同部分时非常有用。这两个部分对于构建基于S2S模型的解决方案都非常重要。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/example3.png" alt="example3" title="图8-4. S2S模式，用于将英语翻译成表情符号。"></p>
<h2 id="Capturing-More-from-a-Sequence-Bidirectional-Recurrent-Models"><a href="#Capturing-More-from-a-Sequence-Bidirectional-Recurrent-Models" class="headerlink" title="Capturing More from a Sequence: Bidirectional Recurrent Models"></a>Capturing More from a Sequence: Bidirectional Recurrent Models</h2><p>理解递归模型的一种方法是把它看作一个将序列编码为向量的黑盒子。在建模序列时，不仅要观察过去的单词，而且还要观察将来出现的单词。考虑以下句子:</p>
<p>The man who hunts ducks out on the weekends.<br>如果模型只从左到右观察，那么“duck”的表示将不同于从右到左观察单词的模型。人类一直在做这种回溯性的更新。</p>
<p>因此，如果把过去和未来的信息结合在一起，就能够有力地按顺序表示一个单词的意思。这就是双向递归模型的目标。递归家族的任何模型，如Elmann RNNs或LSTMs或GRUs，都可以用于这种双向表达。与第6章和第7章中的单向模型一样，双向模型可以用于分类和序列标记设置，我们需要预测输入中每个单词的一个标签。图8-5和图8-6详细说明了这一点。在图8-6中，$ϕ_{love}$是表示、编码或该时刻网络的“隐藏的状态”,当输入的词是”love”步。当我们讨论注意力时，这种状态信息在“从一个序列中获取更多信息:注意力”中变得很重要。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/Attention.png" alt="Attention" title="图8-5. 用于序列分类的双向RNN模型。注意模型“读取”这句话在这两个方向,并产生一个句子表示ϕ的作文向前和向后表示。这里没有显示的是由线性层和softmax组成的最终分类层。"><br><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/Attention2.png" alt="Attention2" title="图8-6。用于序列标记的双向递归模型。注意输入中的每个单词是如何存在“前向”表示和“后向”表示，它们被连接起来以产生所讨论单词的最终表示。这里没有显示的是最终分类层，在每个时间步骤由线性层和softmax组成。"></p>
<h2 id="Capturing-More-from-a-Sequence-Attention"><a href="#Capturing-More-from-a-Sequence-Attention" class="headerlink" title="Capturing More from a Sequence: Attention"></a>Capturing More from a Sequence: Attention</h2><p>“序列到序列模型，编码器 - 解码器模型和条件生成”中引入的S2S模型公式的一个问题是它将整个输入句子变成单个矢量（“编码”）φ并使用该编码生成输出，如图8-7所示。虽然这可能适用于非常短的句子，但对于长句，这样的模型无法捕获整个输入中的信息;例如，见Bengio等。 （1994）和Le和Zuidema（2016）。这是仅使用最终隐藏状态作为编码的限制。长输入的另一个问题是，当长时间输入反向传播时，梯度消失，使训练变得困难。<br><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/Attention3.png" alt="Attention3" title="图8-7.使用编码器 - 解码器模型将长法语句子翻译成英语。最终表示φ无法捕获输入中的长程依赖性并使训练变得困难。"><br>对于曾尝试翻译的双语/多语言读者来说，这种首先编码然后解码的过程可能会有点奇怪。作为人类，我们通常不会提炼句子的含义并从意义中产生翻译。对于图8-7中的示例，“pour” we know there will be a “for”; similarly “breakfast” is on our mind when we see “petit-déjeuner,” and so on. In other words, our mind focuses on the relevant parts of the input while producing output. This phenomenon is called attention. Attention has been widely studied in neuroscience and other allied fields, and it is what makes us quite successful despite having limited memories. Attention happens everywhere. In fact, it is happening right now to you, dear reader. Each. Word. You. Are. Reading. Now. Is. Being. Attended. To. Even if you have an exceptional memory, you’re probably not reading this entire book as a string. When you are reading a word, you are paying attention to the neighboring word, possibly the topic of the Section and Chapter, and so on.</p>
<p>以类似的方式，我们希望序列生成模型将注意力集中到输入的不同部分，而不仅仅是整个输入的最终总结。这就是注意力机制。第一个包含自然语言处理(NLP)注意概念的模型是Bahdanau等人(2015)的机器翻译模型。从那时起，人们提出了几种注意机制和提高注意的方法。在本节中，我们将回顾一些基本的注意机制，并介绍一些与注意相关的术语。事实证明，注意力对于改进输入和输出复杂的深度学习系统非常有用。事实上，Bahdanau等人通过“BLEU score”(我们在“评估序列生成模型”中看到的)来衡量机器翻译系统的性能，当输入变长时，机器翻译系统在没有注意机制的情况下会下降，如图8-8所示。增加注意力可以解决问题。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/example4.png" alt="example4" title="图8-8. 为什么需要注意？该图表显示了具有（RNNsearch-30，RNNsearch-50）和没有（RNNenc-30，RNNenc-50）注意力的机器翻译系统的BLEU分数的变化。 RNN * -30和RNN * -50系统分别用长达30和50个单词的句子进行训练。在机器翻译系统中，没有注意，系统的性能随着句子长度的增加而降低。通过注意，较长句子的翻译得到改善，但机器翻译性能的稳定性与训练它的句子的长度有关。 （图由Bahdanau等人提供[2015]）"></p>
<h3 id="Attention-in-Deep-Neural-Networks"><a href="#Attention-in-Deep-Neural-Networks" class="headerlink" title="Attention in Deep Neural Networks"></a>Attention in Deep Neural Networks</h3><p>注意力是一种通用的机制，可以用于本书前面讨论过的任何一种模型。但我们在这里用编码器-解码器模型来描述它，因为这些模型是注意力机制真正发挥作用的地方。考虑一个S2S模型。回想一下,在一个典型的S2S模型中,每个时间步生成一个隐藏的状态表示,表示$ϕ_w$,特定于该时间步的编码器。(如图8-6所示。)为了引起注意，我们不仅要考虑编码器的最终隐藏状态，还要考虑每个中间步骤的隐藏状态。这些编码器隐藏状态，在某种程度上是非信息性的，称为值。在某些情况下，编码器的隐藏状态也称为键。注意力还取决于调用查询的解码器的前一个隐藏状态。图8-9说明了时间步骤0的所有这些。时间步长t=0的查询向量是一个固定的超参数。注意由一个向量来表示，这个向量的维数与它所关注的值的维数相同。这被称为注意力向量，或注意力权重，有时也称为对齐。注意力权重与编码器状态(“值”)相结合，生成一个有时也称为瞥见的上下文向量。这个上下文向量成为解码器的输入，而不是完整的句子编码。使用兼容性函数更新下一个时间步骤的注意向量。相容函数的确切性质取决于所使用的注意机制。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/Encoder_Decoder.png" alt="Encoder_Decoder" title="图8-9. 时间步长t=0时的注意。预测的输出是“对”和关注块考虑隐状态的编码器ϕw所有输入的单词。要详细了解这个图（我们强烈推荐），请参见“深度神经网络中的注意”。"><br>有几种方法可以实现关注。最简单和最常用的是内容感知机制。您可以在“示例：神经机器翻译”中看到内容感知注意力。另一种流行的注意机制是位置感知注意力，它仅依赖于查询向量和密钥。注意权重通常是0到1之间的浮点值。这称为软注意。相反，可以学习二进制0/1向量以引起注意。这被称为硬关注。</p>
<p>图8-9中所示的注意机制取决于输入中所有时间步长的编码器状态。这也被称为全球关注。相反，对于本地注意力，您可以设计一种注意机制，该机制仅依赖于当前时间步长周围的输入窗口。</p>
<p>有时，特别是在机器翻译中，可以明确地提供对齐信息作为训练数据的一部分。在这种情况下，可以设计受监督的注意力来使用共同训练的单独神经网络来学习注意力功能。对于诸如文档之类的大型输入，可以设计粗粒度到细粒度的注意机制，也称为分级注意，不仅关注立即输入，而且还考虑文档的结构 - 段落，部分，章节等。<br>Vaswani等人对变压器网络的研究。 （2017），引入多头注意，其中多个注意向量用于跟踪输入的不同区域。他们还普及了自我关注的概念，这是一种机制，通过该机制，模型可以了解输入的哪些区域相互影响。</p>
<p>当输入是多模式时 - 例如，图像和语音 - 可以设计多模式注意力。关于注意力的文献虽然很新，但已经非常广泛，这表明了这一主题的重要性。详细介绍它们的每一个都超出了本书的范围，我们将引导您到Luong，Pham和Manning（2011）以及Vaswani等人。 （2017）作为起点。</p>
<h2 id="Evaluating-Sequence-Generation-Models"><a href="#Evaluating-Sequence-Generation-Models" class="headerlink" title="Evaluating Sequence Generation Models"></a>Evaluating Sequence Generation Models</h2><p>当生成任务中可以看到多个有效答案时，精度，召回，准确度和F1等分类指标无法帮助模型 - 单个法语句子可以有多个英语翻译。序列模型根据称为参考输出的预期输出进行评估。在比较不同的模型时，我们使用分数来表明模型输出的“良好”与参考的接近程度。例如，在像机器翻译这样的任务中，如果一个模型只有一个单词关闭，我们可能不希望像另一个产生完全无法理解的答案的模型那样惩罚该模型。单个输入示例可以有多个参考输出。例如，对于特定的法语句子，可能存在多个有效的英语翻译，使用略微不同的单词。序列生成模型有两种评估：人工评估和自动评估。</p>
<p>人体评估涉及一个或多个人类受试者，要么对模型输出给出“竖起拇指”或“拇指向下”评级，要么进行编辑以纠正翻译。这导致了一个简单的“错误率”，它非常接近系统输出与人工任务相关的最终目标。人类评价很重要，但是很少使用，因为人类注释者往往是缓慢，昂贵和难以获得的。最后，人类也可能彼此不一致，并且，与任何其他金标准一样，人类评估与注释器间协议率配对。测量注释器间协议率也是另一个昂贵的主张。一种常见的人类评估指标是人为目标翻译错误率（HTER）。 HTER是一个加权编辑距离，由人类为了合理充分的意义和流畅性而“修复”翻译输出而进行的插入，删除和转置次数计算得出（参见图8-10）。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/Just.png" alt="Just" title="图8-10. 翻译任务的人工评估。（由菲利普·科恩）。"><br>另一方面，自动评估操作简单快捷。有两种度量标准可用于自动评估生成的序列。我们再次使用机器翻译作为示例，但这些指标也适用于涉及生成序列的任何任务。这些指标包括基于ngram重叠的指标和困惑。基于Ngram重叠的度量倾向于通过使用ngram重叠统计来计算得分来测量输出相对于参考的接近程度。 BLEU，ROUGE和METEOR是基于ngram重叠的度量的示例。其中，BLEU经受了时间的考验，成为机器翻译文献中的衡量标准.6 BLEU代表“BiLingual Evaluation Understudy”。我们跳过BLEU的确切表述，并建议您阅读Papineni等人。 （2002年）。出于实际目的，我们使用像NLTK7或SacreBLEU8这样的包来计算分数。当参考数据可用时，BLEU本身的计算非常快速和容易。</p>
<p>困惑是基于信息理论的另一种自动评估指标，您可以将其应用于可以测量输出序列概率的任何情况。对于序列x，如果P（x）是序列的概率，则困惑定义如下：</p>
<script type="math/tex; mode=display">Perplexity(x)=2^{-P(x)logP(x)}</script><p>这为我们提供了一种比较不同序列生成模型的简单方法 - 测量保持数据集的模型的困惑度。虽然这很容易计算，但是当用于序列生成评估时，困惑会有许多问题。首先，它是一个膨胀的指标。请注意，困惑的表达式涉及取幂。因此，模型性能（可能性）的微小差异可能导致困惑的巨大差异，从而产生重大进展的错觉。其次，对困惑的改变可能不会转化为通过其他指标观察到的模型错误率的相应变化。最后，就像BLEU和其他基于ngram的指标一样，困惑的改善可能不会转化为人类判断的可察觉的改进。</p>
<p>在下一节中，我们将跟进机器翻译示例，并通过PyTorch实现将这些概念巧妙地结合在一起。</p>
<h2 id="Example-Neural-Machine-Translation"><a href="#Example-Neural-Machine-Translation" class="headerlink" title="Example: Neural Machine Translation"></a>Example: Neural Machine Translation</h2><p>在本例中，我们将介绍S2S模型最常用的实现:机器翻译。随着深度学习在2010年代早期的流行，很明显，使用嵌入式词汇和RNNs是一种非常强大的两种语言之间的翻译方法——只要有足够的数据。引入“序列生成模型评价”中的注意机制，进一步完善了机器翻译模型。在这一部分，我们描述了一个基于Luong, Pham, and Manning(2015)的实现，它简化了S2S模型中的注意方法。</p>
<p>我们首先概述数据集和神经机器翻译所需的特殊记账类型。数据集是一个平行的语料库;它由成对的英语句子和相应的法语翻译组成。因为我们正在处理两个可能不同长度的序列，所以我们需要跟踪输入序列和输出序列的最大长度和词汇。在大多数情况下，这个例子是对完整读者在前几章中所看到的内容的直接扩展。</p>
<p>在覆盖数据集和簿记数据结构之后，我们通过参与源序列中的不同位置来遍历模型以及它如何生成目标序列。我们模型中的编码器使用双向GRU（bi-GRU）来计算源序列中每个位置的向量，这些向量由序列的所有部分通知。为此，我们使用PyTorch的PackedSequences数据结构。我们在“NMT模型中的编码和解码”中更深入地介绍了这一点。在“从序列捕获更多：注意力”中讨论的注意机制应用于bi-GRU的输出并用于调节目标序列生成。我们讨论模型的结果以及在“训练常规和结果”中可以改进的方法。</p>
<h3 id="Machine-Translation-Dataset"><a href="#Machine-Translation-Dataset" class="headerlink" title="Machine Translation Dataset"></a>Machine Translation Dataset</h3><p>对于此示例，我们使用来自Tatoeba Project的英语 - 法语句子对的数据集.数据预处理首先将所有句子设为小写，并将NLTK的英语和法语标记符应用于每个句子对。接下来，我们应用NLTK的特定于语言的单词标记生成器来创建标记列表。即使我们进行了进一步的计算，我们将在下一段中描述，但这个标记列表是一个预处理的数据集。</p>
<h2 id="除了刚刚描述的标准预处理之外，我们还使用指定的语法模式列表来选择数据的子集，以简化学习问题。从本质上讲，这意味着我们将数据范围缩小到只有有限范围的句法模式。反过来，这意味着在训练期间，模型将看到更少的变化，并在更短的训练时间内具有更高的性能。"><a href="#除了刚刚描述的标准预处理之外，我们还使用指定的语法模式列表来选择数据的子集，以简化学习问题。从本质上讲，这意味着我们将数据范围缩小到只有有限范围的句法模式。反过来，这意味着在训练期间，模型将看到更少的变化，并在更短的训练时间内具有更高的性能。" class="headerlink" title="除了刚刚描述的标准预处理之外，我们还使用指定的语法模式列表来选择数据的子集，以简化学习问题。从本质上讲，这意味着我们将数据范围缩小到只有有限范围的句法模式。反过来，这意味着在训练期间，模型将看到更少的变化，并在更短的训练时间内具有更高的性能。"></a>除了刚刚描述的标准预处理之外，我们还使用指定的语法模式列表来选择数据的子集，以简化学习问题。从本质上讲，这意味着我们将数据范围缩小到只有有限范围的句法模式。反过来，这意味着在训练期间，模型将看到更少的变化，并在更短的训练时间内具有更高的性能。</h2><p>Note</p>
<h2 id="在构建新模型和尝试新体系结构时，您应该在建模选择和评估这些选择之间实现更快的迭代周期。"><a href="#在构建新模型和尝试新体系结构时，您应该在建模选择和评估这些选择之间实现更快的迭代周期。" class="headerlink" title="在构建新模型和尝试新体系结构时，您应该在建模选择和评估这些选择之间实现更快的迭代周期。"></a>在构建新模型和尝试新体系结构时，您应该在建模选择和评估这些选择之间实现更快的迭代周期。</h2><p>我们用来选择数据子集的句法模式是以“I am”，“he is ”，“she is”，“they are”，“you are”或“we are”开头的英语句子。数据集从135,842个句子对减少到13,062个句子对，系数为10.为了最终确定学习设置，我们将剩余的13,062个句子对分为70％训练，15％验证和15％测试分裂。从刚刚列出的语法开始的每个句子的比例通过首先按句子开始分组，从这些组创建分割，然后合并每个组的分割来保持不变。</p>
<h3 id="A-Vectorization-Pipeline-for-NMT"><a href="#A-Vectorization-Pipeline-for-NMT" class="headerlink" title="A Vectorization Pipeline for NMT"></a>A Vectorization Pipeline for NMT</h3><p>对源英语和目标法语句子进行矢量化需要比前面章节中看到的更复杂的管道。复杂性增加有两个原因。首先，源序列和目标序列在模型中具有不同的角色，属于不同的语言，并且以两种不同的方式进行矢量化。其次，作为使用PyTorch的PackedSequences的先决条件，我们按源句的长度对每个小批量进行排序。为了准备这两个复杂性，NMTVectorizer实例化了两个独立的SequenceVocabulary对象和两个最大序列长度的测量，如例8-1所示。<br>Example 8-1. Constructing the NMTVectorizer<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">class NMTVectorizer(object):</span><br><span class="line">    &quot;&quot;&quot; The Vectorizer which coordinates the Vocabularies and puts them to use&quot;&quot;&quot;</span><br><span class="line">    def __init__(self, source_vocab, target_vocab, max_source_length,</span><br><span class="line">                 max_target_length):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Args:</span><br><span class="line">            source_vocab (SequenceVocabulary): maps source words to integers</span><br><span class="line">            target_vocab (SequenceVocabulary): maps target words to integers</span><br><span class="line">            max_source_length (int): the longest sequence in the source dataset</span><br><span class="line">            max_target_length (int): the longest sequence in the target dataset</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.source_vocab = source_vocab</span><br><span class="line">        self.target_vocab = target_vocab</span><br><span class="line"></span><br><span class="line">        self.max_source_length = max_source_length</span><br><span class="line">        self.max_target_length = max_target_length</span><br><span class="line"></span><br><span class="line">    @classmethod</span><br><span class="line">    def from_dataframe(cls, bitext_df):</span><br><span class="line">        &quot;&quot;&quot;Instantiate the vectorizer from the dataset dataframe</span><br><span class="line"></span><br><span class="line">        Args:</span><br><span class="line">            bitext_df (pandas.DataFrame): the parallel text dataset</span><br><span class="line">        Returns:</span><br><span class="line">            an instance of the NMTVectorizer</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        source_vocab = SequenceVocabulary()</span><br><span class="line">        target_vocab = SequenceVocabulary()</span><br><span class="line">        max_source_length, max_target_length = 0, 0</span><br><span class="line"></span><br><span class="line">        for _, row in bitext_df.iterrows():</span><br><span class="line">            source_tokens = row[&quot;source_language&quot;].split(&quot; &quot;)</span><br><span class="line">            if len(source_tokens) &gt; max_source_length:</span><br><span class="line">                max_source_length = len(source_tokens)</span><br><span class="line">            for token in source_tokens:</span><br><span class="line">                source_vocab.add_token(token)</span><br><span class="line"></span><br><span class="line">            target_tokens = row[&quot;target_language&quot;].split(&quot; &quot;)</span><br><span class="line">            if len(target_tokens) &gt; max_target_length:</span><br><span class="line">                max_target_length = len(target_tokens)</span><br><span class="line">            for token in target_tokens:</span><br><span class="line">                target_vocab.add_token(token)</span><br><span class="line"></span><br><span class="line">        return cls(source_vocab, target_vocab, max_source_length,</span><br><span class="line">                   max_target_length</span><br></pre></td></tr></table></figure></p>
<p>复杂性的第一个增加是处理源序列和目标序列的不同方式。源序列在开始时插入BEGIN-OF-SEQUENCE进行矢量化，并将END-OF-SEQUENCE标记添加到结尾。该模型使用bi-GRU为源句子中的每个标记创建摘要向量，并且这些摘要向量极大地受益于具有句子边界的指示。相反，目标序列被矢量化为两个副本，偏移一个标记：第一个副本需要BEGIN-OF-SEQUENCE标记，第二个副本需要END-OF-SEQUENCE标记。如果您从第7章回忆起来，序列预测任务需要在每个时间步骤观察输入令牌和输出令牌。 S2S模型中的解码器正在执行此任务，但增加了编码器上下文的可用性。为了解决这种复杂性，我们制定了核心矢量化方法_vectorize，无论它是源索引还是目标索引都无关紧要。然后，编写两个方法来分别处理源索引和目标索引。最后，使用NMTVectorizer.vectorize方法协调这些索引集，该方法是数据集调用的方法。例8-2显示了代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NMTVectorizer</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">""" The Vectorizer which coordinates the Vocabularies and puts them to use"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_vectorize</span><span class="params">(self, indices, vector_length=<span class="number">-1</span>, mask_index=<span class="number">0</span>)</span>:</span></span><br><span class="line">        <span class="string">"""Vectorize the provided indices</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            indices (list): a list of integers that represent a sequence</span></span><br><span class="line"><span class="string">            vector_length (int): an argument for forcing the length of index vector</span></span><br><span class="line"><span class="string">            mask_index (int): the mask_index to use; almost always 0</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> vector_length &lt; <span class="number">0</span>:</span><br><span class="line">            vector_length = len(indices)</span><br><span class="line">        vector = np.zeros(vector_length, dtype=np.int64)</span><br><span class="line">        vector[:len(indices)] = indices</span><br><span class="line">        vector[len(indices):] = mask_index</span><br><span class="line">        <span class="keyword">return</span> vector</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_source_indices</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        <span class="string">"""Return the vectorized source text</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            text (str): the source text; tokens should be separated by spaces</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            indices (list): list of integers representing the text</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        indices = [self.source_vocab.begin_seq_index]</span><br><span class="line">        indices.extend(self.source_vocab.lookup_token(token)</span><br><span class="line">                       <span class="keyword">for</span> token <span class="keyword">in</span> text.split(<span class="string">" "</span>))</span><br><span class="line">        indices.append(self.source_vocab.end_seq_index)</span><br><span class="line">        <span class="keyword">return</span> indices</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_target_indices</span><span class="params">(self, text)</span>:</span></span><br><span class="line">        <span class="string">"""Return the vectorized source text</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            text (str): the source text; tokens should be separated by spaces</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            a tuple: (x_indices, y_indices)</span></span><br><span class="line"><span class="string">                x_indices (list): list of ints; observations in target decoder</span></span><br><span class="line"><span class="string">                y_indices (list): list of ints; predictions in target decoder</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        indices = [self.target_vocab.lookup_token(token)</span><br><span class="line">                   <span class="keyword">for</span> token <span class="keyword">in</span> text.split(<span class="string">" "</span>)]</span><br><span class="line">        x_indices = [self.target_vocab.begin_seq_index] + indices</span><br><span class="line">        y_indices = indices + [self.target_vocab.end_seq_index]</span><br><span class="line">        <span class="keyword">return</span> x_indices, y_indices</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">vectorize</span><span class="params">(self, source_text, target_text, use_dataset_max_lengths=True)</span>:</span></span><br><span class="line">        <span class="string">"""Return the vectorized source and target text</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            source_text (str): text from the source language</span></span><br><span class="line"><span class="string">            target_text (str): text from the target language</span></span><br><span class="line"><span class="string">            use_dataset_max_lengths (bool): whether to use the max vector lengths</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            The vectorized data point as a dictionary with the keys:</span></span><br><span class="line"><span class="string">                source_vector, target_x_vector, target_y_vector, source_length</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        source_vector_length = <span class="number">-1</span></span><br><span class="line">        target_vector_length = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_dataset_max_lengths:</span><br><span class="line">            source_vector_length = self.max_source_length + <span class="number">2</span></span><br><span class="line">            target_vector_length = self.max_target_length + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        source_indices = self._get_source_indices(source_text)</span><br><span class="line">        source_vector = self._vectorize(source_indices,</span><br><span class="line">                                        vector_length=source_vector_length,</span><br><span class="line">                                        mask_index=self.source_vocab.mask_index)</span><br><span class="line"></span><br><span class="line">        target_x_indices, target_y_indices = self._get_target_indices(target_text)</span><br><span class="line">        target_x_vector = self._vectorize(target_x_indices,</span><br><span class="line">                                        vector_length=target_vector_length,</span><br><span class="line">                                        mask_index=self.target_vocab.mask_index)</span><br><span class="line">        target_y_vector = self._vectorize(target_y_indices,</span><br><span class="line">                                        vector_length=target_vector_length,</span><br><span class="line">                                        mask_index=self.target_vocab.mask_index)</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">"source_vector"</span>: source_vector,</span><br><span class="line">                <span class="string">"target_x_vector"</span>: target_x_vector,</span><br><span class="line">                <span class="string">"target_y_vector"</span>: target_y_vector,</span><br><span class="line">                <span class="string">"source_length"</span>: len(source_indices)&#125;</span><br></pre></td></tr></table></figure>
<p>复杂性的第二次增加再次来自源序列。为了使用bi-GRU对源序列进行编码，我们使用PyTorch的PackedSequences数据结构。通常，可变长度序列的小批量数字表示为整数矩阵中的行，其中每个序列左对齐并且零填充以适应可变长度。 PackedSequences数据结构通过在每个时间步，一个接一个地连接序列的数据并知道每个时间步的序列数，将可变长度序列表示为数组，如图8-11所示。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/example5.png" alt="example5" title="图8-11。填充序列矩阵及其长度显示在左侧。填充矩阵是通过用0（零）对它们进行右边填充并将它们堆叠为行向量来表示可变长度序列的标准方式。在PyTorch语义中，我们可以将填充序列打包成一个terser表示，Packed Sequences，右侧显示batch_sizes。该表示允许GPU通过跟踪每个时间步中有多少序列（batch_sizes）来逐步执行序列。"></p>
<p>创建PackedSequence有两个先决条件：了解每个序列的长度，并按源序列的长度按降序对序列进行排序。为了反映这个新排序的矩阵，小批量中的剩余张量按相同的顺序排序，以便它们与源序列编码保持一致。在例8-3中，generate_batches函数被修改为generate_nmt_batches函数。</p>
<p>Example 8-3. Generating minibatches for the NMT example<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_nmt_batches</span><span class="params">(dataset, batch_size, shuffle=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                            drop_last=True, device=<span class="string">"cpu"</span>)</span>:</span></span><br><span class="line">    <span class="string">"""A generator function which wraps the PyTorch DataLoader; NMT Version """</span></span><br><span class="line">    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,</span><br><span class="line">                            shuffle=shuffle, drop_last=drop_last)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data_dict <span class="keyword">in</span> dataloader:</span><br><span class="line">        lengths = data_dict[<span class="string">'x_source_length'</span>].numpy()</span><br><span class="line">        sorted_length_indices = lengths.argsort()[::<span class="number">-1</span>].tolist()</span><br><span class="line"></span><br><span class="line">        out_data_dict = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> name, tensor <span class="keyword">in</span> data_dict.items():</span><br><span class="line">            out_data_dict[name] = data_dict[name][sorted_length_indices].to(device)</span><br><span class="line">        <span class="keyword">yield</span> out_data_dict</span><br></pre></td></tr></table></figure></p>
<h3 id="Encoding-and-Decoding-in-the-NMT-Model"><a href="#Encoding-and-Decoding-in-the-NMT-Model" class="headerlink" title="Encoding and Decoding in the NMT Model"></a>Encoding and Decoding in the NMT Model</h3><p>在这个例子中，我们从源序列开始 - 一个英语句子 - 我们生成一个目标序列 - 相应的法语翻译。标准方法是使用“序列到序列模型，编码器 - 解码器模型和条件生成”中描述的编码器 - 解码器模型。在示例8-4和示例8-5中呈现的模型中，编码器首先将每个源序列映射到具有bi-GRU的矢量状态序列（参见“从序列中捕获更多：双向递归模型”）。然后，解码器以解码器的隐藏状态作为其初始隐藏状态开始，并使用注意机制（参见“从序列中捕获更多：注意”）来选择源序列中的不同信息以生成输出序列。在本节的其余部分，我们将更详细地解释此过程。</p>
<p>Example 8-4. The NMTModel encapsulates and coordinates the encoder and decoder in a single forward method.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NMTModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">""" A Neural Machine Translation Model """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, source_vocab_size, source_embedding_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                 target_vocab_size, target_embedding_size, encoding_size,</span></span></span><br><span class="line"><span class="function"><span class="params">                 target_bos_index)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            source_vocab_size (int): number of unique words in source language</span></span><br><span class="line"><span class="string">            source_embedding_size (int): size of the source embedding vectors</span></span><br><span class="line"><span class="string">            target_vocab_size (int): number of unique words in target language</span></span><br><span class="line"><span class="string">            target_embedding_size (int): size of the target embedding vectors</span></span><br><span class="line"><span class="string">            encoding_size (int): the size of the encoder RNN.</span></span><br><span class="line"><span class="string">            target_bos_index (int): index for BEGIN-OF-SEQUENCE token</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(NMTModel, self).__init__()</span><br><span class="line">        self.encoder = NMTEncoder(num_embeddings=source_vocab_size,</span><br><span class="line">                                  embedding_size=source_embedding_size,</span><br><span class="line">                                  rnn_hidden_size=encoding_size)</span><br><span class="line">        decoding_size = encoding_size * <span class="number">2</span></span><br><span class="line">        self.decoder = NMTDecoder(num_embeddings=target_vocab_size,</span><br><span class="line">                                  embedding_size=target_embedding_size,</span><br><span class="line">                                  rnn_hidden_size=decoding_size,</span><br><span class="line">                                  bos_index=target_bos_index)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x_source, x_source_lengths, target_sequence)</span>:</span></span><br><span class="line">        <span class="string">"""The forward pass of the model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x_source (torch.Tensor): the source text data tensor.</span></span><br><span class="line"><span class="string">                x_source.shape should be (batch, vectorizer.max_source_length)</span></span><br><span class="line"><span class="string">            x_source_lengths torch.Tensor): the length of the sequences in x_source</span></span><br><span class="line"><span class="string">            target_sequence (torch.Tensor): the target text data tensor</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            decoded_states (torch.Tensor): prediction vectors at each output step</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        encoder_state, final_hidden_states = self.encoder(x_source,</span><br><span class="line">                                                          x_source_lengths)</span><br><span class="line">        decoded_states = self.decoder(encoder_state=encoder_state,</span><br><span class="line">                                      initial_hidden_state=final_hidden_states,</span><br><span class="line">                                      target_sequence=target_sequence)</span><br><span class="line">        <span class="keyword">return</span> decoded_states</span><br></pre></td></tr></table></figure></p>
<p>THE ENCODER<br>Example 8-5. The encoder embeds the source words and extracts features with a bi-GRU<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NMTEncoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_embeddings, embedding_size, rnn_hidden_size)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            num_embeddings (int): size of source vocabulary</span></span><br><span class="line"><span class="string">            embedding_size (int): size of the embedding vectors</span></span><br><span class="line"><span class="string">            rnn_hidden_size (int): size of the RNN hidden state vectors</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(NMTEncoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.source_embedding = nn.Embedding(num_embeddings, embedding_size,</span><br><span class="line">                                             padding_idx=<span class="number">0</span>)</span><br><span class="line">        self.birnn = nn.GRU(embedding_size, rnn_hidden_size, bidirectional=<span class="keyword">True</span>,</span><br><span class="line">                            batch_first=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x_source, x_lengths)</span>:</span></span><br><span class="line">        <span class="string">"""The forward pass of the model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x_source (torch.Tensor): the input data tensor.</span></span><br><span class="line"><span class="string">                x_source.shape is (batch, seq_size)</span></span><br><span class="line"><span class="string">            x_lengths (torch.Tensor): vector of lengths for each item in the batch</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            a tuple: x_unpacked (torch.Tensor), x_birnn_h (torch.Tensor)</span></span><br><span class="line"><span class="string">                x_unpacked.shape = (batch, seq_size, rnn_hidden_size * 2)</span></span><br><span class="line"><span class="string">                x_birnn_h.shape = (batch, rnn_hidden_size * 2)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        x_embedded = self.source_embedding(x_source)</span><br><span class="line">        <span class="comment"># create PackedSequence; x_packed.data.shape=(number_items, embedding_size)</span></span><br><span class="line">        x_lengths = x_lengths.detach().cpu().numpy()</span><br><span class="line">        x_packed = pack_padded_sequence(x_embedded, x_lengths, batch_first=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># x_birnn_h.shape = (num_rnn, batch_size, feature_size)</span></span><br><span class="line">        x_birnn_out, x_birnn_h  = self.birnn(x_packed)</span><br><span class="line">        <span class="comment"># permute to (batch_size, num_rnn, feature_size)</span></span><br><span class="line">        x_birnn_h = x_birnn_h.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># flatten features; reshape to (batch_size, num_rnn * feature_size)</span></span><br><span class="line">        <span class="comment">#  (recall: -1 takes the remaining positions,</span></span><br><span class="line">        <span class="comment">#           flattening the two RNN hidden vectors into 1)</span></span><br><span class="line">        x_birnn_h = x_birnn_h.contiguous().view(x_birnn_h.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first=<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">return</span> x_unpacked, x_birnn_h</span><br></pre></td></tr></table></figure></p>
<p>通常，编码器将整数序列作为输入，并为每个位置创建特征向量。在该示例中，编码器的输出是这些向量以及用于制作特征向量的bi-GRU的最终隐藏状态。该隐藏状态用于在下一节中初始化解码器的隐藏状态。</p>
<p>深入了解编码器，我们首先使用嵌入层嵌入输入序列。通常，只需在嵌入层上设置padding_idx标志，我们就可以使模型处理可变长度序列，因为任何等于padding_idx的位置都会被赋予零值向量，该向量在优化期间不会更新。回想一下，这被称为面具。然而，在这种编码器 - 解码器模型中，掩蔽位置需要以不同方式处理，因为我们使用bi-GRU来编码源序列。主要原因是后向分量可能受到屏蔽位置的影响，其因子与在序列上开始之前遇到的屏蔽位置的数量成比例。</p>
<p>为了处理bi-GRU中可变长度序列的掩码位置，我们使用PyTorch的PackedSequence数据结构。 PackedSequences源自CUDA如何允许以批处理格式处理可变长度序列。如果满足两个条件，则可以将任何零填充序列（例如示例8-6中所示的编码器中的嵌入源序列）转换为PackedSequence：提供每个序列的长度，并根据以下顺序对小批量进行排序。这些序列的长度。这在图8-11中以可视方式显示，因为它是一个复杂的主题，我们在例8-6及其输出中再次演示它.</p>
<p>Example 8-6. A simple demonstration of packed_padded_sequences and pad_packed_sequences<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Input[<span class="number">0</span>]</span><br><span class="line">abcd_padded = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], dtype=torch.float32)</span><br><span class="line">efg_padded = torch.tensor([<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">0</span>], dtype=torch.float32)</span><br><span class="line">h_padded = torch.tensor([<span class="number">8</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">padded_tensor = torch.stack([abcd_padded, efg_padded, h_padded])</span><br><span class="line"></span><br><span class="line">describe(padded_tensor)</span><br><span class="line">Output[<span class="number">0</span>]</span><br><span class="line">Type: torch.FloatTensor</span><br><span class="line">Shape/size: torch.Size([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">Values:</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">4.</span>],</span><br><span class="line">        [ <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">8.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br><span class="line">Input[<span class="number">1</span>]</span><br><span class="line">lengths = [<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line">packed_tensor = pack_padded_sequence(padded_tensor, lengths,   </span><br><span class="line">                                     batch_first=<span class="keyword">True</span>)</span><br><span class="line">packed_tensor</span><br><span class="line">Output[<span class="number">1</span>]</span><br><span class="line">PackedSequence(data=tensor([ <span class="number">1.</span>,  <span class="number">5.</span>,  <span class="number">8.</span>,  <span class="number">2.</span>,  <span class="number">6.</span>,  <span class="number">3.</span>,  <span class="number">7.</span>,  <span class="number">4.</span>]),</span><br><span class="line">               batch_sizes=tensor([ <span class="number">3</span>,  <span class="number">2</span>,  <span class="number">2</span>,  <span class="number">1</span>]))</span><br><span class="line">Input[<span class="number">2</span>]</span><br><span class="line">unpacked_tensor, unpacked_lengths = \</span><br><span class="line">    pad_packed_sequence(packed_tensor, batch_first=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">describe(unpacked_tensor)</span><br><span class="line">describe(unpacked_lengths)</span><br><span class="line">Output[<span class="number">2</span>]</span><br><span class="line">Type: torch.FloatTensor</span><br><span class="line">Shape/size: torch.Size([<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">Values:</span><br><span class="line">tensor([[ <span class="number">1.</span>,  <span class="number">2.</span>,  <span class="number">3.</span>,  <span class="number">4.</span>],</span><br><span class="line">        [ <span class="number">5.</span>,  <span class="number">6.</span>,  <span class="number">7.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [ <span class="number">8.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>,  <span class="number">0.</span>]])</span><br><span class="line">Type: torch.LongTensor</span><br><span class="line">Shape/size: torch.Size([<span class="number">3</span>])</span><br><span class="line">Values:</span><br><span class="line">tensor([ <span class="number">4</span>,  <span class="number">3</span>,  <span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>我们在生成每个minibatch时处理排序，如上一节所述。然后，如例8-7所示，通过传递嵌入的序列，序列的长度和表示第一个维度是批量维度的布尔标志来激发PyTorch的pack_padded_sequence函数。此函数的输出是PackedSequence。将得到的PackedSequence输入到bi-GRU中以为下游解码器创建状态向量。使用另一个布尔标志将bi-GRU的输出解压缩为完整张量，指示批处理在第一维上。解包操作，如图8-11所示，将每个屏蔽位置15设置为零值向量，保留下游计算的完整性。</p>
<p>Example 8-7. The NMT Decoder constructs a target sentence from the encoded source sentence<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NMTDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_embeddings, embedding_size, rnn_hidden_size, bos_index)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            num_embeddings (int): number of embeddings is also the number of</span></span><br><span class="line"><span class="string">                unique words in target vocabulary</span></span><br><span class="line"><span class="string">            embedding_size (int): the embedding vector size</span></span><br><span class="line"><span class="string">            rnn_hidden_size (int): size of the hidden rnn state</span></span><br><span class="line"><span class="string">            bos_index(int): begin-of-sequence index</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(NMTDecoder, self).__init__()</span><br><span class="line">        self._rnn_hidden_size = rnn_hidden_size</span><br><span class="line">        self.target_embedding = nn.Embedding(num_embeddings=num_embeddings,</span><br><span class="line">                                             embedding_dim=embedding_size,</span><br><span class="line">                                             padding_idx=<span class="number">0</span>)</span><br><span class="line">        self.gru_cell = nn.GRUCell(embedding_size + rnn_hidden_size,</span><br><span class="line">                                   rnn_hidden_size)</span><br><span class="line">        self.hidden_map = nn.Linear(rnn_hidden_size, rnn_hidden_size)</span><br><span class="line">        self.classifier = nn.Linear(rnn_hidden_size * <span class="number">2</span>, num_embeddings)</span><br><span class="line">        self.bos_index = bos_index</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_indices</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        <span class="string">""" return the BEGIN-OF-SEQUENCE index vector """</span></span><br><span class="line">        <span class="keyword">return</span> torch.ones(batch_size, dtype=torch.int64) * self.bos_index</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_context_vectors</span><span class="params">(self, batch_size)</span>:</span></span><br><span class="line">        <span class="string">""" return a zeros vector for initializing the context """</span></span><br><span class="line">        <span class="keyword">return</span> torch.zeros(batch_size, self._rnn_hidden_size)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, encoder_state, initial_hidden_state, target_sequence)</span>:</span></span><br><span class="line">        <span class="string">"""The forward pass of the model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            encoder_state (torch.Tensor): the output of the NMTEncoder</span></span><br><span class="line"><span class="string">            initial_hidden_state (torch.Tensor): The last hidden state in the  NMTEncoder</span></span><br><span class="line"><span class="string">            target_sequence (torch.Tensor): the target text data tensor</span></span><br><span class="line"><span class="string">            sample_probability (float): the schedule sampling parameter</span></span><br><span class="line"><span class="string">                probability of using model's predictions at each decoder step</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            output_vectors (torch.Tensor): prediction vectors at each output step</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># We are making an assumption there: The batch is on first</span></span><br><span class="line">        <span class="comment"># The input is (Batch, Seq)</span></span><br><span class="line">        <span class="comment"># We want to iterate over sequence so we permute it to (S, B)</span></span><br><span class="line">        target_sequence = target_sequence.permute(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># use the provided encoder hidden state as the initial hidden state</span></span><br><span class="line">        h_t = self.hidden_map(initial_hidden_state)</span><br><span class="line"></span><br><span class="line">        batch_size = encoder_state.size(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># initialize context vectors to zeros</span></span><br><span class="line">        context_vectors = self._init_context_vectors(batch_size)</span><br><span class="line">        <span class="comment"># initialize first y_t word as BOS</span></span><br><span class="line">        y_t_index = self._init_indices(batch_size)</span><br><span class="line"></span><br><span class="line">        h_t = h_t.to(encoder_state.device)</span><br><span class="line">        y_t_index = y_t_index.to(encoder_state.device)</span><br><span class="line">        context_vectors = context_vectors.to(encoder_state.device)</span><br><span class="line"></span><br><span class="line">        output_vectors = []</span><br><span class="line">        <span class="comment"># All cached tensors are moved from the GPU and stored for analysis</span></span><br><span class="line">        self._cached_p_attn = []</span><br><span class="line">        self._cached_ht = []</span><br><span class="line">        self._cached_decoder_state = encoder_state.cpu().detach().numpy()</span><br><span class="line"></span><br><span class="line">        output_sequence_size = target_sequence.size(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(output_sequence_size):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 1: Embed word and concat with previous context</span></span><br><span class="line">            y_input_vector = self.target_embedding(target_sequence[i])</span><br><span class="line">            rnn_input = torch.cat([y_input_vector, context_vectors], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 2: Make a GRU step, getting a new hidden vector</span></span><br><span class="line">            h_t = self.gru_cell(rnn_input, h_t)</span><br><span class="line">            self._cached_ht.append(h_t.cpu().data.numpy())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 3: Use the current hidden to attend to the encoder state</span></span><br><span class="line">            context_vectors, p_attn, _ = \</span><br><span class="line">                verbose_attention(encoder_state_vectors=encoder_state,</span><br><span class="line">                                  query_vector=h_t)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># auxiliary: cache the attention probabilities for visualization</span></span><br><span class="line">            self._cached_p_attn.append(p_attn.cpu().detach().numpy())</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 4: Use the current hidden and context vectors</span></span><br><span class="line">            <span class="comment">#         to make a prediction to the next word</span></span><br><span class="line">            prediction_vector = torch.cat((context_vectors, h_t), dim=<span class="number">1</span>)</span><br><span class="line">            score_for_y_t_index = self.classifier(prediction_vector)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># auxiliary: collect the prediction scores</span></span><br><span class="line">            output_vectors.append(score_for_y_t_index)</span><br></pre></td></tr></table></figure></p>
<p>在编码器利用其bi-GRU和打包 - 解包协调创建状态向量之后，解码器在时间步骤上迭代以生成输出序列。在功能上，这个循环应该看起来与第7章中的生成循环非常相似，但是有一些差异明显是Luong等人的注意方式的方法选择。首先，在每个时间步骤提供目标序列作为观察。通过使用GRUCell计算隐藏状态。通过将线性层应用于编码器bi-GRU的级联最终隐藏状态来计算初始隐藏状态.在每个时间步骤处对解码器GRU的输入是嵌入式输入令牌和最后时间步骤的上下文的级联向量。向量。上下文向量旨在捕获对该时间步骤有用的信息，并用于调节模型的输出。对于第一个步骤，上下文向量全部为0（零）以表示无上下文并且在数学上仅允许输入对GRU计算做出贡献。</p>
<p>使用新的隐藏状态作为查询向量，使用当前时间步骤的关注机制创建一组新的上下文向量。这些上下文向量与隐藏状态连接以创建表示该时间步长处的解码信息的向量。该解码信息状态向量用在分类器（在这种情况下，简单的线性层）中以创建预测向量score_for_y_t_index。这些预测矢量可以使用softmax函数转换为输出词汇表上的概率分布，或者它们可以与交叉熵损失一起使用以优化地面实况目标。在我们转向如何在训练例程中使用预测向量之前，我们首先检查注意力计算本身。</p>
<p>A CLOSER LOOK AT ATTENTION<br>了解注意机制在此示例中的工作方式非常重要。回想一下前面的部分，可以使用查询，键和值来描述注意机制。分数函数将查询向量和关键向量作为输入，以计算在值向量中选择的一组权重。在这个例子中，我们使用点积评分函数，但它不是唯一的.在这个例子中，解码器的隐藏状态被用作查询向量，编码器状态向量集是关键和值向量。</p>
<p>解码器隐藏状态与编码器状态中的矢量的点积为编码序列中的每个项创建标量。在使用softmax函数时，这些标量变为编码器状态中的矢量的概率分布。这些概率用于在将编码器状态向量加在一起之前对其进行加权，以产生每个批次项目的单个向量。总而言之，允许解码器隐藏状态在每个时间步骤优先加权编码器状态。这就像一个聚光灯，使模型能够学习如何突出显示生成输出序列所需的信息。我们在例8-8中演示了这种版本的注意机制。第一个尝试详细说明操作。此外，它使用视图操作插入大小为1的维度，以便可以针对另一个张量广播张量。在terse_attention版本中，视图操作被更常用的练习替换，取消压缩。此外，不是将元素和求和相乘，而是使用更有效的matmul运算。</p>
<p>Example 8-8. Attention that does element-wise multiplication and summing more explicitly<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">verbose_attention</span><span class="params">(encoder_state_vectors, query_vector)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    encoder_state_vectors: 3dim tensor from bi-GRU in encoder</span></span><br><span class="line"><span class="string">    query_vector: hidden state in decoder GRU</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    batch_size, num_vectors, vector_size = encoder_state_vectors.size()</span><br><span class="line">    vector_scores = \</span><br><span class="line">        torch.sum(encoder_state_vectors * query_vector.view(batch_size, <span class="number">1</span>,</span><br><span class="line">                                                            vector_size),</span><br><span class="line">                  dim=<span class="number">2</span>)</span><br><span class="line">    vector_probabilities = F.softmax(vector_scores, dim=<span class="number">1</span>)</span><br><span class="line">    weighted_vectors = \</span><br><span class="line">        encoder_state_vectors * vector_probabilities.view(batch_size,</span><br><span class="line">                                                          num_vectors, <span class="number">1</span>)</span><br><span class="line">    context_vectors = torch.sum(weighted_vectors, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> context_vectors, vector_probabilities</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">terse_attention</span><span class="params">(encoder_state_vectors, query_vector)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    encoder_state_vectors: 3dim tensor from bi-GRU in encoder</span></span><br><span class="line"><span class="string">    query_vector: hidden state</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    vector_scores = torch.matmul(encoder_state_vectors,</span><br><span class="line">                                 query_vector.unsqueeze(dim=<span class="number">2</span>)).squeeze()</span><br><span class="line">    vector_probabilities = F.softmax(vector_scores, dim=<span class="number">-1</span>)</span><br><span class="line">    context_vectors = torch.matmul(encoder_state_vectors.transpose(<span class="number">-2</span>, <span class="number">-1</span>),</span><br><span class="line">                                   vector_probabilities.unsqueeze(dim=<span class="number">2</span>)).squeeze()</span><br><span class="line">    <span class="keyword">return</span> context_vectors, vector_probabilities</span><br></pre></td></tr></table></figure></p>
<p>LEARNING TO SEARCH AND SCHEDULED SAMPLING</p>
<p>当前编写的方式，模型假定提供了目标序列，并将在解码器的每个时间步骤用作输入。在测试时，违反了这个假设，因为模型不能作弊并且知道它试图生成的序列。为了适应这一事实，一种技术是允许模型在训练期间使用自己的预测。这是一种在文献中探索为“学习搜索”和“预定抽样”的技术.理解这种技术的一种直观方法是将预测问题视为搜索问题。在每个时间步，模型有许多路径可供选择（选择的数量是目标词汇的大小），数据是正确路径的观察。在测试时，模型最终被允许“离开路径”，因为没有提供正确的路径，它应该从中计算概率分布。因此，让模型采样自己的路径的技术提供了一种方法，在该方法中，当模型偏离数据集中的目标序列时，可以优化模型以获得更好的概率分布。</p>
<p>代码有三个主要修改，以使模型在训练期间采样自己的预测。首先，初始索引更明确地作为BEGIN-OF-SEQUENCE标记索引。其次，为生成循环中的每个步骤绘制随机样本，如果随机样本小于样本概率，则在该迭代期间使用模型的预测。最后，第三个实际采样本身在条件if下使用use_sample。在示例8-9中，注释行显示了如何使用最大预测，而未注释行显示了如何以与其概率成比例的速率实际采样索引。</p>
<p>Example 8-9. The decoder with a sampling procedures (in bold) built into the forward pass</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NMTDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_embeddings, embedding_size, rnn_size, bos_index)</span>:</span></span><br><span class="line">        super(NMTDecoder, self).__init__()</span><br><span class="line">        <span class="comment"># ... other init code here ...</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># arbitrarily set; any small constant will be fine</span></span><br><span class="line">        self._sampling_temperature = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, encoder_state, initial_hidden_state, target_sequence,</span></span></span><br><span class="line"><span class="function"><span class="params">               sample_probability=<span class="number">0.0</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> target_sequence <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            sample_probability = <span class="number">1.0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># We are making an assumption there: The batch is on first</span></span><br><span class="line">            <span class="comment"># The input is (Batch, Seq)</span></span><br><span class="line">            <span class="comment"># We want to iterate over sequence so we permute it to (S, B)</span></span><br><span class="line">            target_sequence = target_sequence.permute(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">            output_sequence_size = target_sequence.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ... nothing changes from the other implementation</span></span><br><span class="line"></span><br><span class="line">        output_sequence_size = target_sequence.size(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(output_sequence_size):</span><br><span class="line">            <span class="comment"># new: a helper boolean and the teacher y_t_index</span></span><br><span class="line">            use_sample = np.random.random() &lt; sample_probability</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> use_sample:</span><br><span class="line">                y_t_index = target_sequence[i]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 1: Embed word and concat with previous context</span></span><br><span class="line">            <span class="comment"># ... code omitted for space</span></span><br><span class="line">            <span class="comment"># Step 2: Make a GRU step, getting a new hidden vector</span></span><br><span class="line">            <span class="comment"># ... code omitted for space</span></span><br><span class="line">            <span class="comment"># Step 3: Use the current hidden to attend to the encoder state</span></span><br><span class="line">            <span class="comment"># ... code omitted for space</span></span><br><span class="line">            <span class="comment"># Step 4: Use the current hidden and context vectors</span></span><br><span class="line">            <span class="comment">#         to make a prediction to the next word</span></span><br><span class="line">            prediction_vector = torch.cat((context_vectors, h_t), dim=<span class="number">1</span>)</span><br><span class="line">            score_for_y_t_index = self.classifier(prediction_vector)</span><br><span class="line">            <span class="comment"># new: sampling if boolean is true.</span></span><br><span class="line">            <span class="keyword">if</span> use_sample:</span><br><span class="line">                <span class="comment"># sampling temperature forces a peakier distribution</span></span><br><span class="line">                p_y_t_index = F.softmax(score_for_y_t_index *</span><br><span class="line">                                        self._sampling_temperature, dim=<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># method 1: choose most likely word</span></span><br><span class="line">                <span class="comment"># _, y_t_index = torch.max(p_y_t_index, 1)</span></span><br><span class="line">                <span class="comment"># method 2: sample from the distribution</span></span><br><span class="line">                y_t_index = torch.multinomial(p_y_t_index, <span class="number">1</span>).squeeze()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># auxiliary: collect the prediction scores</span></span><br><span class="line">            output_vectors.append(score_for_y_t_index)</span><br><span class="line"></span><br><span class="line">        output_vectors = torch.stack(output_vectors).permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output_vectors</span><br></pre></td></tr></table></figure>
<h3 id="Training-Routine-and-Results"><a href="#Training-Routine-and-Results" class="headerlink" title="Training Routine and Results"></a>Training Routine and Results</h3><p>此示例的训练例程几乎与前面章节中介绍的训练例程相同。对于固定数量的历元，我们在称为minibatches的块中迭代数据集。然而，这里的每个小批量由四个张量组成：源序列的整数矩阵，目标序列的两个整数矩阵，以及源序列长度的整数向量。两个靶序列矩阵是靶序列偏移1并用BEGIN-OF-SEQUENCE令牌填充以充当靶序列观察，或END-OF-SEQUENCE令牌充当靶序列预测标记。该模型将源序列和​​目标序列观察作为输入，以产生目标序列预测。在损失函数中使用目标序列预测标签来计算交叉熵损失，然后将其反向传播到每个模型参数以使其知道其梯度。然后调用优化器并将每个模型参数更新一些与梯度成比例的量。</p>
<p>除了数据集的训练部分上的循环之外，验证部分上还有一个循环。验证分数用作模型改进的偏差较小的度量。该过程与训练例程相同，只是模型处于eval模式并且模型未相对于验证数据更新。</p>
<p>在训练模型之后，测量性能成为一个重要而重要的问题。在“评估序列生成模型”中描述了几个序列生成评估度量，但是诸如测量预测句子和参考语句之间的n-gram重叠的BLEU的度量已经成为机器翻译领域的标准。聚合结果的评估代码已被省略，但您可以在本书的随附代码库中找到它.在代码中，模型的输出与源句子，参考目标语句和注意概率矩阵聚合在一起。例。最后，为每对源和生成的句子计算BLEU-4。</p>
<p>为了定性评估模型的工作情况，我们将注意概率矩阵可视化为源和生成文本之间的对齐。然而，值得注意的是，最近的研究表明，基于注意力的对齐与经典机器翻译中的对齐并不完全相同。基于注意力的对齐分数可以指示解码器的有用信息，例如在生成输出动词时参与句子的主语（Koehn和Knowles，2017），而不是单词和短语之间的对齐指示翻译同义词。</p>
<p>我们比较了我们模型的两个版本，它们与目标句子的交互方式不同。第一个版本使用提供的目标序列作为解码器中每个时间步的输入。第二个版本使用预定采样，以允许模型将其自己的预测视为解码器中的输入。这有利于强制模型优化其自身的错误。表8-1显示了BLEU分数。重要的是要记住，为了便于训练，我们选择了标准NMT任务的简化版本，这就是为什么分数似乎高于您在研究文献中通常会发现的分数。虽然第二个模型，即具有预定采样的模型，具有更高的BLEU分数，但是得分相当接近。但这些得分究竟意味着什么呢？为了研究这个问题，我们需要定性地检查模型。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/test.png" alt="test" title="表8 - 1。先前显示的两个模型的BLEU得分;BLEU被计算为1-、2-、3-和4克重叠的简单平均值"></p>
<p>对于我们更深入的检查，我们绘制注意力分数，以查看它们是否在源句和目标句之间提供任何类型的对齐信息。我们发现在这次检查中两个模型之间形成了鲜明的对比.图8-12显示了具有预定采样的模型的每个解码器时间步长的注意概率分布。在该模型中，注意权重对于从数据集的验证部分采样的句子排列得相当好。</p>
<p><img src="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/test1.png" alt="test1" title="图8-12. 具有预定采样的模型的注意力权重矩阵被绘制为模型性能的定性评估"></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>本章重点介绍了在所谓的条件生成模型的条件上下文中生成序列输出。当条件上下文本身来自另一个序列时，我们将其称为序列到序列或S2S模型。我们还讨论了S2S模型如何成为编码器 - 解码器模型的特例。为了充分利用序列，我们讨论了第6章和第7章中讨论的序列模型的结构变体，特别是双向模型。我们还学习了如何结合注意机制来有效捕获更长距离的背景。最后，我们讨论了如何评估序列到序列模型，并使用端到端机器翻译示例进行演示。到目前为止，我们已将本书的每一章专门用于特定的网络架构。在下一章中，我们将前面的所有章节结合在一起，并查看如何使用各种模型体系结构的综合构建许多真实系统的示例。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><p>Yoshua Bengio, Patrice Simard, and Paolo Frasconi. (1994). “Learning long-term dependencies with gradient descent is difficult.” IEEE transactions on neural networks.</p>
</li>
<li><p>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. (2002) “BLEU: a method for automatic evaluation of machine translation.” In Proceedings ACL.. Hal Daumé III, John Langford, Daniel Marcu. (2009). “Search-based Structured Prediction.” In Machine Learning Journal.</p>
</li>
<li><p>Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer. “Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks.” In Proceedings of NIPS 2015.</p>
</li>
<li><p>Minh-Thang Luong, Hieu Pham, and Christopher D. Manning. (2015). “Effective Approaches to Attention-based Neural Machine Translation.” In Proceedings of EMNLP.</p>
</li>
<li><p>Phong Le and Willem Zuidema. (2016). “Quantifying the Vanishing Gradient and Long Distance Dependency Problem in Recursive Neural Networks and Recursive LSTMs.” Proceedings of the 1st Workshop on Representation Learning for NLP.</p>
</li>
<li><p>Philipp Koehn, Rebecca Knowles. (2017). “Six Challenges for Neural Machine Translation.” In Proceedings of the First Workshop on Neural Machine Translation.</p>
</li>
<li><p>Graham Neubig. (2017). “Neural Machine Translation and Sequence-to-Sequence Models: A Tutorial.” arXiv:1703.01619.</p>
</li>
<li><p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia Polosukhin. (2017). “Attention is all you need.” In Proceedings of NIPS.</p>
</li>
</ol>
<p>In this chapter, we reserve the symbol ϕ for encodings.<br>This is not possible for streaming applications, but a large number of practical applications of NLP happen in a batch (non-streaming) context anyways.<br>Sentences like the one in this example are called “Garden Path Sentences.” Such sentences are more common than one would imagine, for e.g., newspaper headlines use such constructs regularly. See <a href="https://en.wikipedia.org/wiki/Garden_path_sentence" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Garden_path_sentence</a>.<br>Consider the two meanings of “duck” (i) □ (noun, quack quack) and (ii) evade (verb)<br>The terminology key, values, and query can be quite confusing for the beginner, but we introduce them here anyway because they have now become a standard. It is worth reading this section (8.3.1) a few times until these concepts become clear. The “Key, Value, Query” terminology comes in because the attention was initially thought of as a search task. For an extended review of these concepts and attention in general, visit <a href="https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html" target="_blank" rel="noopener">https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html</a>.<br>So much that the original 2002 paper that proposed that BLEU received a “test of the time award” in 2018.<br>For an example, see <a href="https://github.com/nltk/nltk/blob/develop/nltk/translate/bleu_score.py" target="_blank" rel="noopener">https://github.com/nltk/nltk/blob/develop/nltk/translate/bleu_score.py</a>.<br>SacreBLEU is the standard when it comes to machine translation evaluation.<br>The dataset was retrieved from <a href="http://www.manythings.org/anki/" target="_blank" rel="noopener">http://www.manythings.org/anki/</a>.<br>We also include the cases in which these subject-verb pairs are contractions, such as “I’m”, “we’re”, and “he’s”.<br>This simply means that the model will be able to see the entire dataset 10 times faster. It doesn’t exactly follow that the convergence will happen in one-tenth the time, because it could be that the model needs to see this dataset for a smaller number of epochs, or some other confounding factor.<br>Sorting the sequences in order takes advantage of a low-level CUDA primitive for RNNs.<br>You should try to convince yourself of this by either visualizing the computations or drawing them out. As a hint, consider the single recurrent step: the input and last hidden are weighted and added together with the bias. If the input is all 0’s, what effect does the bias have on the output?<br>We utilize the describe function shown in section 1.4.<br>Starting from left to right on the sequence dimension, any position past the known length of the sequence is assumed to be masked.<br>The Vectorizer prepends the BEGIN-OF-SEQUENCE token to the sequence, so the first observation is always a special token indicating the boundary.<br>See section 7.3 of Graham Neubig’s tutorial for a discussion on connecting encoders and decoders in neural machine translation. See (Neubig, 2017).<br>We refer you to Luong, Pham, and Manning (2011), in which they outline three different scoring functions.<br>Each batch item is a sequence and the probabilities for each sequence sum to 1.<br>Broadcasting happens when a tensor has a dimension of size 1. Let this tensor be called Tensor A. When Tensor A is used in an element-wise mathematical operation (such as addition or subtraction) with another tensor called Tensor B, its shape (the number of elements on each dimension) should be identical except for the dimension with size 1. The operation of Tensor A on Tensor B is repeated for each position in Tensor B. If Tensor A has a shape (10, 1, 10) and Tensor B has a shape (10, 5, 10), A+B will repeat the addition of Tensor A for each of the five positions in Tensor B.<br>We refer you to two papers on this topic: “Search-based Structured Prediction” by Daumé, Langford, Marcu, and “Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks” by Bengio, Vinyals, Jaitly, Shazeer (2015).<br>If you’re familiar with Monte Carlo sampling for optimization techniques such as Markov Chain Monte Carlo, you will recognize this pattern.<br>Primarily, this is because gradient descent and automatic differentiation is an elegant abstraction between model definitions and their optimization.<br><a href="https://github.com/joosthub/nlpbook/chapters/chapter_8/example_8_5" target="_blank" rel="noopener">https://github.com/joosthub/nlpbook/chapters/chapter_8/example_8_5</a><br>We omit a plot for the first model because it attended to only the final state in the encoder RNN. As noted by Koehn and Knowles (2017), the attention weights are endemic of many different situations. We suspect the attention weights in the first model did not need to rely on attention as much because the information it needed was already encoded in the states of the encoder GRU.</p>

      
    </div>
    
    
    

	<div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/">Natural-Language-Processing-with-PyTorch（八）</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 Yif Du 的个人博客">Yif Du</a></p>
  <p><span>发布时间:</span>2018年12月28日 - 09:12</p>
  <p><span>最后更新:</span>2018年12月28日 - 11:12</p>
  <p><span>原始链接:</span><a href="/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/" title="Natural-Language-Processing-with-PyTorch（八）">http://yifdu.github.io/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="http://yifdu.github.io/2018/12/28/Natural-Language-Processing-with-PyTorch（八）/" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
      $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
        });
    });  
</script>

      
    </div>
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
            <a href="/tags/Pytorch/" rel="tag"># Pytorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/26/数字图像处理笔记（四）/" rel="next" title="数字图像处理笔记（四）">
                <i class="fa fa-chevron-left"></i> 数字图像处理笔记（四）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/12/28/Natural-Language-Processing-with-PyTorch（九）/" rel="prev" title="Natural-Language-Processing-with-PyTorch（九）">
                Natural-Language-Processing-with-PyTorch（九） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container"></div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/xuanyi.jpg" alt="Yif Du">
            
              <p class="site-author-name" itemprop="name">Yif Du</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">146</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">33</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">115</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yifdu" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="17210240004@fudan.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Chapter-8-Advanced-Sequence-Modeling-for-Natural-Language-Processing"><span class="nav-number">1.</span> <span class="nav-text">Chapter 8. Advanced Sequence Modeling for Natural Language Processing</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Sequence-to-Sequence-Models-Encoder–Decoder-Models-and-Conditioned-Generation"><span class="nav-number">1.1.</span> <span class="nav-text">Sequence-to-Sequence Models, Encoder–Decoder Models, and Conditioned Generation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Capturing-More-from-a-Sequence-Bidirectional-Recurrent-Models"><span class="nav-number">1.2.</span> <span class="nav-text">Capturing More from a Sequence: Bidirectional Recurrent Models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Capturing-More-from-a-Sequence-Attention"><span class="nav-number">1.3.</span> <span class="nav-text">Capturing More from a Sequence: Attention</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Attention-in-Deep-Neural-Networks"><span class="nav-number">1.3.1.</span> <span class="nav-text">Attention in Deep Neural Networks</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Evaluating-Sequence-Generation-Models"><span class="nav-number">1.4.</span> <span class="nav-text">Evaluating Sequence Generation Models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Example-Neural-Machine-Translation"><span class="nav-number">1.5.</span> <span class="nav-text">Example: Neural Machine Translation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Machine-Translation-Dataset"><span class="nav-number">1.5.1.</span> <span class="nav-text">Machine Translation Dataset</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#除了刚刚描述的标准预处理之外，我们还使用指定的语法模式列表来选择数据的子集，以简化学习问题。从本质上讲，这意味着我们将数据范围缩小到只有有限范围的句法模式。反过来，这意味着在训练期间，模型将看到更少的变化，并在更短的训练时间内具有更高的性能。"><span class="nav-number">1.6.</span> <span class="nav-text">除了刚刚描述的标准预处理之外，我们还使用指定的语法模式列表来选择数据的子集，以简化学习问题。从本质上讲，这意味着我们将数据范围缩小到只有有限范围的句法模式。反过来，这意味着在训练期间，模型将看到更少的变化，并在更短的训练时间内具有更高的性能。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#在构建新模型和尝试新体系结构时，您应该在建模选择和评估这些选择之间实现更快的迭代周期。"><span class="nav-number">1.7.</span> <span class="nav-text">在构建新模型和尝试新体系结构时，您应该在建模选择和评估这些选择之间实现更快的迭代周期。</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Vectorization-Pipeline-for-NMT"><span class="nav-number">1.7.1.</span> <span class="nav-text">A Vectorization Pipeline for NMT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Encoding-and-Decoding-in-the-NMT-Model"><span class="nav-number">1.7.2.</span> <span class="nav-text">Encoding and Decoding in the NMT Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Training-Routine-and-Results"><span class="nav-number">1.7.3.</span> <span class="nav-text">Training Routine and Results</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary"><span class="nav-number">1.8.</span> <span class="nav-text">Summary</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-number">1.9.</span> <span class="nav-text">References</span></a></li></ol></li></ol></div>
            

			
          </div>
        </section>
      <!--/noindex-->
      

      
	 

    </div>
		  
	  
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="heart">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yif Du</span>

  
</div>





        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
  <script src="/js/src/md5.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '7428ad62daef314bef06',
          clientSecret: '93cd3f4cd41cfc00c4760f65f8d895a66088ea5a',
          repo: 'Comments',
          owner: 'yifdu',
          admin: ['yifdu'],
          id: md5(location.pathname),
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')           
       </script>


  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  <style>
#selectionCopyright {
    position: absolute;
    display: none;
    background: rgba(244,67,54,.7);
    color: #fff;
    border-radius: 6px;
    box-shadow: none;
    border: none;
    font-size: 14px;
}
#selectionCopyright a{
    color:#fff;
    border-color: #fff;
}
#selectionCopyright::before {
    content: "";
    width: 0;
    height: 0;
    border-style: solid;
    border-width: 6px 8px 6px 0;
    border-color: transparent rgba(244,67,54,.7) transparent transparent;
    position: absolute;
    left: -8px;
    top:50%;
    transform:translateY(-50%);
}
</style>

<button id="selectionCopyright" disabled="disabled">本文发表于[<a href="http://yifdu.github.io">yifdu.github.io</a>]分享请注明来源！</button>

<script>
window.onload = function() {
    function selectText() {
        if (document.selection) { //IE浏览器下
            return document.selection.createRange().text; //返回选中的文字
        } else { //非IE浏览器下
            return window.getSelection().toString(); //返回选中的文字
        }
    }
    var content = document.getElementsByTagName("body")[0];
    var scTip = document.getElementById('selectionCopyright');

    content.onmouseup = function(ev) { //设定一个onmouseup事件
        var ev = ev || window.event;
        var left = ev.clientX;//获取鼠标相对浏览器可视区域左上角水平距离距离
        var top = ev.clientY;//获取鼠标相对浏览器可视区域左上角垂直距离距离
        var xScroll = Math.max(document.body.scrollLeft, document.documentElement.scrollLeft);//获取文档水平滚动距离
        var yScroll = Math.max(document.body.scrollTop, document.documentElement.scrollTop);//获取文档垂直滚动距离
        if (selectText().length > 0) {
            setTimeout(function() { //设定一个定时器
                scTip.style.display = 'inline-block';
                scTip.style.left = left + xScroll + 15 + 'px';//鼠标当前x值
                scTip.style.top = top + yScroll - 15 + 'px';//鼠标当前y值
            }, 100);
        } else {
            scTip.style.display = 'none';
        }
    };

    content.onclick = function(ev) {
        var ev = ev || window.event;
        ev.cancelBubble = true;
    };
    document.onclick = function() {
        scTip.style.display = 'none';
    };
};
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-miku"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
