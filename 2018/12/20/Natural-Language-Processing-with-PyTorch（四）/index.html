<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<meta name="theme-color" content="#222">
<script>
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！请问博主爸爸');
                history.back();
            }
        }
    })();
</script>


  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "258f1ebb"
    });
  daovoice('update');
  </script>









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="NLP,Pytorch,">










<meta name="description" content="由Yif翻译，仅供学习严禁任何商业用途 Chapter 4. Feed-Forward Networks for Natural Language Processing在第3章中，我们通过观察感知器来介绍神经网络的基础，感知器是现存最简单的神经网络。感知器的一个历史性的缺点是它不能学习数据中存在的一些非常重要的模式。例如，查看图4-1中绘制的数据点。这相当于非此即彼(XOR)的情况，在这种情况下，">
<meta name="keywords" content="NLP,Pytorch">
<meta property="og:type" content="article">
<meta property="og:title" content="Natural-Language-Processing-with-PyTorch（四）">
<meta property="og:url" content="http://yifdu.github.io/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/index.html">
<meta property="og:site_name" content="深度菜鸟">
<meta property="og:description" content="由Yif翻译，仅供学习严禁任何商业用途 Chapter 4. Feed-Forward Networks for Natural Language Processing在第3章中，我们通过观察感知器来介绍神经网络的基础，感知器是现存最简单的神经网络。感知器的一个历史性的缺点是它不能学习数据中存在的一些非常重要的模式。例如，查看图4-1中绘制的数据点。这相当于非此即彼(XOR)的情况，在这种情况下，">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545023935255&di=c2469985994fb00217b96200714f5f27&imgtype=0&src=http%3A%2F%2Fimage.tupian114.com%2F20120504%2F2012050420332255.jpg">
<meta property="og:updated_time" content="2018-12-28T03:44:54.332Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Natural-Language-Processing-with-PyTorch（四）">
<meta name="twitter:description" content="由Yif翻译，仅供学习严禁任何商业用途 Chapter 4. Feed-Forward Networks for Natural Language Processing在第3章中，我们通过观察感知器来介绍神经网络的基础，感知器是现存最简单的神经网络。感知器的一个历史性的缺点是它不能学习数据中存在的一些非常重要的模式。例如，查看图4-1中绘制的数据点。这相当于非此即彼(XOR)的情况，在这种情况下，">
<meta name="twitter:image" content="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545023935255&di=c2469985994fb00217b96200714f5f27&imgtype=0&src=http%3A%2F%2Fimage.tupian114.com%2F20120504%2F2012050420332255.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yifdu.github.io/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/">





  <title>Natural-Language-Processing-with-PyTorch（四） | 深度菜鸟</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">深度菜鸟</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-resume">
          <a href="/resume/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            简历
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yifdu.github.io/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yif Du">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/xuanyi.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="深度菜鸟">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Natural-Language-Processing-with-PyTorch（四）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-20T09:04:55+08:00">
                2018-12-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Pytorch/" itemprop="url" rel="index">
                    <span itemprop="name">Pytorch</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Pytorch/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读数
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  14.2k 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  54 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
        <div class="post-gallery" itemscope="" itemtype="http://schema.org/ImageGallery">
          
          
            <div class="post-gallery-row">
              <a class="post-gallery-img fancybox" href="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545023935255&di=c2469985994fb00217b96200714f5f27&imgtype=0&src=http%3A%2F%2Fimage.tupian114.com%2F20120504%2F2012050420332255.jpg" rel="gallery_cjuldzq2s00kt58wafpp5ryhh" itemscope="" itemtype="http://schema.org/ImageObject" itemprop="url">
                <img src="https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1545023935255&di=c2469985994fb00217b96200714f5f27&imgtype=0&src=http%3A%2F%2Fimage.tupian114.com%2F20120504%2F2012050420332255.jpg" itemprop="contentUrl">
              </a>
            
          

          
          </div>
        </div>
      

      
        <p><strong>由Yif翻译，仅供学习严禁任何商业用途</strong></p>
<h1 id="Chapter-4-Feed-Forward-Networks-for-Natural-Language-Processing"><a href="#Chapter-4-Feed-Forward-Networks-for-Natural-Language-Processing" class="headerlink" title="Chapter 4. Feed-Forward Networks for Natural Language Processing"></a>Chapter 4. Feed-Forward Networks for Natural Language Processing</h1><p>在第3章中，我们通过观察感知器来介绍神经网络的基础，感知器是现存最简单的神经网络。感知器的一个历史性的缺点是它不能学习数据中存在的一些非常重要的模式。例如，查看图4-1中绘制的数据点。这相当于非此即彼(XOR)的情况，在这种情况下，决策边界不能是一条直线(也称为线性可分)。在这个例子中，感知器失败了。<br><img src="/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/classifier.png" alt="classifier" title="图4-1. XOR数据集中的两个类绘制为圆形和星形。请注意，没有任何一行可以分隔这两个类。"></p>
<p>在这一章中，我们将探索传统上称为前馈网络的神经网络模型，以及两种前馈神经网络:多层感知器和卷积神经网络。多层感知器在结构上扩展了我们在第3章中研究的简单感知器，将多个感知器分组在一个单层，并将多个层叠加在一起。我们稍后将介绍多层感知器，并在“示例:带有多层感知器的姓氏分类”中展示它们在多层分类中的应用。</p>
<p>本章研究的第二种前馈神经网络，卷积神经网络，在处理数字信号时深受窗口滤波器的启发。通过这种窗口特性，卷积神经网络能够在输入中学习局部化模式，这不仅使其成为计算机视觉的主轴，而且是检测单词和句子等序列数据中的子结构的理想候选。我们在“卷积神经网络”中概述了卷积神经网络，并在“示例:使用CNN对姓氏进行分类”中演示了它们的使用。</p>
<p>在本章中，多层感知器和卷积神经网络被分组在一起，因为它们都是前馈神经网络，并且与另一类神经网络——递归神经网络(RNNs)形成对比，递归神经网络(RNNs)允许反馈(或循环)，这样每次计算都可以从之前的计算中获得信息。在第6章和第7章中，我们将介绍RNNs以及为什么允许网络结构中的循环是有益的。</p>
<p>在我们介绍这些不同的模型时，确保您理解事物如何工作的一个有用方法是在计算数据张量时注意它们的大小和形状。每种类型的神经网络层对它所计算的数据张量的大小和形状都有特定的影响，理解这种影响可以极大地有助于对这些模型的深入理解。</p>
<h2 id="The-Multilayer-Perceptron"><a href="#The-Multilayer-Perceptron" class="headerlink" title="The Multilayer Perceptron"></a>The Multilayer Perceptron</h2><p>多层感知器(MLP)被认为是最基本的神经网络构建模块之一。最简单的MLP是对第3章感知器的扩展。感知器将数据向量作为输入，计算出一个输出值。在MLP中，许多感知器被分组，以便单个层的输出是一个新的向量，而不是单个输出值。在PyTorch中，正如您稍后将看到的，这只需设置线性层中的输出特性的数量即可完成。MLP的另一个方面是，它将多个层与每个层之间的非线性结合在一起。</p>
<p>最简单的MLP，如图4-2所示，由三个表示阶段和两个线性层组成。第一阶段是输入向量。这是给定给模型的向量。在“示例:对餐馆评论的情绪进行分类”中，输入向量是Yelp评论的一个收缩的one-hot表示。给定输入向量，第一个线性层计算一个隐藏向量——表示的第二阶段。隐藏向量之所以这样被调用，是因为它是位于输入和输出之间的层的输出。我们所说的“层的输出”是什么意思?理解这个的一种方法是隐藏向量中的值是组成该层的不同感知器的输出。使用这个隐藏的向量，第二个线性层计算一个输出向量。在像Yelp评论分类这样的二进制任务中，输出向量仍然可以是1。在多类设置中，您将在本章后面的“示例:带有多层感知器的姓氏分类”一节中看到，输出向量是类数量的大小。虽然在这个例子中，我们只展示了一个隐藏的向量，但是有可能有多个中间阶段，每个阶段产生自己的隐藏向量。最终的隐藏向量总是通过线性层和非线性的组合映射到输出向量。</p>
<p><img src="/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/MLP.png" alt="MLP" title="图4-2. 一种具有两个线性层和三个表示阶段（输入向量、隐藏向量和输出向量）的MLP的可视化表示。"></p>
<p>mlp的力量来自于添加第二个线性层和允许模型学习一个线性分割的的中间表示——该属性的能表示一个直线(或更一般的,一个超平面)可以用来区分数据点落在线(或超平面)的哪一边的。学习具有特定属性的中间表示，如分类任务是线性可分的，这是使用神经网络的最深刻后果之一，也是其建模能力的精髓。在下一节中，我们将更深入地研究这意味着什么。</p>
<h3 id="A-Simple-Example-XOR"><a href="#A-Simple-Example-XOR" class="headerlink" title="A Simple Example: XOR"></a>A Simple Example: XOR</h3><p>让我们看一下前面描述的XOR示例，看看感知器与MLP之间会发生什么。在这个例子中，我们在一个二元分类任务中训练感知器和MLP:星和圆。每个数据点是一个二维坐标。在不深入研究实现细节的情况下，最终的模型预测如图4-3所示。在这个图中，错误分类的数据点用黑色填充，而正确分类的数据点没有填充。在左边的面板中，从填充的形状可以看出，感知器在学习一个可以将星星和圆分开的决策边界方面有困难。然而，MLP(右面板)学习了一个更精确地对恒星和圆进行分类的决策边界。</p>
<p><img src="/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/MLP_1.png" alt="MLP_1" title="图4-3. 从感知器（左）和MLP（右）学习的XOR问题的解决方案显示。每个数据点的真正类是该点的形状:星形或圆形。错误的分类用块填充，正确的分类没有填充。这些线是每个模型的决策边界。在左边的面板中，感知器学习一个不能正确地将圆与星分开的决策边界。事实上，没有一条线可以。在右边的面板中，MLP学会了从圆中分离星。"></p>
<p>虽然在图中显示MLP有两个决策边界，这是它的优点，但它实际上只是一个决策边界!决策边界就是这样出现的，因为中间表示法改变了空间，使一个超平面同时出现在这两个位置上。在图4-4中，我们可以看到MLP计算的中间值。这些点的形状表示类(星形或圆形)。我们所看到的是，神经网络(本例中为MLP)已经学会了“扭曲”数据所处的空间，以便在数据通过最后一层时，用一线来分割它们。<br><img src="/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/MLP_2.png “图4-4. MLP的输入和中间表示是可视化的。从左到右:（1）网络的输入，（2）第一个线性模块的输出，（3）第一个非线性模块的输出，（4）第二个线性模块的输出。如您所见，第一个线性模块的输出将圆和星分组，而第二个线性模块的输出将数据点重新组织为线性可分的。”" alt="MLP_2"></p>
<p>相反，如图4-5所示，感知器没有额外的一层来处理数据的形状，直到数据变成线性可分的。<br><img src="/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/MLP_3.png" alt="MLP_3" title="图4-5. 感知器的输入和输出表示。因为它没有像MLP那样的中间表示来分组和重新组织，所以它不能将圆和星分开。"></p>
<h3 id="Implementing-MLPs-in-PyTorch"><a href="#Implementing-MLPs-in-PyTorch" class="headerlink" title="Implementing MLPs in PyTorch"></a>Implementing MLPs in PyTorch</h3><p>在上一节中，我们概述了MLP的核心思想。在本节中，我们将介绍PyTorch中的一个实现。如前所述，MLP除了第3章中简单的感知器之外，还有一个额外的计算层。在我们在例4-1中给出的实现中，我们用PyTorch的两个线性模块实例化了这个想法。线性对象被命名为fc1和fc2，它们遵循一个通用约定，即将线性模块称为“完全连接层”，简称为“fc层”。除了这两个线性层外，还有一个修正的线性单元(ReLU)非线性(在第3章“激活函数”一节中介绍)，它在被输入到第二个线性层之前应用于第一个线性层的输出。由于层的顺序性，您必须确保层中的输出数量等于下一层的输入数量。使用两个线性层之间的非线性是必要的，因为没有它，两个线性层在数学上等价于一个线性层4，因此不能建模复杂的模式。MLP的实现只实现反向传播的前向传递。这是因为PyTorch根据模型的定义和向前传递的实现，自动计算出如何进行向后传递和梯度更新。</p>
<p>Example 4-1. Multilayer Perceptron<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultilayerPerceptron</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, hidden_dim, output_dim)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            input_dim (int): the size of the input vectors</span></span><br><span class="line"><span class="string">            hidden_dim (int): the output size of the first Linear layer</span></span><br><span class="line"><span class="string">            output_dim (int): the output size of the second Linear layer</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(MultilayerPerceptron, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x_in, apply_softmax=False)</span>:</span></span><br><span class="line">        <span class="string">"""The forward pass of the MLP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x_in (torch.Tensor): an input data tensor.</span></span><br><span class="line"><span class="string">                x_in.shape should be (batch, input_dim)</span></span><br><span class="line"><span class="string">            apply_softmax (bool): a flag for the softmax activation</span></span><br><span class="line"><span class="string">                should be false if used with the Cross Entropy losses</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            the resulting tensor. tensor.shape should be (batch, output_dim)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        intermediate = F.relu(self.fc1(x_in))</span><br><span class="line">        output = self.fc2(intermediate)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> apply_softmax:</span><br><span class="line">            output = F.softmax(output, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure></p>
<p>在例4-2中，我们实例化了MLP。由于MLP实现的通用性，我们可以为任何大小的输入建模。为了演示，我们使用大小为3的输入维度、大小为4的输出维度和大小为100的隐藏维度。请注意，在print语句的输出中，每个层中的单元数很好地排列在一起，以便为维度3的输入生成维度4的输出。</p>
<p>Example 4-2. An example instantiation of an MLP<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Input[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">2</span> <span class="comment"># number of samples input at once</span></span><br><span class="line">input_dim = <span class="number">3</span></span><br><span class="line">hidden_dim = <span class="number">100</span></span><br><span class="line">output_dim = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">mlp = MultilayerPerceptron(input_dim, hidden_dim, output_dim)</span><br><span class="line">print(mlp)</span><br><span class="line">Output[<span class="number">0</span>]</span><br><span class="line">MultilayerPerceptron(</span><br><span class="line">  (fc1): Linear(in_features=<span class="number">3</span>, out_features=<span class="number">100</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (fc2): Linear(in_features=<span class="number">100</span>, out_features=<span class="number">4</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (relu): ReLU()</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>我们可以通过传递一些随机输入来快速测试模型的“连接”，如示例4-3所示。因为模型还没有经过训练，所以输出是随机的。在花费时间训练模型之前，这样做是一个有用的完整性检查。请注意PyTorch的交互性是如何让我们在开发过程中实时完成所有这些工作的，这与使用NumPy或panda没有太大区别:</p>
<p>Example 4-3. Testing the MLP with random inputs<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Input[<span class="number">0</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">describe</span><span class="params">(x)</span>:</span></span><br><span class="line">    print(<span class="string">"Type: &#123;&#125;"</span>.format(x.type()))</span><br><span class="line">    print(<span class="string">"Shape/size: &#123;&#125;"</span>.format(x.shape))</span><br><span class="line">    print(<span class="string">"Values: \n&#123;&#125;"</span>.format(x))</span><br><span class="line"></span><br><span class="line">x_input = torch.rand(batch_size, input_dim)</span><br><span class="line">describe(x_input)</span><br><span class="line">Output[<span class="number">0</span>]</span><br><span class="line">Type: torch.FloatTensor</span><br><span class="line">Shape/size: torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">Values:</span><br><span class="line">tensor([[ <span class="number">0.8329</span>,  <span class="number">0.4277</span>,  <span class="number">0.4363</span>],</span><br><span class="line">        [ <span class="number">0.9686</span>,  <span class="number">0.6316</span>,  <span class="number">0.8494</span>]])</span><br><span class="line">Input[<span class="number">1</span>]</span><br><span class="line">y_output = mlp(x_input, apply_softmax=<span class="keyword">False</span>)</span><br><span class="line">describe(y_output)</span><br><span class="line">Output[<span class="number">1</span>]</span><br><span class="line">Type: torch.FloatTensor</span><br><span class="line">Shape/size: torch.Size([<span class="number">2</span>, <span class="number">4</span>])</span><br><span class="line">Values:</span><br><span class="line">tensor([[<span class="number">-0.2456</span>,  <span class="number">0.0723</span>,  <span class="number">0.1589</span>, <span class="number">-0.3294</span>],</span><br><span class="line">        [<span class="number">-0.3497</span>,  <span class="number">0.0828</span>,  <span class="number">0.3391</span>, <span class="number">-0.4271</span>]])</span><br></pre></td></tr></table></figure></p>
<p>学习如何读取PyTorch模型的输入和输出非常重要。在前面的例子中，MLP模型的输出是一个有两行四列的张量。这个张量中的行与批处理维数对应，批处理维数是小批处理中的数据点的数量。列是每个数据点的最终特征向量。在某些情况下，例如在分类设置中，特征向量是一个预测向量。名称为“预测向量”表示它对应于一个概率分布。预测向量会发生什么取决于我们当前是在进行训练还是在执行推理。在训练期间，输出按原样使用，带有一个损失函数和目标类标签的表示。我们将在“示例:带有多层感知器的姓氏分类”中对此进行深入介绍。</p>
<p>但是，如果您想将预测向量转换为概率，则需要额外的步骤。具体来说，您需要softmax函数，它用于将一个值向量转换为概率。softmax有许多根。在物理学中，它被称为玻尔兹曼或吉布斯分布;在统计学中，它是多项式逻辑回归;在自然语言处理(NLP)社区，它是最大熵(MaxEnt)分类器。不管叫什么名字，这个函数背后的直觉是，大的正值会导致更高的概率，小的负值会导致更小的概率。在示例4-3中，apply_softmax参数应用了这个额外的步骤。在例4-4中，您可以看到相同的输出，但是这次将apply_softmax标志设置为True:</p>
<p>Example 4-4. MLP with apply_softmax=True<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Input[<span class="number">0</span>]</span><br><span class="line">y_output = mlp(x_input, apply_softmax=<span class="keyword">True</span>)</span><br><span class="line">describe(y_output)</span><br><span class="line">Output[<span class="number">0</span>]</span><br><span class="line">Type: torch.FloatTensor</span><br><span class="line">Shape/size: torch.Size([<span class="number">2</span>, <span class="number">4</span>])</span><br><span class="line">Values:</span><br><span class="line">tensor([[ <span class="number">0.2087</span>,  <span class="number">0.2868</span>,  <span class="number">0.3127</span>,  <span class="number">0.1919</span>],</span><br><span class="line">        [ <span class="number">0.1832</span>,  <span class="number">0.2824</span>,  <span class="number">0.3649</span>,  <span class="number">0.1696</span>]])</span><br></pre></td></tr></table></figure></p>
<p>综上所述，mlp是将张量映射到其他张量的线性层。在每一对线性层之间使用非线性来打破线性关系，并允许模型扭曲向量空间。在分类设置中，这种扭曲应该导致类之间的线性可分性。另外，您可以使用softmax函数将MLP输出解释为概率，但是不应该将softmax与特定的损失函数一起使用，因为底层实现可以利用高级数学/计算捷径。</p>
<h1 id="Example-Surname-Classification-with-a-Multilayer-Perceptron"><a href="#Example-Surname-Classification-with-a-Multilayer-Perceptron" class="headerlink" title="Example: Surname Classification with a Multilayer Perceptron"></a>Example: Surname Classification with a Multilayer Perceptron</h1><p>在本节中，我们将MLP应用于将姓氏分类到其原籍国的任务。从公开观察到的数据推断人口统计信息(如国籍)具有从产品推荐到确保不同人口统计用户获得公平结果的应用。人口统计和其他自我识别信息统称为“受保护属性”。“在建模和产品中使用这些属性时，必须小心。”我们首先对每个姓氏的字符进行拆分，并像对待“示例:将餐馆评论的情绪分类”中的单词一样对待它们。除了数据上的差异，字符层模型在结构和实现上与基于单词的模型基本相似.</p>
<p>您应该从这个例子中吸取的一个重要教训是，MLP的实现和训练是从我们在第3章中看到的感知器的实现和培训直接发展而来的。事实上，我们在本书的第3章中提到了这个例子，以便更全面地了解这些组件。此外，我们不包括你可以在“例子:餐馆评论的情绪分类”中看到的代码，如果你想在一个地方看到例子代码，我们强烈建议你跟随补充材料。</p>
<p>本节的其余部分将从姓氏数据集及其预处理步骤的描述开始。然后，我们使用词汇表、向量化器和DataLoader类逐步完成从姓氏字符串到向量化小批处理的管道。如果您通读了第3章，您应该将这些辅助类视为老朋友，只是做了一些小小的修改。</p>
<p>我们将通过描述姓氏分类器模型及其设计背后的思想过程来继续本节。MLP类似于我们在第3章中看到的感知器例子，但是除了模型的改变，我们在这个例子中引入了多类输出及其对应的损失函数。在描述了模型之后，我们完成了训练例程。训练程序与您在“示例:对餐馆评论的情绪进行分类”中看到的非常相似，因此为了简洁起见，我们在这里不像在该部分中那样深入。我们强烈建议您回顾这一节以获得更多的澄清。</p>
<h3 id="The-Surname-Dataset"><a href="#The-Surname-Dataset" class="headerlink" title="The Surname Dataset"></a>The Surname Dataset</h3><p>在这个例子中，我们介绍了一个姓氏数据集，它收集了来自18个不同国家的10,000个姓氏，这些姓氏是作者从互联网上不同的姓名来源收集的。该数据集将在本书的几个示例中重用，并具有一些使其有趣的属性。第一个性质是它是相当不平衡的。排名前三的课程占数据的60%以上:27%是英语，21%是俄语，14%是阿拉伯语。剩下的15个民族的频率也在下降——这也是语言特有的特性。第二个特点是，在国籍和姓氏正字法(拼写)之间有一种有效和直观的关系。有些拼写变体与原籍国联系非常紧密(比如“O ‘Neill”、“Antonopoulos”、“Nagasawa”或“Zhu”)。</p>
<p>为了创建最终的数据集，我们从一个比本书补充材料中包含的版本处理更少的版本开始，并执行了几个数据集修改操作。第一个目的是减少这种不平衡——原始数据集中70%以上是俄文，这可能是由于抽样偏差或俄文姓氏的增多。为此，我们通过选择标记为俄语的姓氏的随机子集对这个过度代表的类进行子样本。接下来，我们根据国籍对数据集进行分组，并将数据集分为三个部分:70%到训练数据集，15%到验证数据集，最后15%到测试数据集，以便跨这些部分的类标签分布具有可比性。</p>
<p>SurnameDataset的实现与“Example: classification of Sentiment of Restaurant Reviews”中的ReviewDataset几乎相同，只是在<strong>getitem</strong>方法的实现方式上略有不同。回想一下，本书中呈现的数据集类继承自PyTorch的数据集类，因此，我们需要实现两个函数:__getitem<strong>方法，它在给定索引时返回一个数据点;以及</strong>len<strong>方法，该方法返回数据集的长度。“示例:餐厅评论的情绪分类”中的示例与本示例的区别在</strong>getitem__中，如示例4-5所示。它不像“示例:将餐馆评论的情绪分类”那样返回一个向量化的评论，而是返回一个向量化的姓氏和与其国籍相对应的索引:</p>
<p>Example 4-5. Implementing SurnameDataset.__getitem__()<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SurnameDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="comment"># Implementation is nearly identical to Section 3.5</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        row = self._target_df.iloc[index]</span><br><span class="line">        surname_vector = \</span><br><span class="line">            self._vectorizer.vectorize(row.surname)</span><br><span class="line">        nationality_index = \</span><br><span class="line">            self._vectorizer.nationality_vocab.lookup_token(row.nationality)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'x_surname'</span>: surname_vector,</span><br><span class="line">                <span class="string">'y_nationality'</span>: nationality_index&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Vocabulary-Vectorizer-and-DataLoader"><a href="#Vocabulary-Vectorizer-and-DataLoader" class="headerlink" title="Vocabulary, Vectorizer, and DataLoader"></a>Vocabulary, Vectorizer, and DataLoader</h3><p>为了使用字符对姓氏进行分类，我们使用词汇表、向量化器和DataLoader将姓氏字符串转换为向量化的minibatches。这些数据结构与“Example: Classifying Sentiment of Restaurant Reviews”中使用的数据结构相同，它们举例说明了一种多态性，这种多态性将姓氏的字符标记与Yelp评论的单词标记相同对待。数据不是通过将字令牌映射到整数来向量化的，而是通过将字符映射到整数来向量化的。</p>
<p>THE VOCABULARY CLASS<br>本例中使用的词汇类与“example: Classifying Sentiment of Restaurant Reviews”中的词汇完全相同，该词汇类将Yelp评论中的单词映射到对应的整数。简要概述一下，词汇表是两个Python字典的协调，这两个字典在令牌(在本例中是字符)和整数之间形成一个双射;也就是说，第一个字典将字符映射到整数索引，第二个字典将整数索引映射到字符。add_token方法用于向词汇表中添加新的令牌，lookup_token方法用于检索索引，lookup_index方法用于检索给定索引的令牌(在推断阶段很有用)。与Yelp评论的词汇表不同，我们使用的是one-hot词汇表，不计算字符出现的频率，只对频繁出现的条目进行限制。这主要是因为数据集很小，而且大多数字符足够频繁。</p>
<p>THE SURNAMEVECTORIZER<br>虽然词汇表将单个令牌(字符)转换为整数，但SurnameVectorizer负责应用词汇表并将姓氏转换为向量。实例化和使用非常类似于“示例:对餐馆评论的情绪进行分类”中的ReviewVectorizer，但有一个关键区别:字符串没有在空格上分割。姓氏是字符的序列，每个字符在我们的词汇表中是一个单独的标记。然而，在“卷积神经网络”出现之前，我们将忽略序列信息，通过迭代字符串输入中的每个字符来创建输入的收缩one-hot向量表示。我们为以前未遇到的字符指定一个特殊的令牌，即UNK。由于我们仅从训练数据实例化词汇表，而且验证或测试数据中可能有惟一的字符，所以在字符词汇表中仍然使用UNK符号。</p>
<p>您应该注意，虽然我们在这个示例中使用了收缩的one-hot，但是在后面的章节中，您将了解其他向量化方法，它们是one-hot编码的替代方法，有时甚至更好。具体来说，在“示例:使用CNN对姓氏进行分类”中，您将看到一个热门矩阵，其中每个字符都是矩阵中的一个位置，并具有自己的热门向量。然后，在第5章中，您将学习嵌入层，返回整数向量的向量化，以及如何使用它们创建密集向量矩阵。但是现在，让我们看一下示例4-6中SurnameVectorizer的代码。</p>
<p>Example 4-6. Implementing SurnameVectorizer<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SurnameVectorizer</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">""" The Vectorizer which coordinates the Vocabularies and puts them to use"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, surname_vocab, nationality_vocab)</span>:</span></span><br><span class="line">        self.surname_vocab = surname_vocab</span><br><span class="line">        self.nationality_vocab = nationality_vocab</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">vectorize</span><span class="params">(self, surname)</span>:</span></span><br><span class="line">        <span class="string">"""Vectorize the provided surname</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            surname (str): the surname</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            one_hot (np.ndarray): a collapsed one-hot encoding</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        vocab = self.surname_vocab</span><br><span class="line">        one_hot = np.zeros(len(vocab), dtype=np.float32)</span><br><span class="line">        <span class="keyword">for</span> token <span class="keyword">in</span> surname:</span><br><span class="line">            one_hot[vocab.lookup_token(token)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> one_hot</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_dataframe</span><span class="params">(cls, surname_df)</span>:</span></span><br><span class="line">        <span class="string">"""Instantiate the vectorizer from the dataset dataframe</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            surname_df (pandas.DataFrame): the surnames dataset</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            an instance of the SurnameVectorizer</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        surname_vocab = Vocabulary(unk_token=<span class="string">"@"</span>)</span><br><span class="line">        nationality_vocab = Vocabulary(add_unk=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> index, row <span class="keyword">in</span> surname_df.iterrows():</span><br><span class="line">            <span class="keyword">for</span> letter <span class="keyword">in</span> row.surname:</span><br><span class="line">                surname_vocab.add_token(letter)</span><br><span class="line">            nationality_vocab.add_token(row.nationality)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> cls(surname_vocab, nationality_vocab)</span><br></pre></td></tr></table></figure></p>
<h3 id="The-Surname-Classifier-Model"><a href="#The-Surname-Classifier-Model" class="headerlink" title="The Surname Classifier Model"></a>The Surname Classifier Model</h3><p>SurnameClassifier是本章前面介绍的MLP的实现(示例4-7)。第一个线性层将输入向量映射到中间向量，并对该向量应用非线性。第二线性层将中间向量映射到预测向量。</p>
<p>在最后一步中，可选地应用softmax操作，以确保输出和为1;这就是所谓的“概率”。它是可选的原因与我们使用的损失函数的数学公式有关——交叉熵损失。我们研究了“损失函数”中的交叉熵损失。回想一下，交叉熵损失对于多类分类是最理想的，但是在训练过程中软最大值的计算不仅浪费而且在很多情况下并不稳定。</p>
<p>Example 4-7. The SurnameClassifier as an MLP<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SurnameClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">""" A 2-layer Multilayer Perceptron for classifying surnames """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, hidden_dim, output_dim)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            input_dim (int): the size of the input vectors</span></span><br><span class="line"><span class="string">            hidden_dim (int): the output size of the first Linear layer</span></span><br><span class="line"><span class="string">            output_dim (int): the output size of the second Linear layer</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(SurnameClassifier, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x_in, apply_softmax=False)</span>:</span></span><br><span class="line">        <span class="string">"""The forward pass of the classifier</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x_in (torch.Tensor): an input data tensor.</span></span><br><span class="line"><span class="string">                x_in.shape should be (batch, input_dim)</span></span><br><span class="line"><span class="string">            apply_softmax (bool): a flag for the softmax activation</span></span><br><span class="line"><span class="string">                should be false if used with the Cross Entropy losses</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            the resulting tensor. tensor.shape should be (batch, output_dim)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        intermediate_vector = F.relu(self.fc1(x_in))</span><br><span class="line">        prediction_vector = self.fc2(intermediate_vector)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> apply_softmax:</span><br><span class="line">            prediction_vector = F.softmax(prediction_vector, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> prediction_vector</span><br></pre></td></tr></table></figure></p>
<h3 id="The-Training-Routine"><a href="#The-Training-Routine" class="headerlink" title="The Training Routine"></a>The Training Routine</h3><p>虽然我们使用了不同的模型、数据集和损失函数，但是训练例程是相同的。因此，在例4-8中，我们只展示了args以及本例中的训练例程与“示例:餐厅评论情绪分类”中的示例之间的主要区别。</p>
<p>Example 4-8. The args for classifying surnames with an MLP<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">args = Namespace(</span><br><span class="line">    <span class="comment"># Data and path information</span></span><br><span class="line">    surname_csv=<span class="string">"data/surnames/surnames_with_splits.csv"</span>,</span><br><span class="line">    vectorizer_file=<span class="string">"vectorizer.json"</span>,</span><br><span class="line">    model_state_file=<span class="string">"model.pth"</span>,</span><br><span class="line">    save_dir=<span class="string">"model_storage/ch4/surname_mlp"</span>,</span><br><span class="line">    <span class="comment"># Model hyper parameters</span></span><br><span class="line">    hidden_dim=<span class="number">300</span></span><br><span class="line">    <span class="comment"># Training  hyper parameters</span></span><br><span class="line">    seed=<span class="number">1337</span>,</span><br><span class="line">    num_epochs=<span class="number">100</span>,</span><br><span class="line">    early_stopping_criteria=<span class="number">5</span>,</span><br><span class="line">    learning_rate=<span class="number">0.001</span>,</span><br><span class="line">    batch_size=<span class="number">64</span>,</span><br><span class="line">    <span class="comment"># Runtime options omitted for space</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>训练中最显著的差异与模型中输出的种类和使用的损失函数有关。在这个例子中，输出是一个多类预测向量，可以转换为概率。正如在模型描述中所描述的，这种输出的损失类型仅限于CrossEntropyLoss和NLLLoss。由于它的简化，我们使用了CrossEntropyLoss。</p>
<p>在例4-9中，我们展示了数据集、模型、损失函数和优化器的实例化。这些实例应该看起来与“示例:将餐馆评论的情绪分类”中的实例几乎相同。事实上，在本书后面的章节中，这种模式将对每个示例进行重复。</p>
<p>Example 4-9. Instantiating the dataset, model, loss, and optimizer</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dataset = SurnameDataset.load_dataset_and_make_vectorizer(args.surname_csv)</span><br><span class="line">vectorizer = dataset.get_vectorizer()</span><br><span class="line"></span><br><span class="line">classifier = SurnameClassifier(input_dim=len(vectorizer.surname_vocab),</span><br><span class="line">                               hidden_dim=args.hidden_dim,</span><br><span class="line">                               output_dim=len(vectorizer.nationality_vocab))</span><br><span class="line"></span><br><span class="line">classifier = classifier.to(args.device)    </span><br><span class="line"></span><br><span class="line">loss_func = nn.CrossEntropyLoss(dataset.class_weights)</span><br><span class="line">optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)</span><br></pre></td></tr></table></figure>
<p>THE TRAINING LOOP<br>与“Example: Classifying Sentiment of Restaurant Reviews”中的训练循环相比，本例的训练循环除了变量名以外几乎是相同的。具体来说，示例4-10显示了使用不同的key从batch_dict中获取数据。除了外观上的差异，训练循环的功能保持不变。利用训练数据，计算模型输出、损失和梯度。然后，使用梯度来更新模型。</p>
<p>Example 4-10. A snippet of the training loop<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># the training routine is these 5 steps:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --------------------------------------</span></span><br><span class="line"><span class="comment"># step 1. zero the gradients</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 2. compute the output</span></span><br><span class="line">y_pred = classifier(batch_dict[<span class="string">'x_surname'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 3. compute the loss</span></span><br><span class="line">loss = loss_func(y_pred, batch_dict[<span class="string">'y_nationality'</span>])</span><br><span class="line">loss_batch = loss.to(<span class="string">"cpu"</span>).item()</span><br><span class="line">running_loss += (loss_batch - running_loss) / (batch_index + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 4. use loss to produce gradients</span></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># step 5. use optimizer to take gradient step</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure></p>
<h3 id="Model-Evaluation-and-Prediction"><a href="#Model-Evaluation-and-Prediction" class="headerlink" title="Model Evaluation and Prediction"></a>Model Evaluation and Prediction</h3><p>要理解模型的性能，您应该使用定量和定性方法分析模型。定量测量出的测试数据的误差，决定了分类器能否推广到不可见的例子。定性地说，您可以通过查看分类器的top-k预测来为一个新示例开发模型所了解的内容的直觉。<br>EVALUATING ON THE TEST DATASET<br>评价SurnameClassifier测试数据,我们执行相同的常规的routine文本分类的例子“餐馆评论的例子:分类情绪”:我们将数据集设置为遍历测试数据,调用classifier.eval()方法,并遍历测试数据以同样的方式与其他数据。在这个例子中，调用classifier.eval()可以防止PyTorch在使用测试/评估数据时更新模型参数。</p>
<p>该模型对测试数据的准确性达到50%左右。如果您在附带的笔记本中运行训练例程，您会注意到在训练数据上的性能更高。这是因为模型总是更适合它所训练的数据，所以训练数据的性能并不代表新数据的性能。如果您遵循代码，我们鼓励您尝试隐藏维度的不同大小。您应该注意到性能的提高。然而，这种增长不会很大(尤其是与“用CNN对姓氏进行分类的例子”中的模型相比)。其主要原因是收缩的onehot向量化方法是一种弱表示。虽然它确实简洁地将每个姓氏表示为单个向量，但它丢弃了字符之间的顺序信息，这对于识别起源非常重要。</p>
<p>CLASSIFYING A NEW SURNAME</p>
<p>示例4-11显示了分类新姓氏的代码。给定一个姓氏作为字符串，该函数将首先应用向量化过程，然后获得模型预测。注意，我们包含了apply_softmax标志，所以结果包含概率。模型预测，在多项式的情况下，是类概率的列表。我们使用PyTorch张量最大函数来得到由最高预测概率表示的最优类。</p>
<p>Example 4-11. A function for performing nationality prediction<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_nationality</span><span class="params">(name, classifier, vectorizer)</span>:</span></span><br><span class="line">    vectorized_name = vectorizer.vectorize(name)</span><br><span class="line">    vectorized_name = torch.tensor(vectorized_name).view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">    result = classifier(vectorized_name, apply_softmax=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    probability_values, indices = result.max(dim=<span class="number">1</span>)</span><br><span class="line">    index = indices.item()</span><br><span class="line"></span><br><span class="line">    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)</span><br><span class="line">    probability_value = probability_values.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'nationality'</span>: predicted_nationality,</span><br><span class="line">            <span class="string">'probability'</span>: probability_value&#125;</span><br></pre></td></tr></table></figure></p>
<p>RETRIEVING THE TOP-K PREDICTIONS FOR A NEW SURNAME<br>不仅要看最好的预测，还要看更多的预测。例如，NLP中的标准实践是采用k-best预测并使用另一个模型对它们重新排序。PyTorch提供了一个torch.topk函数，它提供了一种方便的方法来获得这些预测，如示例4-12所示。</p>
<p>Example 4-12. Predicting the top-k nationalities<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_topk_nationality</span><span class="params">(name, classifier, vectorizer, k=<span class="number">5</span>)</span>:</span></span><br><span class="line">    vectorized_name = vectorizer.vectorize(name)</span><br><span class="line">    vectorized_name = torch.tensor(vectorized_name).view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">    prediction_vector = classifier(vectorized_name, apply_softmax=<span class="keyword">True</span>)</span><br><span class="line">    probability_values, indices = torch.topk(prediction_vector, k=k)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># returned size is 1,k</span></span><br><span class="line">    probability_values = probability_values.detach().numpy()[<span class="number">0</span>]</span><br><span class="line">    indices = indices.detach().numpy()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    results = []</span><br><span class="line">    <span class="keyword">for</span> prob_value, index <span class="keyword">in</span> zip(probability_values, indices):</span><br><span class="line">        nationality = vectorizer.nationality_vocab.lookup_index(index)</span><br><span class="line">        results.append(&#123;<span class="string">'nationality'</span>: nationality,</span><br><span class="line">                        <span class="string">'probability'</span>: prob_value&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure></p>
<h3 id="Regularizing-MLPs-Weight-Regularization-and-Structural-Regularization-or-Dropout"><a href="#Regularizing-MLPs-Weight-Regularization-and-Structural-Regularization-or-Dropout" class="headerlink" title="Regularizing MLPs: Weight Regularization and Structural Regularization (or Dropout)"></a>Regularizing MLPs: Weight Regularization and Structural Regularization (or Dropout)</h3><p>在第三章中，我们解释了正则化是如何解决过拟合问题的，并研究了两种重要的权重正则化类型——l1和L2。这些权值正则化方法也适用于MLPs和卷积神经网络，我们将在本章后面介绍。除权值正则化外，对于深度模型(即例如本章讨论的前馈网络，一种称为dropout的结构正则化方法变得非常重要。</p>
<p>DROPOUT</p>
<p>简单地说，在训练过程中，dropout有一定概率使属于两个相邻层的单元之间的连接减弱。这有什么用呢?我们从斯蒂芬•梅里蒂(Stephen Merity)的一段直观(且幽默)的解释开始:<br>“Dropout，简单地说，是指如果你能在喝醉的时候反复学习如何做一件事，那么你应该能够在清醒的时候做得更好。这一见解产生了许多最先进的结果和一个新兴的领域。”<br>神经网络——尤其是具有大量分层的深层网络——可以在单元之间创建有趣的相互适应。“Coadaptation”是神经科学中的一个术语，但在这里它只是指一种情况，即两个单元之间的联系变得过于紧密，而牺牲了其他单元之间的联系。这通常会导致模型与数据过拟合。通过概率地丢弃单元之间的连接，我们可以确保没有一个单元总是依赖于另一个单元，从而产生健壮的模型。dropout不会向模型中添加额外的参数，但是需要一个超参数——“drop probability”。drop probability，正如你可能已经猜到的，是单位之间的连接drop的概率。通常将下降概率设置为0.5。例4-13给出了一个带dropout的MLP的重新实现。<br>Example 4-13. MLP with dropout<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultilayerPerceptron</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, hidden_dim, output_dim)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            input_dim (int): the size of the input vectors</span></span><br><span class="line"><span class="string">            hidden_dim (int): the output size of the first Linear layer</span></span><br><span class="line"><span class="string">            output_dim (int): the output size of the second Linear layer</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(MultilayerPerceptron, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_dim, output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x_in, apply_softmax=False)</span>:</span></span><br><span class="line">        <span class="string">"""The forward pass of the MLP</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x_in (torch.Tensor): an input data tensor.</span></span><br><span class="line"><span class="string">                x_in.shape should be (batch, input_dim)</span></span><br><span class="line"><span class="string">            apply_softmax (bool): a flag for the softmax activation</span></span><br><span class="line"><span class="string">                should be false if used with the Cross Entropy losses</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            the resulting tensor. tensor.shape should be (batch, output_dim)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        intermediate = F.relu(self.fc1(x_in))</span><br><span class="line">        output = self.fc2(F.dropout(intermediate, p=<span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> apply_softmax:</span><br><span class="line">            output = F.softmax(output, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure></p>
<p>请注意，dropout只适用于训练期间，不适用于评估期间。作为练习，我们鼓励您试验带有dropout的SurnameClassifier模型，看看它如何更改结果。</p>
<h2 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h2><p>在本章的第一部分中，我们深入研究了MLPs、由一系列线性层和非线性函数构建的神经网络。mlp不是利用顺序模式的最佳工具。例如，在姓氏数据集中，姓氏可以有(不同长度的)段，这些段可以显示出相当多关于其起源国家的信息(如“O’Neill”中的“O”、“Antonopoulos”中的“opoulos”、“Nagasawa”中的“sawa”或“Zhu”中的“Zh”)。这些段的长度可以是可变的，挑战是在不显式编码的情况下捕获它们。</p>
<p>在本节中，我们将介绍卷积神经网络(CNN)，这是一种非常适合检测空间子结构(并因此创建有意义的空间子结构)的神经网络。CNNs通过使用少量的权重来扫描输入数据张量来实现这一点。通过这种扫描，它们产生表示子结构检测(或不检测)的输出张量。</p>
<h2 id="在本节的其余部分中，我们首先描述CNN的工作方式，以及在设计CNN时应该考虑的问题。我们深入研究CNN超参数，目的是提供直观的行为和这些超参数对输出的影响。最后，我们通过几个简单的例子逐步说明CNNs的机制。在“示例-使用CNN对姓氏进行分类”中，我们将深入研究一个更广泛的示例。"><a href="#在本节的其余部分中，我们首先描述CNN的工作方式，以及在设计CNN时应该考虑的问题。我们深入研究CNN超参数，目的是提供直观的行为和这些超参数对输出的影响。最后，我们通过几个简单的例子逐步说明CNNs的机制。在“示例-使用CNN对姓氏进行分类”中，我们将深入研究一个更广泛的示例。" class="headerlink" title="在本节的其余部分中，我们首先描述CNN的工作方式，以及在设计CNN时应该考虑的问题。我们深入研究CNN超参数，目的是提供直观的行为和这些超参数对输出的影响。最后，我们通过几个简单的例子逐步说明CNNs的机制。在“示例:使用CNN对姓氏进行分类”中，我们将深入研究一个更广泛的示例。"></a>在本节的其余部分中，我们首先描述CNN的工作方式，以及在设计CNN时应该考虑的问题。我们深入研究CNN超参数，目的是提供直观的行为和这些超参数对输出的影响。最后，我们通过几个简单的例子逐步说明CNNs的机制。在“示例:使用CNN对姓氏进行分类”中，我们将深入研究一个更广泛的示例。</h2><p>HISTORICAL CONTEXT</p>
<h2 id="CNNs的名称和基本功能源于经典的数学运算卷积。卷积已经应用于各种工程学科，包括数字信号处理和计算机图形学。一般来说，卷积使用程序员指定的参数。这些参数被指定来匹配一些功能设计，如突出边缘或抑制高频声音。事实上，许多Photoshop滤镜都是应用于图像的固定卷积运算。然而，在深度学习和本章中，我们从数据中学习卷积滤波器的参数，因此它对于解决当前的任务是最优的。"><a href="#CNNs的名称和基本功能源于经典的数学运算卷积。卷积已经应用于各种工程学科，包括数字信号处理和计算机图形学。一般来说，卷积使用程序员指定的参数。这些参数被指定来匹配一些功能设计，如突出边缘或抑制高频声音。事实上，许多Photoshop滤镜都是应用于图像的固定卷积运算。然而，在深度学习和本章中，我们从数据中学习卷积滤波器的参数，因此它对于解决当前的任务是最优的。" class="headerlink" title="CNNs的名称和基本功能源于经典的数学运算卷积。卷积已经应用于各种工程学科，包括数字信号处理和计算机图形学。一般来说，卷积使用程序员指定的参数。这些参数被指定来匹配一些功能设计，如突出边缘或抑制高频声音。事实上，许多Photoshop滤镜都是应用于图像的固定卷积运算。然而，在深度学习和本章中，我们从数据中学习卷积滤波器的参数，因此它对于解决当前的任务是最优的。"></a>CNNs的名称和基本功能源于经典的数学运算卷积。卷积已经应用于各种工程学科，包括数字信号处理和计算机图形学。一般来说，卷积使用程序员指定的参数。这些参数被指定来匹配一些功能设计，如突出边缘或抑制高频声音。事实上，许多Photoshop滤镜都是应用于图像的固定卷积运算。然而，在深度学习和本章中，我们从数据中学习卷积滤波器的参数，因此它对于解决当前的任务是最优的。</h2><h3 id="CNN-Hyperparameters"><a href="#CNN-Hyperparameters" class="headerlink" title="CNN Hyperparameters"></a>CNN Hyperparameters</h3><p>为了理解不同的设计决策对CNN意味着什么，我们在图4-6中展示了一个示例。在本例中，单个“核”应用于输入矩阵。卷积运算(线性算子)的精确数学表达式对于理解这一节并不重要，但是从这个图中可以直观地看出，核是一个小的方阵，它被系统地应用于输入矩阵的不同位置。</p>
<p>虽然经典卷积是通过指定核的具体值来设计的，但是CNN是通过指定控制CNN行为的超参数来设计的，然后使用梯度下降来为给定数据集找到最佳参数。两个主要的超参数控制卷积的形状(称为kernel_size)和卷积将在输入数据张量(称为stride)中相乘的位置。还有一些额外的超参数控制输入数据张量被0填充了多少(称为padding)，以及当应用到输入数据张量(称为dilation)时，乘法应该相隔多远。在下面的小节中，我们将更详细地介绍这些超参数。</p>
<p>DIMENSION OF THE CONVOLUTION OPERATION<br>首先要理解的概念是卷积运算的维数。在图4-6和本节的其他图中，我们使用二维卷积进行说明，但是根据数据的性质，还有更适合的其他维度的卷积。在PyTorch中，卷积可以是一维、二维或三维的，分别由Conv1d、Conv2d和Conv3d模块实现。一维卷积对于每个时间步都有一个特征向量的时间序列非常有用。在这种情况下，我们可以在序列维度上学习模式。NLP中的卷积运算大多是一维的卷积。另一方面，二维卷积试图捕捉数据中沿两个方向的时空模式;例如，在图像中沿高度和宽度维度——为什么二维卷积在图像处理中很流行。类似地，在三维卷积中，模式是沿着数据中的三维捕获的。例如，在视频数据中，信息是三维的，二维表示图像的帧，时间维表示帧的序列。就本书而言，我们主要使用Conv1d。</p>
<p>CHANNELS<br>非正式地，通道(channel)是指沿输入中的每个点的特征维度。例如，在图像中，对应于RGB组件的图像中的每个像素有三个通道。在使用卷积时，文本数据也可以采用类似的概念。从概念上讲，如果文本文档中的“像素”是单词，那么通道的数量就是词汇表的大小。如果我们更细粒度地考虑字符的卷积，通道的数量就是字符集的大小(在本例中刚好是词汇表)。在PyTorch卷积实现中，输入通道的数量是in_channels参数。卷积操作可以在输出(out_channels)中产生多个通道。您可以将其视为卷积运算符将输入特征维“映射”到输出特征维。图4-7和图4-8说明了这个概念。</p>
<p>很难立即知道有多少输出通道适合当前的问题。为了简化这个困难，我们假设边界是1,1,024——我们可以有一个只有一个通道的卷积层，也可以有一个只有1,024个通道的卷积层。现在我们有了边界，接下来要考虑的是有多少个输入通道。一种常见的设计模式是，从一个卷积层到下一个卷积层，通道数量的缩减不超过2倍。这不是一个硬性的规则，但是它应该让您了解适当数量的out_channels是什么样子的。</p>
<p>KERNEL SIZE</p>
<p>核矩阵的宽度称为核大小(PyTorch中的kernel_size)。在图4-6中，核大小为2，而在图4-9中，我们显示了一个大小为3的内核。您应该形成的直觉是，卷积将输入中的空间(或时间)本地信息组合在一起，每个卷积的本地信息量由内核大小控制。然而，通过增加核的大小，也会减少输出的大小(Dumoulin和Visin, 2016)。这就是为什么当核大小为3时，输出矩阵是图4-9中的2x2，而当核大小为2时，输出矩阵是图4-6中的3x3。</p>
<p>此外，您可以将NLP应用程序中核大小的行为看作类似于通过查看单词组捕获语言模式的n-gram的行为。使用较小的核大小，可以捕获较小的频繁模式，而较大的核大小会导致较大的模式，这可能更有意义，但是发生的频率更低。较小的核大小会导致输出中的细粒度特性，而较大的核大小会导致粗粒度特性。</p>
<p>STRIDE<br>Stride控制卷积之间的步长。如果步长与核相同，则内核计算不会重叠。另一方面，如果跨度为1，则内核重叠最大。输出张量可以通过增加步幅的方式被有意的压缩来总结信息，如图4-10所示。<br>PADDING<br>即使stride和kernel_size允许控制每个计算出的特征值有多大范围，它们也有一个有害的、有时是无意的副作用，那就是缩小特征映射的总大小(卷积的输出)。为了抵消这一点，输入数据张量被人为地增加了长度(如果是一维、二维或三维)、高度(如果是二维或三维)和深度(如果是三维)，方法是在每个维度上附加和前置0。这意味着CNN将执行更多的卷积，但是输出形状可以控制，而不会影响所需的核大小、步幅或扩展。图4-11展示了正在运行的填充。<br>DILATION<br>膨胀控制卷积核如何应用于输入矩阵。在图4-12中，我们显示，将膨胀从1(默认值)增加到2意味着当应用于输入矩阵时，核的元素彼此之间是两个空格。另一种考虑这个问题的方法是在核中跨跃——在核中的元素或核的应用之间存在一个step size，即存在“holes”。这对于在不增加参数数量的情况下总结输入空间的更大区域是有用的。当卷积层被叠加时，扩张卷积被证明是非常有用的。连续扩张的卷积指数级地增大了“接受域”的大小;即网络在做出预测之前所看到的输入空间的大小。</p>
<h3 id="Implementing-CNNs-in-PyTorch"><a href="#Implementing-CNNs-in-PyTorch" class="headerlink" title="Implementing CNNs in PyTorch"></a>Implementing CNNs in PyTorch</h3><p>在本节中，我们将通过端到端示例来利用上一节中介绍的概念。一般来说，神经网络设计的目标是找到一个能够完成任务的超参数组态。我们再次考虑在“示例:带有多层感知器的姓氏分类”中引入的现在很熟悉的姓氏分类任务，但是我们将使用CNNs而不是MLP。我们仍然需要应用最后一个线性层，它将学会从一系列卷积层创建的特征向量创建预测向量。这意味着目标是确定卷积层的配置，从而得到所需的特征向量。所有CNN应用程序都是这样的:首先有一组卷积层，它们提取一个feature map，然后将其作为上游处理的输入。在分类中，上游处理几乎总是应用线性(或fc)层。</p>
<p>本节中的实现遍历设计决策，以构建一个特征向量。我们首先构造一个人工数据张量，以反映实际数据的形状。数据张量的大小是三维的——这是向量化文本数据的最小批大小。如果你对一个字符序列中的每个字符使用onehot向量，那么onehot向量序列就是一个矩阵，而onehot矩阵的小批量就是一个三维张量。使用卷积的术语，每个onehot(通常是词汇表的大小)的大小是”input channels”的数量，字符序列的长度是“width”。</p>
<p>在例4-14中，构造特征向量的第一步是将PyTorch的Conv1d类的一个实例应用到三维数据张量。通过检查输出的大小，你可以知道张量减少了多少。我们建议您参考图4-9来直观地解释为什么输出张量在收缩。</p>
<p>Example 4-14. Artificial data and using a Conv1d class<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Input[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">one_hot_size = <span class="number">10</span></span><br><span class="line">sequence_width = <span class="number">7</span></span><br><span class="line">data = torch.randn(batch_size, one_hot_size, sequence_width)</span><br><span class="line">conv1 = Conv1d(in_channels=one_hot_size, out_channels=<span class="number">16</span>,</span><br><span class="line">               kernel_size=<span class="number">3</span>)</span><br><span class="line">intermediate1 = conv1(data)</span><br><span class="line">print(data.size())</span><br><span class="line">print(intermediate1.size())</span><br><span class="line">Output[<span class="number">0</span>]</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">10</span>, <span class="number">7</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">16</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure></p>
<p>进一步减小输出张量的主要方法有三种。第一种方法是创建额外的卷积并按顺序应用它们。最终，对应的sequence_width (dim=2)维度的大小将为1。我们在例4-15中展示了应用两个额外卷积的结果。一般来说，对输出张量的约简应用卷积的过程是迭代的，需要一些猜测工作。我们的示例是这样构造的:经过三次卷积之后，最终的输出在最终维度上的大小为1。</p>
<p>Example 4-15. The iterative application of convolutions to data<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Input[<span class="number">0</span>]</span><br><span class="line">conv2 = nn.Conv1d(in_channels=<span class="number">16</span>, out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line">conv3 = nn.Conv1d(in_channels=<span class="number">32</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">intermediate2 = conv2(intermediate1)</span><br><span class="line">intermediate3 = conv3(intermediate2)</span><br><span class="line"></span><br><span class="line">print(intermediate2.size())</span><br><span class="line">print(intermediate3.size())</span><br><span class="line">Output[<span class="number">0</span>]</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">32</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">64</span>, <span class="number">1</span>])</span><br><span class="line">Input[<span class="number">1</span>]</span><br><span class="line">y_output = intermediate3.squeeze()</span><br><span class="line">print(y_output.size())</span><br><span class="line">Output[<span class="number">1</span>]</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">64</span>])</span><br></pre></td></tr></table></figure></p>
<p>在每次卷积中，通道维数的大小都会增加，因为通道维数是每个数据点的特征向量。张量实际上是一个特征向量的最后一步是去掉讨厌的尺寸=1维。您可以使用squeeze()方法来实现这一点。该方法将删除size=1的所有维度并返回结果。然后，得到的特征向量可以与其他神经网络组件(如线性层)一起使用来计算预测向量。</p>
<p>另外还有两种方法可以将张量简化为每个数据点的一个特征向量:将剩余的值压平为特征向量，并在额外维度上求平均值。这两种方法如示例4-16所示。使用第一种方法，只需使用PyTorch的view()方法将所有向量平展成单个向量。第二种方法使用一些数学运算来总结向量中的信息。最常见的操作是算术平均值，但沿feature map维数求和和使用最大值也是常见的。每种方法都有其优点和缺点。扁平化保留了所有的信息，但会导致比预期(或计算上可行)更大的特征向量。平均变得与额外维度的大小无关，但可能会丢失信息。</p>
<p>Example 4-16. Two additional methods for reducing to feature vectors<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Input[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># Method 2 of reducing to feature vectors</span></span><br><span class="line">print(intermediate1.view(batch_size, <span class="number">-1</span>).size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Method 3 of reducing to feature vectors</span></span><br><span class="line">print(torch.mean(intermediate1, dim=<span class="number">2</span>).size())</span><br><span class="line"><span class="comment"># print(torch.max(intermediate1, dim=2).size())</span></span><br><span class="line"><span class="comment"># print(torch.sum(intermediate1, dim=2).size())</span></span><br><span class="line">Output[<span class="number">0</span>]</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">80</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">16</span>])</span><br></pre></td></tr></table></figure></p>
<p>这种设计一系列卷积的方法是基于经验的:从数据的预期大小开始，处理一系列卷积，最终得到适合您的特征向量。虽然这种方法在实践中效果很好，但在给定卷积的超参数和输入张量的情况下，还有另一种计算张量输出大小的方法，即使用从卷积运算本身推导出的数学公式。</p>
<h2 id="Example-Classifying-Surnames-by-Using-a-CNN"><a href="#Example-Classifying-Surnames-by-Using-a-CNN" class="headerlink" title="Example: Classifying Surnames by Using a CNN"></a>Example: Classifying Surnames by Using a CNN</h2><p>为了证明CNN的有效性，让我们应用一个简单的CNN模型来分类姓氏。这项任务的许多细节与前面的MLP示例相同，但真正发生变化的是模型的构造和向量化过程。模型的输入，而不是我们在上一个例子中看到的收缩的onehot，将是一个onehot的矩阵。这种设计将使CNN能够更好地“view”字符的排列，并对在“示例:带有多层感知器的姓氏分类”中使用的收缩的onehot编码中丢失的序列信息进行编码。</p>
<h3 id="The-SurnameDataset"><a href="#The-SurnameDataset" class="headerlink" title="The SurnameDataset"></a>The SurnameDataset</h3><p>虽然姓氏数据集之前在“示例:带有多层感知器的姓氏分类”中进行了描述，但是我们建议您参考“姓氏数据集”来了解它的描述。尽管我们使用了来自“示例:带有多层感知器的姓氏分类”中的相同数据集，但在实现上有一个不同之处:数据集由onehot向量矩阵组成，而不是一个收缩的onehot向量。为此，我们实现了一个数据集类，它跟踪最长的姓氏，并将其作为矩阵中包含的行数提供给矢量化器。列的数量是onehot向量的大小(词汇表的大小)。示例4-17显示了对SurnameDataset.__getitem__的更改;我们显示对SurnameVectorizer的更改。在下一小节向量化。</p>
<p>我们使用数据集中最长的姓氏来控制onehot矩阵的大小有两个原因。首先，将每一小批姓氏矩阵组合成一个三维张量，要求它们的大小相同。其次，使用数据集中最长的姓氏意味着可以以相同的方式处理每个小批处理。</p>
<p>Example 4-17. SurnameDataset modified for passing the maximum surname length<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SurnameDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="comment"># ... existing implementation from Section 4.2</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        row = self._target_df.iloc[index]</span><br><span class="line"></span><br><span class="line">        surname_matrix = \</span><br><span class="line">            self._vectorizer.vectorize(row.surname, self._max_seq_length)</span><br><span class="line"></span><br><span class="line">        nationality_index = \</span><br><span class="line">             self._vectorizer.nationality_vocab.lookup_token(row.nationality)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">'x_surname'</span>: surname_matrix,</span><br><span class="line">                <span class="string">'y_nationality'</span>: nationality_index&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Vocabulary-Vectorizer-and-DataLoader-1"><a href="#Vocabulary-Vectorizer-and-DataLoader-1" class="headerlink" title="Vocabulary, Vectorizer, and DataLoader"></a>Vocabulary, Vectorizer, and DataLoader</h3><p>在本例中，尽管词汇表和DataLoader的实现方式与“示例:带有多层感知器的姓氏分类”中的示例相同，但Vectorizer的vectorize()方法已经更改，以适应CNN模型的需要。具体来说，正如我们在示例4-18中的代码中所示，该函数将字符串中的每个字符映射到一个整数，然后使用该整数构造一个由onehot向量组成的矩阵。重要的是，矩阵中的每一列都是不同的onehot向量。主要原因是，我们将使用的Conv1d层要求数据张量在第0维上具有批处理，在第1维上具有通道，在第2维上具有特性。</p>
<p>除了更改为使用onehot矩阵之外，我们还修改了矢量化器，以便计算姓氏的最大长度并将其保存为max_surname_length</p>
<p>Example 4-18. Implementing the Surname Vectorizer for CNNs<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SurnameVectorizer</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">""" The Vectorizer which coordinates the Vocabularies and puts them to use"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">vectorize</span><span class="params">(self, surname)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            surname (str): the surname</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            one_hot_matrix (np.ndarray): a matrix of one-hot vectors</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">        one_hot_matrix_size = (len(self.character_vocab), self.max_surname_length)</span><br><span class="line">        one_hot_matrix = np.zeros(one_hot_matrix_size, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> position_index, character <span class="keyword">in</span> enumerate(surname):</span><br><span class="line">            character_index = self.character_vocab.lookup_token(character)</span><br><span class="line">            one_hot_matrix[character_index][position_index] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> one_hot_matrix</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_dataframe</span><span class="params">(cls, surname_df)</span>:</span></span><br><span class="line">        <span class="string">"""Instantiate the vectorizer from the dataset dataframe</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            surname_df (pandas.DataFrame): the surnames dataset</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            an instance of the SurnameVectorizer</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        character_vocab = Vocabulary(unk_token=<span class="string">"@"</span>)</span><br><span class="line">        nationality_vocab = Vocabulary(add_unk=<span class="keyword">False</span>)</span><br><span class="line">        max_surname_length = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> index, row <span class="keyword">in</span> surname_df.iterrows():</span><br><span class="line">            max_surname_length = max(max_surname_length, len(row.surname))</span><br><span class="line">            <span class="keyword">for</span> letter <span class="keyword">in</span> row.surname:</span><br><span class="line">                character_vocab.add_token(letter)</span><br><span class="line">            nationality_vocab.add_token(row.nationality)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> cls(character_vocab, nationality_vocab, max_surname_length)</span><br></pre></td></tr></table></figure></p>
<h3 id="Reimplementing-the-SurnameClassifier-with-Convolutional-Networks"><a href="#Reimplementing-the-SurnameClassifier-with-Convolutional-Networks" class="headerlink" title="Reimplementing the SurnameClassifier with Convolutional Networks"></a>Reimplementing the SurnameClassifier with Convolutional Networks</h3><p>我们在本例中使用的模型是使用我们在“卷积神经网络”中介绍的方法构建的。实际上，我们在该部分中创建的用于测试卷积层的“人工”数据与姓氏数据集中使用本例中的矢量化器的数据张量的大小完全匹配。正如您在示例4-19中所看到的，它与我们在“卷积神经网络”中引入的Conv1d序列既有相似之处，也有需要解释的新添加内容。具体来说，该模型类似于“卷积神经网络”，它使用一系列一维卷积来增量地计算更多的特征，从而得到一个单特征向量。</p>
<p>然而，本例中的新内容是使用sequence和ELU PyTorch模块。序列模块是封装线性操作序列的方便包装器。在这种情况下，我们使用它来封装Conv1d序列的应用程序。ELU是类似于第3章中介绍的ReLU的非线性函数，但是它不是将值裁剪到0以下，而是对它们求幂。ELU已经被证明是卷积层之间使用的一种很有前途的非线性(Clevert et al.， 2015)。</p>
<p>在本例中，我们将每个卷积的通道数与num_channels超参数绑定。我们可以选择不同数量的通道分别进行卷积运算。这样做需要优化更多的超参数。我们发现256足够大，可以使模型达到合理的性能。</p>
<p>Example 4-19. The CNN-based SurnameClassifier<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SurnameClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, initial_num_channels, num_classes, num_channels)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            initial_num_channels (int): size of the incoming feature vector</span></span><br><span class="line"><span class="string">            num_classes (int): size of the output prediction vector</span></span><br><span class="line"><span class="string">            num_channels (int): constant channel size to use throughout network</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        super(SurnameClassifier, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.convnet = nn.Sequential(</span><br><span class="line">            nn.Conv1d(in_channels=initial_num_channels,</span><br><span class="line">                      out_channels=num_channels, kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.ELU(),</span><br><span class="line">            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,</span><br><span class="line">                      kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.ELU(),</span><br><span class="line">            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,</span><br><span class="line">                      kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            nn.ELU(),</span><br><span class="line">            nn.Conv1d(in_channels=num_channels, out_channels=num_channels,</span><br><span class="line">                      kernel_size=<span class="number">3</span>),</span><br><span class="line">            nn.ELU()</span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Linear(num_channels, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x_surname, apply_softmax=False)</span>:</span></span><br><span class="line">        <span class="string">"""The forward pass of the classifier</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x_surname (torch.Tensor): an input data tensor.</span></span><br><span class="line"><span class="string">                x_surname.shape should be (batch, initial_num_channels,</span></span><br><span class="line"><span class="string">                                           max_surname_length)</span></span><br><span class="line"><span class="string">            apply_softmax (bool): a flag for the softmax activation</span></span><br><span class="line"><span class="string">                should be false if used with the Cross Entropy losses</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            the resulting tensor. tensor.shape should be (batch, num_classes)</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        features = self.convnet(x_surname).squeeze(dim=<span class="number">2</span>)</span><br><span class="line">        prediction_vector = self.fc(features)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> apply_softmax:</span><br><span class="line">            prediction_vector = F.softmax(prediction_vector, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> prediction_vector</span><br></pre></td></tr></table></figure></p>
<h3 id="The-Training-Routine-1"><a href="#The-Training-Routine-1" class="headerlink" title="The Training Routine"></a>The Training Routine</h3><p>训练程序包括以下似曾相识的的操作序列:实例化数据集,实例化模型,实例化损失函数,实例化优化器,遍历数据集的训练分区和更新模型参数,遍历数据集的验证分区和测量性能,然后重复数据集迭代一定次数。此时，这是本书到目前为止的第三个训练例程实现，应该将这个操作序列内部化。对于这个例子，我们将不再详细描述具体的训练例程，因为它与“示例:带有多层感知器的姓氏分类”中的例程完全相同。但是，输入参数是不同的，您可以在示例4-20中看到。</p>
<p>Example 4-20. Input arguments to the CNN surname classifier<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">args = Namespace(</span><br><span class="line">    <span class="comment"># Data and Path information</span></span><br><span class="line">    surname_csv=<span class="string">"data/surnames/surnames_with_splits.csv"</span>,</span><br><span class="line">    vectorizer_file=<span class="string">"vectorizer.json"</span>,</span><br><span class="line">    model_state_file=<span class="string">"model.pth"</span>,</span><br><span class="line">    save_dir=<span class="string">"model_storage/ch4/cnn"</span>,</span><br><span class="line">    <span class="comment"># Model hyper parameters</span></span><br><span class="line">    hidden_dim=<span class="number">100</span>,</span><br><span class="line">    num_channels=<span class="number">256</span>,</span><br><span class="line">    <span class="comment"># Training hyper parameters</span></span><br><span class="line">    seed=<span class="number">1337</span>,</span><br><span class="line">    learning_rate=<span class="number">0.001</span>,</span><br><span class="line">    batch_size=<span class="number">128</span>,</span><br><span class="line">    num_epochs=<span class="number">100</span>,</span><br><span class="line">    early_stopping_criteria=<span class="number">5</span>,</span><br><span class="line">    dropout_p=<span class="number">0.1</span>,</span><br><span class="line">    <span class="comment"># Runtime omitted for space ...</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<h3 id="Model-Evaluation-and-Prediction-1"><a href="#Model-Evaluation-and-Prediction-1" class="headerlink" title="Model Evaluation and Prediction"></a>Model Evaluation and Prediction</h3><p>要理解模型的性能，需要对性能进行定量和定性的度量。下面将描述这两个度量的基本组件。我们鼓励您扩展它们，以探索该模型及其所学习到的内容。</p>
<p>Evaluating on the Test Dataset<br>正如“示例:带有多层感知器的姓氏分类”中的示例与本示例之间的训练例程没有变化一样，执行评估的代码也没有变化。总之，调用分类器的eval()方法来防止反向传播，并迭代测试数据集。与MLP约50%的性能相比，该模型的测试集性能准确率约为56%。尽管这些性能数字绝不是这些特定架构的上限，但是通过一个相对简单的CNN模型获得的改进应该足以让您在文本数据上尝试CNNs。</p>
<p>Classifying or retrieving top predictions for a new surname</p>
<p>在本例中，predict_nationality()函数的一部分发生了更改，如示例4-21所示:我们没有使用视图方法重塑新创建的数据张量以添加批处理维度，而是使用PyTorch的unsqueeze()函数在批处理应该在的位置添加大小为1的维度。相同的更改反映在predict_topk_nationality()函数中。</p>
<p>Example 4-21. Using the trained model to make predictions<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_nationality</span><span class="params">(surname, classifier, vectorizer)</span>:</span></span><br><span class="line">    <span class="string">"""Predict the nationality from a new surname</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        surname (str): the surname to classifier</span></span><br><span class="line"><span class="string">        classifier (SurnameClassifer): an instance of the classifier</span></span><br><span class="line"><span class="string">        vectorizer (SurnameVectorizer): the corresponding vectorizer</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        a dictionary with the most likely nationality and its probability</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    vectorized_surname = vectorizer.vectorize(surname)</span><br><span class="line">    vectorized_surname = torch.tensor(vectorized_surname).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    result = classifier(vectorized_surname, apply_softmax=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    probability_values, indices = result.max(dim=<span class="number">1</span>)</span><br><span class="line">    index = indices.item()</span><br><span class="line"></span><br><span class="line">    predicted_nationality = vectorizer.nationality_vocab.lookup_index(index)</span><br><span class="line">    probability_value = probability_values.item()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">'nationality'</span>: predicted_nationality, <span class="string">'probability'</span>: probability_value&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Miscellaneous-Topics-in-CNNs"><a href="#Miscellaneous-Topics-in-CNNs" class="headerlink" title="Miscellaneous Topics in CNNs"></a>Miscellaneous Topics in CNNs</h2><p>为了结束我们的讨论，我们概述了几个其他的主题，这些主题是CNNs的核心，但在它们的共同使用中起着主要作用。特别是，您将看到Pooling操作、batch Normalization、network-in-network connection和residual connections的描述。</p>
<h3 id="Pooling-Operation"><a href="#Pooling-Operation" class="headerlink" title="Pooling Operation"></a>Pooling Operation</h3><p>Pooling是将高维特征映射总结为低维特征映射的操作。卷积的输出是一个特征映射。feature map中的值总结了输入的一些区域。由于卷积计算的重叠性，许多计算出的特征可能是冗余的。Pooling是一种将高维(可能是冗余的)特征映射总结为低维特征映射的方法。在形式上，池是一种像sum、mean或max这样的算术运算符，系统地应用于feature map中的局部区域，得到的池操作分别称为sum pooling、average pooling和max pooling。池还可以作为一种方法，将较大但较弱的feature map的统计强度改进为较小但较强的feature map。图4-13说明了Pooling。</p>
<h3 id="Batch-Normalization-BatchNorm"><a href="#Batch-Normalization-BatchNorm" class="headerlink" title="Batch Normalization (BatchNorm)"></a>Batch Normalization (BatchNorm)</h3><p>批处理标准化是设计网络时经常使用的一种工具。BatchNorm对CNN的输出进行转换，方法是将激活量缩放为零均值和单位方差。它用于Z-transform的平均值和方差值每批更新一次，这样任何单个批中的波动都不会太大地移动或影响它。BatchNorm允许模型对参数的初始化不那么敏感，并且简化了学习速率的调整(Ioffe and Szegedy, 2015)。在PyTorch中，批处理规范是在nn模块中定义的。例4-22展示了如何用卷积和线性层实例化和使用批处理规范。</p>
<p>Example 4-22. Using s Conv1D layer with batch normalization.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ...</span></span><br><span class="line">        self.conv1 = nn.Conv1d(in_channels=<span class="number">1</span>, out_channels=<span class="number">10</span>,</span><br><span class="line">                               kernel_size=<span class="number">5</span>,</span><br><span class="line">                               stride=<span class="number">1</span>)</span><br><span class="line">        self.conv1_bn = nn.BatchNorm1d(num_features=<span class="number">10</span>)</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">       <span class="comment"># ...</span></span><br><span class="line">       x = F.relu(self.conv1(x))</span><br><span class="line">       x = self.conv1_bn(x)</span><br><span class="line">       <span class="comment"># ...</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Network-in-Network-Connections-1x1-Convolutions"><a href="#Network-in-Network-Connections-1x1-Convolutions" class="headerlink" title="Network-in-Network Connections (1x1 Convolutions)"></a>Network-in-Network Connections (1x1 Convolutions)</h3><p>Network-in-Network (NiN)连接是具有kernel_size=1的卷积内核，具有一些有趣的特性。具体来说，1x1卷积就像通道之间的一个完全连通的线性层。这在从多通道feature map映射到更浅的feature map时非常有用。在图4-14中，我们展示了一个应用于输入矩阵的NiN连接。如您所见，它将两个通道简化为一个通道。因此，NiN或1x1卷积提供了一种廉价的方法来合并参数较少的额外非线性(Lin et al.， 2013)。</p>
<h3 id="Residual-Connections-Residual-Block"><a href="#Residual-Connections-Residual-Block" class="headerlink" title="Residual Connections/Residual Block"></a>Residual Connections/Residual Block</h3><p>CNNs中最重要的趋势之一是Residual connection，它支持真正深层的网络(超过100层)。它也称为skip connection。如果将卷积函数表示为conv，则residual block的输出如下:</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>在本章中，您学习了两个基本的前馈架构:多层感知器(MLP;也称为“full-connected”网络)和卷积神经网络(CNN)。我们看到了MLPs在近似任何非线性函数方面的威力，并展示了MLPs在NLP中的应用，以及从姓氏中对国籍进行分类的应用。我们研究了mlp的一个主要缺点/限制—缺乏参数共享—并介绍了卷积网络架构作为一种可能的解决方案。最初为计算机视觉开发的CNNs，现已成为NLP的中流砥柱;主要是因为它们的高效实现和低内存需求。我们研究了卷积的不同变体——填充、扩展和扩展——以及它们如何转换输入空间。本章还专门讨论了卷积滤波器的输入和输出大小选择的实际问题。我们展示了卷积操作如何通过扩展姓氏分类示例来使用convnets来帮助捕获语言中的子结构信息。最后，我们讨论了与卷积网络设计相关的一些杂项但重要的主题:1)Pooling，2)Batchnorm，3)1x1卷积，4)residual connection。在现代CNN的设计中，经常可以看到像Inception架构(Szegedy et al.， 2015)那样同时使用许多这样的技巧。在Inception架构中，小心地使用这些技巧可以让卷积网络深入到数百层，不仅精确，而且训练速度快。在第5章中，我们探讨了学习和使用表示表示离散单元的主题，例如使用嵌入式的单词、句子、文档和其他特征类型。</p>

      
    </div>
    
    
    

	<div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

<div class="my_post_copyright">
  <script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>
  
  <!-- JS库 sweetalert 可修改路径 -->
  <script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script>
  <script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script>
  <p><span>本文标题:</span><a href="/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/">Natural-Language-Processing-with-PyTorch（四）</a></p>
  <p><span>文章作者:</span><a href="/" title="访问 Yif Du 的个人博客">Yif Du</a></p>
  <p><span>发布时间:</span>2018年12月20日 - 09:12</p>
  <p><span>最后更新:</span>2018年12月28日 - 11:12</p>
  <p><span>原始链接:</span><a href="/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/" title="Natural-Language-Processing-with-PyTorch（四）">http://yifdu.github.io/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/</a>
    <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="http://yifdu.github.io/2018/12/20/Natural-Language-Processing-with-PyTorch（四）/" aria-label="复制成功！"></i></span>
  </p>
  <p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p>  
</div>
<script> 
    var clipboard = new Clipboard('.fa-clipboard');
      $(".fa-clipboard").click(function(){
      clipboard.on('success', function(){
        swal({   
          title: "",   
          text: '复制成功',
          icon: "success", 
          showConfirmButton: true
          });
        });
    });  
</script>

      
    </div>
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/NLP/" rel="tag"># NLP</a>
          
            <a href="/tags/Pytorch/" rel="tag"># Pytorch</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/19/Natural-Language-Processing-with-PyTorch（三）/" rel="next" title="Natural-Language-Processing-with-PyTorch（三）">
                <i class="fa fa-chevron-left"></i> Natural-Language-Processing-with-PyTorch（三）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/12/21/Natural-Language-Processing-with-PyTorch（五）/" rel="prev" title="Natural-Language-Processing-with-PyTorch（五）">
                Natural-Language-Processing-with-PyTorch（五） <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div id="gitalk-container"></div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/xuanyi.jpg" alt="Yif Du">
            
              <p class="site-author-name" itemprop="name">Yif Du</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">141</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">108</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yifdu" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="17210240004@fudan.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Chapter-4-Feed-Forward-Networks-for-Natural-Language-Processing"><span class="nav-number">1.</span> <span class="nav-text">Chapter 4. Feed-Forward Networks for Natural Language Processing</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#The-Multilayer-Perceptron"><span class="nav-number">1.1.</span> <span class="nav-text">The Multilayer Perceptron</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Simple-Example-XOR"><span class="nav-number">1.1.1.</span> <span class="nav-text">A Simple Example: XOR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Implementing-MLPs-in-PyTorch"><span class="nav-number">1.1.2.</span> <span class="nav-text">Implementing MLPs in PyTorch</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Example-Surname-Classification-with-a-Multilayer-Perceptron"><span class="nav-number">2.</span> <span class="nav-text">Example: Surname Classification with a Multilayer Perceptron</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Surname-Dataset"><span class="nav-number">2.0.1.</span> <span class="nav-text">The Surname Dataset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vocabulary-Vectorizer-and-DataLoader"><span class="nav-number">2.0.2.</span> <span class="nav-text">Vocabulary, Vectorizer, and DataLoader</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Surname-Classifier-Model"><span class="nav-number">2.0.3.</span> <span class="nav-text">The Surname Classifier Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Training-Routine"><span class="nav-number">2.0.4.</span> <span class="nav-text">The Training Routine</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-Evaluation-and-Prediction"><span class="nav-number">2.0.5.</span> <span class="nav-text">Model Evaluation and Prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularizing-MLPs-Weight-Regularization-and-Structural-Regularization-or-Dropout"><span class="nav-number">2.0.6.</span> <span class="nav-text">Regularizing MLPs: Weight Regularization and Structural Regularization (or Dropout)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Convolutional-Neural-Networks"><span class="nav-number">2.1.</span> <span class="nav-text">Convolutional Neural Networks</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#在本节的其余部分中，我们首先描述CNN的工作方式，以及在设计CNN时应该考虑的问题。我们深入研究CNN超参数，目的是提供直观的行为和这些超参数对输出的影响。最后，我们通过几个简单的例子逐步说明CNNs的机制。在“示例-使用CNN对姓氏进行分类”中，我们将深入研究一个更广泛的示例。"><span class="nav-number">2.2.</span> <span class="nav-text">在本节的其余部分中，我们首先描述CNN的工作方式，以及在设计CNN时应该考虑的问题。我们深入研究CNN超参数，目的是提供直观的行为和这些超参数对输出的影响。最后，我们通过几个简单的例子逐步说明CNNs的机制。在“示例:使用CNN对姓氏进行分类”中，我们将深入研究一个更广泛的示例。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CNNs的名称和基本功能源于经典的数学运算卷积。卷积已经应用于各种工程学科，包括数字信号处理和计算机图形学。一般来说，卷积使用程序员指定的参数。这些参数被指定来匹配一些功能设计，如突出边缘或抑制高频声音。事实上，许多Photoshop滤镜都是应用于图像的固定卷积运算。然而，在深度学习和本章中，我们从数据中学习卷积滤波器的参数，因此它对于解决当前的任务是最优的。"><span class="nav-number">2.3.</span> <span class="nav-text">CNNs的名称和基本功能源于经典的数学运算卷积。卷积已经应用于各种工程学科，包括数字信号处理和计算机图形学。一般来说，卷积使用程序员指定的参数。这些参数被指定来匹配一些功能设计，如突出边缘或抑制高频声音。事实上，许多Photoshop滤镜都是应用于图像的固定卷积运算。然而，在深度学习和本章中，我们从数据中学习卷积滤波器的参数，因此它对于解决当前的任务是最优的。</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CNN-Hyperparameters"><span class="nav-number">2.3.1.</span> <span class="nav-text">CNN Hyperparameters</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Implementing-CNNs-in-PyTorch"><span class="nav-number">2.3.2.</span> <span class="nav-text">Implementing CNNs in PyTorch</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Example-Classifying-Surnames-by-Using-a-CNN"><span class="nav-number">2.4.</span> <span class="nav-text">Example: Classifying Surnames by Using a CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#The-SurnameDataset"><span class="nav-number">2.4.1.</span> <span class="nav-text">The SurnameDataset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vocabulary-Vectorizer-and-DataLoader-1"><span class="nav-number">2.4.2.</span> <span class="nav-text">Vocabulary, Vectorizer, and DataLoader</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reimplementing-the-SurnameClassifier-with-Convolutional-Networks"><span class="nav-number">2.4.3.</span> <span class="nav-text">Reimplementing the SurnameClassifier with Convolutional Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Training-Routine-1"><span class="nav-number">2.4.4.</span> <span class="nav-text">The Training Routine</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Model-Evaluation-and-Prediction-1"><span class="nav-number">2.4.5.</span> <span class="nav-text">Model Evaluation and Prediction</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Miscellaneous-Topics-in-CNNs"><span class="nav-number">2.5.</span> <span class="nav-text">Miscellaneous Topics in CNNs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pooling-Operation"><span class="nav-number">2.5.1.</span> <span class="nav-text">Pooling Operation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Batch-Normalization-BatchNorm"><span class="nav-number">2.5.2.</span> <span class="nav-text">Batch Normalization (BatchNorm)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Network-in-Network-Connections-1x1-Convolutions"><span class="nav-number">2.5.3.</span> <span class="nav-text">Network-in-Network Connections (1x1 Convolutions)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Residual-Connections-Residual-Block"><span class="nav-number">2.5.4.</span> <span class="nav-text">Residual Connections/Residual Block</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summary"><span class="nav-number">2.6.</span> <span class="nav-text">Summary</span></a></li></ol></div>
            

			
          </div>
        </section>
      <!--/noindex-->
      

      
	 

    </div>
		  
	  
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="heart">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yif Du</span>

  
</div>





        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
  <script src="/js/src/md5.min.js"></script>
   <script type="text/javascript">
        var gitalk = new Gitalk({
          clientID: '7428ad62daef314bef06',
          clientSecret: '93cd3f4cd41cfc00c4760f65f8d895a66088ea5a',
          repo: 'Comments',
          owner: 'yifdu',
          admin: ['yifdu'],
          id: md5(location.pathname),
          distractionFreeMode: 'true'
        })
        gitalk.render('gitalk-container')           
       </script>


  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  <style>
#selectionCopyright {
    position: absolute;
    display: none;
    background: rgba(244,67,54,.7);
    color: #fff;
    border-radius: 6px;
    box-shadow: none;
    border: none;
    font-size: 14px;
}
#selectionCopyright a{
    color:#fff;
    border-color: #fff;
}
#selectionCopyright::before {
    content: "";
    width: 0;
    height: 0;
    border-style: solid;
    border-width: 6px 8px 6px 0;
    border-color: transparent rgba(244,67,54,.7) transparent transparent;
    position: absolute;
    left: -8px;
    top:50%;
    transform:translateY(-50%);
}
</style>

<button id="selectionCopyright" disabled="disabled">本文发表于[<a href="http://yifdu.github.io">yifdu.github.io</a>]分享请注明来源！</button>

<script>
window.onload = function() {
    function selectText() {
        if (document.selection) { //IE浏览器下
            return document.selection.createRange().text; //返回选中的文字
        } else { //非IE浏览器下
            return window.getSelection().toString(); //返回选中的文字
        }
    }
    var content = document.getElementsByTagName("body")[0];
    var scTip = document.getElementById('selectionCopyright');

    content.onmouseup = function(ev) { //设定一个onmouseup事件
        var ev = ev || window.event;
        var left = ev.clientX;//获取鼠标相对浏览器可视区域左上角水平距离距离
        var top = ev.clientY;//获取鼠标相对浏览器可视区域左上角垂直距离距离
        var xScroll = Math.max(document.body.scrollLeft, document.documentElement.scrollLeft);//获取文档水平滚动距离
        var yScroll = Math.max(document.body.scrollTop, document.documentElement.scrollTop);//获取文档垂直滚动距离
        if (selectText().length > 0) {
            setTimeout(function() { //设定一个定时器
                scTip.style.display = 'inline-block';
                scTip.style.left = left + xScroll + 15 + 'px';//鼠标当前x值
                scTip.style.top = top + yScroll - 15 + 'px';//鼠标当前y值
            }, 100);
        } else {
            scTip.style.display = 'none';
        }
    };

    content.onclick = function(ev) {
        var ev = ev || window.event;
        ev.cancelBubble = true;
    };
    document.onclick = function() {
        scTip.style.display = 'none';
    };
};
</script>

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"live2d-widget-model-miku"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
